
每周分类神经辐射场 ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
==========================================================================================================================
## 按类别筛选: [全部](./weekly_nerf_cn.md) | [动态](./classified_weekly_nerf_cn/dynamic.md) | [编辑](./classified_weekly_nerf_cn/editing.md) | [快速](./classified_weekly_nerf_cn/fast.md) | [泛化](./classified_weekly_nerf_cn/generalization.md) 
## [光照](./classified_weekly_nerf_cn/lighting.md) | [重建](./classified_weekly_nerf_cn/reconstruction.md) | [纹理](./classified_weekly_nerf_cn/texture.md) | [语义](./classified_weekly_nerf_cn/semantic.md) | [姿态-SLAM](./classified_weekly_nerf_cn/pose-slam.md) | [其他](./classified_weekly_nerf_cn/others.md) 
## 大部分为机器翻译，少数论文手动翻译，有翻译错误可以PR修复。
## Jul31 - Aug6, 2022
  - [NFOMP：具有非完整约束的差动驱动机器人最优运动规划器的神经场, IEEE Robotics and Automation Letters](https://ieeexplore.ieee.org/abstract/document/9851532/) | [code]
    > 摘要：最优运动规划是移动机器人中最关键的问题之一。一方面，经典的基于采样的方法为这个问题提出了渐近最优的解决方案。然而，这些规划器无法在合理的计算时间内实现平滑和短的轨迹。另一方面，基于优化的方法能够在各种场景中生成平滑而平坦的轨迹，包括密集的人群。然而，现代基于优化的方法使用预先计算的有符号距离函数进行碰撞损失估计，它限制了这些方法在一般配置空间中的应用，包括具有非完整约束的差分驱动非圆形机器人。此外，基于优化的方法缺乏准确处理 U 形或薄障碍物的能力。我们建议从两个方面改进优化方法。首先，我们开发了一个障碍物神经场模型来估计碰撞损失；将此模型与轨迹优化一起训练可以持续改善碰撞损失，同时实现更可行和更平滑的轨迹。其次，我们通过将拉格朗日乘数添加到轨迹损失函数中来强制轨迹考虑非完整约束。我们应用我们的方法解决了具有非完整约束的差动驱动机器人的最优运动规划问题，对我们的解决方案进行了基准测试，并证明了新的规划器生成了非常适合机器人跟随的平滑、短而平坦的轨迹，并且优于最先进的方法在归一化曲率上提高了 25%，在 MovingAI 环境中的尖点数量上提高了 75%。
  - [NeSF: 用于 3D 场景的可概括语义分割的神经语义场](https://research.google/pubs/pub51563/) | [code]
    > 我们提出了 NeSF，一种从预训练的密度场和稀疏的 2D 语义监督产生 3D 语义场的方法。我们的方法通过利用将 3D 信息存储在神经域中的神经表示来避开传统的场景表示。尽管仅由 2D 信号监督，我们的方法能够从新颖的相机姿势生成 3D 一致的语义图，并且可以在任意 3D 点进行查询。值得注意的是，NeSF 与任何产生密度场的方法兼容，并且随着预训练密度场质量的提高，其准确性也会提高。我们的实证分析证明了在令人信服的合成场景上与竞争性 2D 和 3D 语义分割基线相当的质量，同时还提供了现有方法无法提供的功能。
  - [PRIF: Primary Ray-based Implicit Function](https://research.google/pubs/pub51556/) | [code]
    > 我们引入了一种新的隐式形状表示，称为基于初级光线的隐式函数 (PRIF)。与大多数基于符号距离函数 (SDF) 处理空间位置的现有方法相比，我们的表示在定向射线上运行。具体来说，PRIF 被制定为直接生成给定输入射线的表面命中点，而无需昂贵的球体跟踪操作，从而实现高效的形状提取和可微渲染。我们证明了经过训练以编码 PRIF 的神经网络在各种任务中取得了成功，包括单一形状表示、类别形状生成、稀疏或嘈杂观察的形状补全、相机姿态估计的逆渲染以及颜色的神经渲染。
  - [Transformers as Meta-Learners for Implicit Neural Representations, ECCV2022](https://arxiv.org/abs/2208.02801) | [***``[code]``***](https://yinboc.github.io/trans-inr/)
    > 近年来，隐式神经表示 (INR) 已经出现并显示出其优于离散表示的优势。然而，将 INR 拟合到给定的观测值通常需要从头开始使用梯度下降进行优化，这是低效的，并且不能很好地泛化稀疏的观测值。为了解决这个问题，大多数先前的工作都训练了一个超网络，该超网络生成单个向量来调制 INR 权重，其中单个向量成为限制输出 INR 重建精度的信息瓶颈。最近的工作表明，通过基于梯度的元学习，可以在没有单向量瓶颈的情况下精确推断 INR 中的整个权重集。受基于梯度的元学习的广义公式的启发，我们提出了一个公式，该公式使用 Transformer 作为 INR 的超网络，它可以使用专门作为集合到集合映射的 Transformer 直接构建整个 INR 权重集。我们展示了我们的方法在不同任务和领域中构建 INR 的有效性，包括 2D 图像回归和 3D 对象的视图合成。我们的工作在 Transformer 超网络和基于梯度的元学习算法之间建立了联系，我们为理解生成的 INR 提供了进一步的分析。
  - [全息显示3D相位全息图的端到端学习](https://www.nature.com/articles/s41377-022-00894-6) | [code]
    > 计算机生成的全息术 (CGH) 提供相干波前的体积控制，是体积 3D 显示器、光刻、神经光刺激和光/声捕获等应用的基础。最近，基于深度学习的方法作为 CGH 合成的有前途的计算范式出现，克服了传统基于模拟/优化的方法中的质量-运行时权衡。然而，预测全息图的质量本质上受数据集质量的限制。在这里，我们介绍了一个新的全息图数据集 MIT-CGH-4K-V2，它使用分层深度图像作为数据高效的体积 3D 输入和用于直接合成高质量 3D 相位的两阶段监督+无监督训练协议-只有全息图。所提出的系统还可以校正视觉像差，从而允许为最终用户定制。我们通过实验展示了逼真的 3D 全息投影并讨论了相关的空间光调制器校准程序。我们的方法在消费级 GPU 上实时运行，在 iPhone 13 Pro 上以 5 FPS 运行，有望显着提高上述应用程序的性能。
  - [VolTeMorph：体积表示的实时、可控和可泛化动画](https://arxiv.org/pdf/2208.00949) | [***``[code]``***](https://arxiv.org/pdf/2208.00949)
    > 最近，用于场景重建和新颖视图合成的体积表示越来越受欢迎，这使人们重新关注在高可见度下对体积内容进行动画处理质量和实时性。虽然基于学习函数的隐式变形方法可以产生令人印象深刻的结果，但它们对于艺术家和内容创作者来说是“黑匣子”，它们需要大量的训练数据才能进行有意义的概括，而且它们不会在训练数据之外产生现实的外推。在这项工作中，我们通过引入一种实时、易于使用现成软件进行编辑并且可以令人信服地推断的体积变形方法来解决这些问题。为了展示我们方法的多功能性，我们将其应用于两个场景：基于物理的对象变形和远程呈现，其中化身使用混合形状进行控制。我们还进行了彻底的实验，表明我们的方法优于结合隐式变形的体积方法和基于网格变形的方法。
  - [基于神经辐射场和运动图的可控自由视点视频重建, IEEE Transactions on Visualization and Computer Graphics](https://ieeexplore.ieee.org/abstract/document/9845414) | [code]
    > 在本文中，我们提出了一种基于运动图和神经辐射场（NeRF）的可控高质量自由视点视频生成方法。与现有的姿势驱动 NeRF 或时间/结构条件的 NeRF 工作不同，我们建议首先构建捕获序列的有向运动图。这种序列-运动-参数化策略不仅能够灵活地控制自由视点视频渲染的姿态，而且避免了相似姿态的冗余计算，从而提高了整体重建效率。此外，为了支持身体形状控制而不损失逼真的自由视点渲染性能，我们通过结合显式表面变形和隐式神经场景表示来改进 vanilla NeRF。具体来说，我们为运动图上的每个有效帧训练一个局部表面引导的 NeRF，并且体积渲染仅在真实表面周围的局部空间中执行，从而实现了合理的形状控制能力。据我们所知，我们的方法是第一个同时支持逼真的自由视点视频重建和基于运动图的用户引导运动遍历的方法。结果和比较进一步证明了所提出方法的有效性。
  - [基于神经描述符字段的鲁棒变化检测, IROS2022](https://ieeexplore.ieee.org/abstract/document/9845414) | [code]
    > 推理环境变化的能力对于长时间运行的机器人至关重要。代理应在操作期间捕获更改，以便可以遵循操作以确保工作会话的顺利进行。然而，不同的视角和累积的定位误差使得机器人很容易由于低观察重叠和漂移的对象关联而错误地检测到周围世界的变化。在本文中，基于最近提出的类别级神经描述符字段 (NDF)，我们开发了一种对象级在线变化检测方法，该方法对部分重叠的观察和嘈杂的定位结果具有鲁棒性。利用 NDF 的形状补全能力和 SE(3) 等效性，我们表示具有紧凑形状代码的对象，该代码编码来自部分观察的完整对象形状。然后基于从 NDF 恢复的对象中心将对象组织在空间树结构中，以便快速查询对象邻域。通过形状代码相似性关联对象并比较局部对象-邻居空间布局，我们提出的方法证明了对低观测重叠和定位噪声的鲁棒性。我们对合成序列和真实世界序列进行了实验，与多种基线方法相比，实现了改进的变化检测结果。
## Jul24 - Jul30, 2022
  - [DoF-NeRF：景深与神经辐射场相遇, ACMMM2022](https://arxiv.org/pdf/2208.00945) | [***``[code]``***](https://github.com/zijinwuzijin/DoF-NeRF)
    > 神经辐射场 (NeRF) 及其变体在表示 3D 场景和合成逼真的新颖视图方面取得了巨大成功。但是，它们通常基于针孔相机模型并假设全焦点输入。这限制了它们的适用性，因为从现实世界捕获的图像通常具有有限的景深 (DoF)。为了缓解这个问题，我们引入了 DoF-NeRF，一种新颖的神经渲染方法，可以处理浅自由度输入并可以模拟自由度效果。特别是，它根据几何光学原理扩展了 NeRF 以模拟镜头的孔径。这样的物理保证允许 DoF-NeRF 操作具有不同焦点配置的视图。得益于显式光圈建模，DoF-NeRF 还可以通过调整虚拟光圈和焦点参数来直接操纵 DoF 效果。它是即插即用的，可以插入到基于 NeRF 的框架中。在合成数据集和真实世界数据集上的实验表明，DoF-NeRF 不仅在全焦点设置中的性能与 NeRF 相当，而且还可以合成以浅自由度输入为条件的全焦点新视图。还演示了 DoF-NeRF 在 DoF 渲染中的一个有趣应用。
  - [ZEPI-Net：通过内部跨尺度对极平面图像零样本学习的光场超分辨率, Neural Processing Letters (2022)](https://link.springer.com/article/10.1007/s11063-022-10955-x) | [code]
    > 光场 (LF) 成像的许多应用都受到空间角分辨率问题的限制，因此需要高效的超分辨率技术。最近，基于学习的解决方案比传统的超分辨率（SR）技术取得了显着更好的性能。不幸的是，学习或训练过程在很大程度上依赖于训练数据集，这对于大多数 LF 成像应用程序来说可能是有限的。在本文中，我们提出了一种基于零样本学习的新型 LF 空间角 SR 算法。我们建议在核平面图像 (EPI) 空间中学习跨尺度可重用特征，并避免显式建模场景先验或从大量 LF 中隐式学习。最重要的是，在不使用任何外部 LF 的情况下，所提出的算法可以同时在空间域和角域中超分辨 LF。此外，所提出的解决方案没有深度或视差估计，这通常由现有的 LF 空间和角度 SR 采用。通过使用一个简单的 8 层全卷积网络，我们表明所提出的算法可以产生与最先进的空间 SR 相当的结果。我们的算法在多组公共 LF 数据集上的角度 SR 方面优于现有方法。实验结果表明，跨尺度特征可以很好地学习并在 EPI 空间中用于 LF SR。
  - [ObjectFusion：具有神经对象先验的准确对象级 SLAM, Graphical Models, Volume 123, September 2022](https://www.sciencedirect.com/science/article/pii/S1524070322000418) | [code]
    > 以前的对象级同步定位和映射 (SLAM) 方法仍然无法以有效的方式创建高质量的面向对象的 3D 地图。主要挑战来自如何有效地表示对象形状以及如何将这种对象表示有效地应用于准确的在线相机跟踪。在本文中，我们提供 ObjectFusion 作为静态场景中的一种新颖的对象级 SLAM，它通过利用神经对象先验，有效地创建具有高质量对象重建的面向对象的 3D 地图。我们提出了一种仅具有单个编码器-解码器网络的神经对象表示，以有效地表达各种类别的对象形状，这有利于对象实例的高质量重建。更重要的是，我们建议将这种神经对象表示转换为精确测量，以共同优化对象形状、对象姿态和相机姿态，以实现最终准确的 3D 对象重建。通过对合成和真实世界 RGB-D 数据集的广泛评估，我们表明我们的 ObjectFusion 优于以前的方法，具有更好的对象重建质量，使用更少的内存占用，并且以更有效的方式，尤其是在对象级别。
  - [MobileNeRF：利用多边形光栅化管道在移动架构上进行高效的神经场渲染](https://arxiv.org/abs/2208.00277) | [***``[code]``***](https://github.com/google-research/jax3d/tree/main/jax3d/projects/mobilenerf)
    > 神经辐射场 (NeRFs) 展示了从新颖视图合成 3D 场景图像的惊人能力。但是，它们依赖于基于光线行进的专用体积渲染算法，这些算法与广泛部署的 g 的功能不匹配图形硬件。本文介绍了一种基于纹理多边形的新 NeRF 表示，它可以使用标准渲染管道有效地合成新图像。 NeRF 表示为一组多边形，其纹理表示二进制不透明度和特征向量。使用 z 缓冲区对多边形进行传统渲染会生成每个像素都有特征的图像，这些图像由在片段着色器中运行的小型、依赖于视图的 MLP 进行解释，以产生最终的像素颜色。这种方法使 NeRF 能够使用传统的多边形光栅化管道进行渲染，该管道提供大规模的像素级并行性，在包括手机在内的各种计算平台上实现交互式帧速率。
  - [神经密度-距离场, ECCV2022](https://arxiv.org/abs/2207.14455) | [***``[code]``***](https://ueda0319.github.io/neddf/)
    > 神经领域在 3D 视觉任务中的成功现在是无可争辩的。遵循这一趋势，已经提出了几种针对视觉定位的方法（例如，SLAM）来使用神经场估计距离或密度场。然而，仅通过基于密度场的方法（例如神经辐射场 (NeRF)）很难实现高定位性能，因为它们在大多数空白区域中不提供密度梯度。另一方面，基于距离场的方法，例如神经隐式表面 (NeuS)，在对象的表面形状方面存在局限性。本文提出了神经密度-距离场 (NeDDF)，这是一种新的 3D 表示，它相互约束距离和密度场。我们将距离场公式扩展到没有明确边界表面的形状，例如毛皮或烟雾，这使得从距离场到密度场的显式转换成为可能。通过显式转换实现的一致距离和密度场既能保证初始值的鲁棒性，又能实现高质量的配准。此外，场之间的一致性允许从稀疏点云快速收敛。实验表明，NeDDF 可以实现高定位性能，同时在新颖的视图合成上提供与 NeRF 相当的结果。该代码可在此 https URL 获得。
  - [通过 NeRF Attention 进行端到端视图合成](https://arxiv.org/abs/2207.14741) | [code]
    > 在本文中，我们提出了一个用于视图合成的简单 seq2seq 公式，其中我们将一组光线点作为输入和输出与光线相对应的颜色。在这个 seq2seq 公式上直接应用标准转换器有两个限制。首先，标准注意力不能成功地适应体积渲染过程，因此合成视图中缺少高频分量。其次，将全局注意力应用于所有光线和像素是非常低效的。受神经辐射场 (NeRF) 的启发，我们提出了 NeRF 注意力 (NeRFA) 来解决上述问题。一方面，NeRFA 将体积渲染方程视为软特征调制过程。通过这种方式，特征调制增强了具有类似 NeRF 电感偏置的变压器。另一方面，NeRFA 执行多阶段注意力以减少计算开销。此外，NeRFA 模型采用光线和像素转换器来学习光线和像素之间的相互作用。 NeRFA 在四个数据集上展示了优于 NeRF 和 NerFormer 的性能：DeepVoxels、Blender、LLFF 和 CO3D。此外，NeRFA 在两种设置下建立了新的 state-of-the-art：单场景视图合成和以类别为中心的新颖视图合成。该代码将公开发布。
  - [脱离网格：用于 3D 血管建模的连续隐式神经表示, MICCAI STACOM 2022](https://arxiv.org/abs/2207.14663) | [code]
    > 个性化 3D 血管模型对于心血管疾病患者的诊断、预后和治疗计划非常有价值。传统上，此类模型是用网格和体素掩码等显式表示或径向基函数或原子（管状）形状等隐式表示构建的。在这里，我们建议在可微的隐式神经表示 (INR) 中通过其有符号距离函数 (SDF) 的零水平集来表示表面。这使我们能够用隐式、连续、轻量级且易于与深度学习算法集成的表示来对复杂的血管结构进行建模。我们在这里通过三个实际示例展示了这种方法的潜力。首先，我们从 CT 图像中获得了腹主动脉瘤 (AAA) 的准确且防水的表面，并从表面上的 200 个点显示出稳健的拟合。其次，我们同时将嵌套的血管壁安装在单个 INR 中，没有交叉点。第三，我们展示了如何将单个动脉的 3D 模型平滑地融合到单个防水表面中。我们的结果表明，INR 是一种灵活的表示形式，具有最小交互注释的潜力复杂血管结构的研究和操作。
  - [神经链：从多视图图像中学习头发的几何形状和外观, ECCV2022](https://arxiv.org/pdf/2207.14067) | [***``[code]``***](https://radualexandru.github.io/neural_strands/)
    > 我们提出了 Neural Strands，这是一种新颖的学习框架，用于从多视图图像输入中对精确的头发几何形状和外观进行建模。学习的头发模型可以从具有高保真视图相关效果的任何视点实时渲染。与体积模型不同，我们的模型实现了直观的形状和样式控制。为了实现这些特性，我们提出了一种基于神经头皮纹理的新型头发表示，该神经头皮纹理对每个纹素位置的单个股线的几何形状和外观进行编码。此外，我们引入了一种基于学习发束光栅化的新型神经渲染框架。我们的神经渲染是精确的和抗锯齿的，使渲染视图一致且逼真。将外观与多视图几何先验相结合，我们首次实现了从多视图设置中联合学习外观和显式头发几何形状。我们展示了我们的方法在各种发型的保真度和效率方面的有效性。
  - [具有全局照明的可重新照明的新视图合成的神经辐射转移场](https://arxiv.org/abs/2207.13607) | [code]
    > 给定场景的一组图像，从新颖的视图和光照条件重新渲染该场景是计算机视觉和图形学中一个重要且具有挑战性的问题。一方面，计算机视觉中的大多数现有作品通常对图像形成过程施加许多假设，例如直接照明和预定义的材料，使场景参数估计易于处理。另一方面，成熟的计算机图形学工具允许在给定所有场景参数的情况下对复杂的照片般逼真的光传输进行建模。结合这些方法，我们提出了一种通过学习神经预计算辐射传递函数来在新视图下重新点亮场景的方法，该函数使用新的环境图隐式处理全局光照效果。我们的方法可以在单一未知照明条件下对一组场景的真实图像进行单独监督。为了在训练期间消除任务的歧义，我们在训练过程中紧密集成了一个可微的路径跟踪器，并提出了合成 OLAT 和真实图像损失的组合。结果表明，与当前技术水平相比，场景参数的恢复解缠结得到了显着改善，因此，我们的重新渲染结果也更加真实和准确。
  - [ShAPO：多对象形状、外观和姿势优化的隐式表示, ECCV2022](https://arxiv.org/abs/2207.13691) | [***``[code]``***](https://zubair-irshad.github.io/projects/ShAPO.html)
    > 我们的方法从单个 RGB-D 观察中研究以对象为中心的 3D 理解的复杂任务。由于这是一个不适定问题，现有方法在具有遮挡的复杂多对象场景中的 3D 形状和 6D 姿势和尺寸估计性能低下。我们提出了 ShaAPO，一种用于联合多对象检测、3D 纹理重建、6D 对象姿态和大小估计的方法。 ShAPO 的关键是一个单次管道，用于回归形状、外观和姿势潜在代码以及每个对象实例的掩码，然后以稀疏到密集的方式进一步细化。首先学习了一种新的解开的先验形状和外观数据库，以将对象嵌入到它们各自的形状和外观空间中。我们还提出了一种新颖的、基于八叉树的可微优化步骤，使我们能够以综合分析的方式在学习的潜在空间下同时进一步改进对象形状、姿势和外观。我们新颖的联合隐式纹理对象表示使我们能够准确地识别和重建新的看不见的对象，而无需访问它们的 3D 网格。通过广泛的实验，我们证明了我们的方法在模拟室内场景上进行训练，能够以最少的微调准确地回归现实世界中新物体的形状、外观和姿势。我们的方法显着优于 NOCS 数据集上的所有基线，6D 姿态估计的 mAP 绝对提高了 8%。
  - [GAUDI：沉浸式 3D 场景生成的神经架构师](https://arxiv.org/abs/2207.13751) | [***``[code]``***](https://github.com/apple/ml-gaudi)
    > 我们介绍了 GAUDI，这是一种生成模型，能够捕捉复杂而逼真的 3D 场景的分布，可以从移动的相机中沉浸式地渲染。我们用一种可扩展但功能强大的方法来解决这个具有挑战性的问题，我们首先优化一个潜在的表示，以解开辐射场和相机姿势。然后使用这种潜在表示来学习生成模型，该模型可以无条件和有条件地生成 3D 场景.我们的模型通过消除相机姿态分布可以跨样本共享的假设来概括以前专注于单个对象的工作。我们展示了 GAUDI 在跨多个数据集的无条件生成设置中获得了最先进的性能，并允许在给定条件变量（如稀疏图像观察或描述场景的文本）的情况下有条件地生成 3D 场景。
  - [AlignSDF：用于手对象重建的姿势对齐有符号距离场, ECCV2022](https://arxiv.org/abs/2207.12909) | [***``[code]``***](https://zerchen.github.io/projects/alignsdf.html)
    > 最近的工作在从单目彩色图像联合重建手和操纵对象方面取得了令人瞩目的进展。现有方法侧重于参数网格或符号距离场 (SDF) 方面的两种替代表示。一方面，参数模型可以从先验知识中受益，但代价是有限的形状变形和网格分辨率。因此，网格模型可能无法精确重建细节，例如手和物体的接触面。另一方面，基于 SDF 的方法可以表示任意细节，但缺乏明确的先验。在这项工作中，我们的目标是使用参数表示提供的先验改进 SDF 模型。特别是，我们提出了一个联合学习框架，可以解开姿势和形状。我们从参数模型中获取手和物体的姿势，并使用它们在 3D 空间中对齐 SDF。我们表明，这种对齐的 SDF 更好地专注于重建形状细节并提高手和物体的重建精度。我们评估了我们的方法，并在具有挑战性的 ObMan 和 DexYCB 基准上展示了对现有技术的显着改进。
  - [拉普拉斯系统的神经格林函数, Computer & Graphics](https://www.sciencedirect.com/science/article/pii/S0097849322001406) | [code]
    > 求解源自拉普拉斯算子的线性方程组是广泛应用的核心。由于线性系统的稀疏性，当解具有大量自由度时，通常采用迭代求解器，例如共轭梯度和多重网格。这些迭代求解器可以看作是拉普拉斯算子格林函数的稀疏近似。在本文中，我们提出了一种机器学习方法，该方法从边界条件中回归格林函数。这是通过格林函数实现的，该函数可以以多尺度方式有效地表示，从而大大降低了与密集矩阵表示相关的成本。此外，由于格林函数完全依赖于边界条件，因此训练所提出的神经网络不需要对线性系统的右侧进行采样。结果表明，我们的方法优于最先进的共轭梯度和多重网格方法。
  - [用笼子变形辐射场, ECCV2022](https://arxiv.org/abs/2207.12298) | [code]
    > 辐射场的最新进展可以实现静态或动态 3D 场景的逼真渲染，但仍不支持用于场景操作或动画的显式变形。在本文中，我们提出了一种新的辐射场变形方法：自由形式的辐射场变形。我们使用一个三角形网格来包围称为笼子的前景对象作为界面，通过操纵笼子顶点，我们的方法可以实现辐射场的自由变形。我们方法的核心是网格变形中常用的基于笼的变形。我们提出了一种将其扩展到辐射场的新公式，该公式将采样点的位置和视图方向从变形空间映射到规范空间，从而实现变形场景的渲染。合成数据集和真实世界数据集的变形结果证明了我们方法的有效性。
  - [NeuMesh：学习基于解缠结神经网格的隐式场，用于几何和纹理编辑, ECCV2022 (Oral)](https://arxiv.org/abs/2207.11911) | [code]
    > 最近，神经隐式渲染技术得到了迅速发展，并在新颖的视图合成和 3D 场景重建中显示出巨大的优势。然而，现有的用于编辑目的的神经渲染方法提供的功能有限，例如，刚性变换，或者不适用于日常生活中一般对象的细粒度编辑。在本文中，我们提出了一种新颖的基于网格的表示，通过在网格顶点上使用解开几何和纹理代码对神经隐场进行编码，这促进了一组编辑功能，包括网格引导的几何编辑、带有纹理交换的指定纹理编辑、填充和绘画操作。为此，我们开发了几种技术包括可学习的符号指标以放大基于网格的表示的空间可区分性，蒸馏和微调机制以实现稳定收敛，以及空间感知优化策略以实现精确的纹理编辑。对真实数据和合成数据的大量实验和编辑示例证明了我们的方法在表示质量和编辑能力方面的优越性。代码可在项目网页上找到：此 https URL。
  - [关于物理概念的可学习性：神经网络能理解什么是真](https://arxiv.org/abs/2207.12186) | [code]
    > 鉴于深度神经网络生成逼真的合成数据的卓越能力，我们重新审视了经典的信号到符号障碍。 DeepFakes 和欺骗突出了物理现实与其抽象表示之间联系的脆弱性，无论是由数字计算机还是生物代理学习。从一个广泛适用的抽象概念定义开始，我们表明标准的前馈架构只能捕获微不足道的概念，无论权重的数量和训练数据的数量如何，尽管它们是非常有效的分类器。另一方面，包含递归的架构可以代表更大的概念类别，但可能仍然无法从有限的数据集中学习它们。我们定性地描述了可以被用随机梯度下降变体训练的现代架构“理解”的概念类别，使用（自由能）拉格朗日来测量信息复杂性。然而，即使一个概念已经被理解，网络也无法将其理解传达给外部代理，除非通过持续的交互和验证。然后，我们将物理对象表征为抽象概念，并使用前面的分析来表明物理对象可以由有限架构编码。然而，为了理解物理概念，传感器必须提供持续令人兴奋的观察，而控制数据采集过程的能力是必不可少的（主动感知）。控制的重要性取决于形式，比听觉或化学感知更有益于视觉。最后，我们得出结论，可以在有限的时间内用有限的资源将物理实体绑定到数字身份，原则上解决了信号到符号的障碍问题，但我们强调了持续验证的必要性。
## 旧论文
参考这个仓库： [awesome-NeRF](https://github.com/yenchenlin/awesome-NeRF).
