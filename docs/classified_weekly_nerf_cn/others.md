
每周分类神经辐射场 - others ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
===================================================================================================================================
## 按类别筛选: 
 [全部](../weekly_nerf_cn.md) | [动态](./dynamic.md) | [编辑](./editing.md) | [快速](./fast.md) | [泛化](./generalization.md) | [人体](./human.md) | [视频](./video.md) | [光照](./lighting.md) | [重建](./reconstruction.md) | [纹理](./texture.md) | [语义](./semantic.md) | [姿态-SLAM](./pose-slam.md) | [其他](./others.md) 
## Sep18 - Sep24, 2022
  - [wildNeRF：使用稀疏单目数据捕获的野外动态场景的完整视图合成](https://arxiv.org/abs/2209.10399) | [code]
    > 我们提出了一种新的神经辐射模型，该模型可以以自我监督的方式进行训练，用于动态非结构化场景的新视图合成。我们的端到端可训练算法可在几秒钟内学习高度复杂的真实静态场景，并在几分钟内学习具有刚性和非刚性运动的动态场景。通过区分静态像素和以运动为中心的像素，我们从一组稀疏的图像中创建高质量的表示。我们对现有基准进行了广泛的定性和定量评估，并在具有挑战性的 NVIDIA 动态场景数据集上设置了最先进的性能指标。此外，我们在具有挑战性的现实世界数据集（例如 Cholec80 和 SurgicalActions160）上评估我们的模型性能。
  - [密度感知 NeRF 集成：量化神经辐射场中的预测不确定性](https://arxiv.org/abs/2209.08718) | [code]
    > 我们表明，如果考虑到密度感知认知不确定性项，则集成有效地量化了神经辐射场 (NeRFs) 中的模型不确定性。在先前的工作中研究的朴素集成只是简单地平均渲染的 RGB 图像，以量化由观察到的场景的相互矛盾的解释引起的模型不确定性。相比之下，由于缺乏关于训练期间未观察到的场景部分的知识，我们还考虑了沿单个射线的终止概率来识别认知模型的不确定性。我们在已建立的 NeRF 不确定性量化基准中实现了新的最先进的性能，优于需要对 NeRF 架构和训练机制进行复杂更改的方法。我们进一步证明了 NeRF 不确定性可用于次佳视图选择和模型细化。
  - [LATITUDE：在城市规模的 NeRF 中使用截断动态低通滤波器进行机器人全局定位, ICRA2023](https://arxiv.org/abs/2209.08498) | [***``[code]``***](https://github.com/jike5/LATITUDE)
    > 神经辐射场 (NeRFs) 在表示具有高分辨率细节和高效内存的复杂 3D 场景方面取得了巨大成功。然而，当前基于 NeRF 的姿态估计器没有初始姿态预测，并且在优化过程中容易出现局部最优。在本文中，我们提出了 LATITUDE：使用截断动态低通滤波器进行全局定位，它在城市规模的 NeRF 中引入了两阶段定位机制。在位置识别阶段，我们通过训练后的 NeRF 生成的图像训练回归器，为全局定位提供初始值。在姿态优化阶段，我们通过直接优化切平面上的姿态来最小化观察图像和渲染图像之间的残差。为了避免收敛到局部最优，我们引入了截断动态低通滤波器 (TDLF) 用于从粗到细的姿态配准。我们在合成数据和真实世界数据上评估我们的方法，并展示其在大规模城市场景中高精度导航的潜在应用。代码和数据将在此 https 网址上公开提供。
  - [医学影像分割的隐式神经表示, MICCAI2022](https://link.springer.com/chapter/10.1007/978-3-031-16443-9_42) | [code]
    > 医学成像中的 3D 信号（例如 CT 扫描）通常被参数化为体素的离散网格。例如，现有的最先进的器官分割方法学习离散的分割图。不幸的是，这些方法的内存需求随着空间分辨率的增加而呈立方增长，这使得它们不适合处理高分辨率扫描。为了克服这个问题，我们设计了一个隐式器官分割网络 (IOSNet)，它利用连续的隐式神经表示并具有几个有用的属性。首先，IOSNet 解码器内存大致恒定且独立于空间分辨率，因为它将分割图参数化为连续函数。其次，IOSNet 的收敛速度比基于离散体素的方法快得多，因为它能够准确地分割器官而不受器官大小的影响，从而在不需要任何辅助技巧的情况下缓解大小不平衡问题。第三，由于其连续学习表示，IOSNet 自然支持超分辨率（即在推理过程中以任意分辨率采样）。此外，尽管使用了一个简单的轻量级解码器，IOSNet 始终优于离散专业分割架构 UNet。因此，我们的方法表明隐式神经表示非常适合医学成像应用，尤其是处理高分辨率 3D 医学扫描。
## Sep11 - Sep17, 2022
  - [DevNet：通过密度体积构建的自监督单目深度学习, ECCV2022](https://arxiv.org/abs/2209.06351) | [code]
    > 单目图像的自监督深度学习通常依赖于时间相邻图像帧之间的 2D 像素级光度关系。然而，它们既没有充分利用 3D 逐点几何对应，也没有有效地解决由遮挡或照明不一致引起的光度翘曲的模糊性。为了解决这些问题，这项工作提出了密度体积构建网络 (DevNet)，这是一种新颖的自我监督单目深度学习框架，可以考虑 3D 空间信息，并利用相邻相机平截头体之间更强的几何约束。我们的 DevNet 不是直接从单个图像中回归像素值，而是将相机平截头体划分为多个平行平面，并预测每个平面上的逐点遮挡概率密度。最终的深度图是通过沿相应光线对密度进行积分来生成的。在训练过程中，引入了新的正则化策略和损失函数来减轻光度模糊和过拟合。在没有明显扩大模型参数大小或运行时间的情况下，DevNet 在 KITTI-2015 室外数据集和 NYU-V2 室内数据集上都优于几个具有代表性的基线。特别是，在深度估计任务中，KITTI-2015 和 NYU-V2 上的 DevNet 的均方根偏差降低了约 4%。此 https 网址提供了代码。
  - [学习用于视图合成的统一 3D 点云](https://arxiv.org/abs/2209.05013) | [code]
    > 基于 3D 点云表示的视图合成方法已证明是有效的。然而，现有方法通常仅从单个源视图合成新视图，并且将它们泛化以处理多个源视图以追求更高的重建质量并非易事。在本文中，我们提出了一种新的基于深度学习的视图合成范式，它从不同的源视图中学习统一的 3D 点云。具体来说，我们首先通过根据深度图将源视图投影到 3D 空间来构建子点云。然后，我们通过自适应融合子点云联合上定义的局部邻域中的点来学习统一的 3D 点云。此外，我们还提出了一个 3D 几何引导图像恢复模块来填充孔洞并恢复渲染新视图的高频细节。三个基准数据集的实验结果表明，我们的方法在数量上和视觉上都在很大程度上优于最先进的视图合成方法。
  - [用于稀疏视图计算机断层扫描的自监督坐标投影网络](https://arxiv.org/abs/2209.05483) | [code]
    > 在目前的工作中，我们提出了一种自监督坐标投影网络（SCOPE），通过解决逆断层扫描成像问题，从单个 SV 正弦图重建无伪影的 CT 图像。与最近使用隐式神经表示网络 (INR) 解决类似问题的相关工作相比，我们的重要贡献是一种有效且简单的重投影策略，该策略将断层扫描图像重建质量提高到有监督的深度学习 CT 重建工作之上。所提出的策略受到线性代数和逆问题之间简单关系的启发。为了求解欠定线性方程组，我们首先引入INR，通过图像连续性先验来约束解空间并获得粗解。其次，我们建议生成密集视图正弦图，提高线性方程组的秩并产生更稳定的 CT 图像解空间。我们的实验结果表明，重投影策略显着提高了图像重建质量（PSNR 至少 +3 dB）。此外，我们将最近的哈希编码集成到我们的 SCOPE 模型中，这极大地加速了模型训练。最后，我们在并行和扇形 X 射线束 SVCT 重建任务中评估 SCOPE。实验结果表明，所提出的 SCOPE 模型在数量和质量上都优于两种最新的基于 INR 的方法和两种流行的监督 DL 方法。
  - [CU-Net：高效的点云颜色上采样网络](https://arxiv.org/abs/2209.06112) | [code]
    > 增强现实、虚拟现实和远程呈现场景需要点云上采样。尽管几何上采样被很好地研究以致密点云坐标，但颜色的上采样在很大程度上被忽略了。在本文中，我们提出了第一个深度学习点云颜色上采样模型 CU-Net。利用基于稀疏卷积的特征提取器和基于神经隐函数的颜色预测模块，CU-Net 实现了线性时间和空间复杂度。因此，理论上保证 CU-Net 比大多数具有二次复杂度的现有方法更有效。实验结果表明，CU-Net 可以实时为具有近百万个点的照片般逼真的点云着色，同时具有比基线更好的视觉质量。此外，CU-Net 可以适应任意的上采样率和看不见的对象。我们的源代码将很快向公众发布。
## Previous weeks
  - [城市辐射场, CVPR2022](https://urban-radiance-fields.github.io/) | [code]
    > 这项工作的目标是从扫描平台捕获的数据中执行 3D 重建和新颖的视图合成，这些平台通常用于城市户外环境（例如街景）中的世界地图绘制。给定一系列由相机和扫描仪在户外场景中移动获得的 RGB 图像序列和激光雷达扫描，我们生成了一个模型，可以从中提取 3D 表面并合成新的 RGB 图像。我们的方法扩展了神经辐射场，该方法已被证明可以在受控环境中为小场景合成逼真的新颖图像，以及利用异步捕获的激光雷达数据、解决捕获图像之间的曝光变化以及利用预测的图像分割来监督密度的新方法在指向天空的光线上。这三个扩展中的每一个都在街景数据的实验中提供了显着的性能改进。与传统方法（例如~COLMAP）和最近的神经表示（例如~Mip-NeRF）相比，我们的系统产生最先进的 3D 表面重建并合成更高质量的新视图。
## Sep4 - Sep10, 2022
  - [具有深度神经表示的隐式全波形反演](https://arxiv.org/abs/2209.03525) | [code]
    > 全波形反演（FWI）通常代表最先进的地下结构和物理参数成像方法，然而，其实施通常面临巨大挑战，例如建立一个良好的初始模型以摆脱局部最小值，以及评估反演结果的不确定性。在本文中，我们提出了使用连续和隐式定义的深度神经表示的隐式全波形反演（IFWI）算法。与对初始模型敏感的 FWI 相比，IFWI 受益于深度学习优化增加的自由度，从而允许从随机初始化开始，这大大降低了非唯一性和陷入局部最小值的风险。理论和实验分析均表明，在给定随机初始模型的情况下，IFWI 能够收敛到全局最小值，并生成具有精细结构的地下高分辨率图像。此外，IFWI 的不确定性分析可以很容易地通过使用各种深度学习方法近似贝叶斯推理来执行，本文通过添加 dropout 神经元对其进行分析。此外，IFWI具有一定的鲁棒性和较强的泛化能力，在各种二维地质模型的实验中得到了体现。通过适当的设置，IFWI也可以很好地适用于多尺度联合地球物理反演。
## Aug28 - Sep3, 2022
  - [FoV-NeRF：虚拟现实的中心凹神经辐射场, TVCG2022](https://ieeexplore.ieee.org/abstract/document/9872532) | [code]
    > 随着消费者显示器和商业 VR 平台的兴起，虚拟现实 (VR) 正变得无处不在。这种显示需要低延迟和高质量的合成图像渲染，同时减少计算开销。神经渲染的最新进展表明，有望通过基于图像的虚拟或物理环境表示来解锁 3D 计算机图形的新可能性。具体来说，神经辐射场 (NeRF) 表明，可以在不损失与视图相关的效果的情况下实现 3D 场景的照片般逼真的质量和连续视图变化。虽然 NeRF 可以显着受益于 VR 应用的渲染，但它面临着由高视场、高分辨率和立体/以自我为中心的观看带来的独特挑战，通常会导致渲染图像的低质量和高延迟。在 VR 中，这不仅会损害交互体验，还可能导致疾病。为了解决 VR 中的六自由度、以自我为中心和立体 NeRF 的这些问题，我们提出了第一个注视条件 3D 神经表示和视图合成方法。我们将视觉和立体敏锐度的人类心理物理学纳入 3D 风景的以自我为中心的神经表示中。然后，我们共同优化延迟/性能和视觉质量，同时相互桥接人类感知和神经场景合成，以实现感知上高质量的沉浸式交互。我们进行了客观分析和主观研究，以评估我们方法的有效性。我们发现我们的方法显着减少了延迟（与 NeRF 相比减少了高达 99% 的时间），而不会损失高保真渲染（在感知上与全分辨率地面实况相同）。所提出的方法可能是迈向未来实时捕捉、传送和可视化远程环境的 VR/AR 系统的第一步。
  - [克隆：用于占用网格辅助神经表示的相机-激光雷达融合](https://arxiv.org/abs/2209.01194) | [code]
    > 本文提出了 CLONeR，它通过允许对从稀疏输入传感器视图观察到的大型户外驾驶场景进行建模，显着改进了 NeRF。这是通过将 NeRF 框架内的占用和颜色学习解耦为分别使用 LiDAR 和相机数据训练的单独的多层感知器 (MLP) 来实现的。此外，本文提出了一种在 NeRF 模型旁边构建可微分 3D 占用网格图 (OGM) 的新方法，并利用此占用网格改进沿射线的点采样，以在度量空间中进行体积渲染。
## Aug21 - Aug27, 2022
## Previous weeks
  - [﻿Plenoxels：没有神经网络的辐射场, CVPR2022(oral)](https://arxiv.org/abs/2112.05131) | [***``[code]``***](https://alexyu.net/plenoxels)
    > 我们介绍了 Plenoxels（全光体素），一种用于照片级真实视图合成的系统。 Plenoxels 将场景表示为具有球谐函数的稀疏 3D 网格。这种表示可以通过梯度方法和正则化从校准图像中优化，而无需任何神经组件。在标准的基准任务中，Plenoxels 的优化速度比神经辐射场快两个数量级，而视觉质量没有损失。
## Aug21 - Aug27, 2022
## Aug14 - Aug20, 2022
## Aug7 - Aug13, 2022
  - [HyperTime：时间序列的隐式神经表示](https://arxiv.org/abs/2208.05836) | [code]
    > 隐式神经表示 (INR) 最近已成为一种强大的工具，可提供准确且与分辨率无关的数据编码。它们作为通用逼近器的鲁棒性已在各种数据源中得到证明，并应用于图像、声音和 3D 场景表示。然而，很少有人关注利用这些架构来表示和分析时间序列数据。在本文中，我们使用 INR 分析时间序列的表示，比较不同的激活函数在重建精度和训练收敛速度方面。我们展示了如何利用这些网络对时间序列进行插补，以及在单变量和多变量数据上的应用。最后，我们提出了一种利用 INR 来学习整个时间序列数据集的压缩潜在表示的超网络架构。我们引入了基于 FFT 的损失来指导训练，以便在时间序列中保留所有频率。我们展示了该网络可用于将时间序列编码为 INR，并且可以对它们的嵌入进行插值以从现有的时间序列中生成新的时间序列。我们通过将其用于数据增强来评估我们的生成方法，并表明它与当前最先进的时间序列增强方法具有竞争力。
  - [NIDN：纳米结构的神经逆向设计](https://arxiv.org/abs/2208.05480) | [code]
    > 近十年来，计算工具已成为材料设计的核心，以降低成本实现快速开发周期。机器学习工具在光子学领域尤其兴起。然而，从优化的角度来看，设计所需的麦克斯韦方程的反演特别具有挑战性，需要复杂的软件。我们提出了一种创新的开源软件工具，称为纳米结构的神经逆向设计 (NIDN)，它允许使用基于物理的深度学习方法设计复杂的堆叠材料纳米结构。我们执行基于梯度的神经网络训练，而不是无导数或数据驱动的优化或学习方法，在这种训练中，我们根据其光谱特性直接优化材料及其结构。 NIDN 支持两种不同的求解器，严格的耦合波分析和有限差分时域方法。 NIDN 的实用性和有效性在几个合成示例以及 1550 nm 滤光片和抗反射涂层的设计中得到了证明。结果与实验基线、其他模拟工具和所需的光谱特性相匹配。鉴于其在网络架构和 Maxwell 求解器方面的完全模块化以及开源、许可的可用性，NIDN 将能够支持广泛应用中的计算材料设计过程。
  - [使用隐式神经表示的蒙特卡罗去噪](https://oaktrust.library.tamu.edu/handle/1969.1/196567) | [code]
    > Monte Carlo 路径追踪是计算机图形学中流行的 3D 渲染技术，但它通常需要在图像中的噪声量和计算时间之间进行代价高昂的权衡。因此，尝试“平滑”噪声图像是有用的，通常通过在样本之间构建新数据或对图像应用过滤器。在这项工作中，我们研究了训练神经网络以将固定视点场景的亮度隐式表示为连续函数的可行性。我们使用多层感知器网络实现神经网络，并在由离线 Monte Carlo 渲染器生成的稀疏采样图像上对其进行训练。该训练数据使用图像平面上每个样本的 (x, y) 坐标作为输入，并将样本的 RGB 颜色作为输出。此外，我们为网络提供第一条光线交点的表面法线、深度和反照率，作为像素坐标旁边的额外输入。这些额外的输入维度通过帮助网络考虑深度、法线和漫反射颜色的变化来提高隐式表示的质量。一旦网络在稀疏采样的场景上得到训练，我们就可以对每个像素的网络进行多次密集采样，以创建最终的去噪图像。我们发现该网络可以在具有柔和照明和光泽反射的场景中快速学习和去噪图像，并且只需少量训练即可轻松处理深度、正常和漫反射颜色的不连续性。
## Jul31 - Aug6, 2022
## Jul24 - Jul30, 2022
  - [DoF-NeRF：景深与神经辐射场相遇, ACMMM2022](https://arxiv.org/pdf/2208.00945) | [***``[code]``***](https://github.com/zijinwuzijin/DoF-NeRF)
    > 神经辐射场 (NeRF) 及其变体在表示 3D 场景和合成逼真的新颖视图方面取得了巨大成功。但是，它们通常基于针孔相机模型并假设全焦点输入。这限制了它们的适用性，因为从现实世界捕获的图像通常具有有限的景深 (DoF)。为了缓解这个问题，我们引入了 DoF-NeRF，一种新颖的神经渲染方法，可以处理浅自由度输入并可以模拟自由度效果。特别是，它根据几何光学原理扩展了 NeRF 以模拟镜头的孔径。这样的物理保证允许 DoF-NeRF 操作具有不同焦点配置的视图。得益于显式光圈建模，DoF-NeRF 还可以通过调整虚拟光圈和焦点参数来直接操纵 DoF 效果。它是即插即用的，可以插入到基于 NeRF 的框架中。在合成数据集和真实世界数据集上的实验表明，DoF-NeRF 不仅在全焦点设置中的性能与 NeRF 相当，而且还可以合成以浅自由度输入为条件的全焦点新视图。还演示了 DoF-NeRF 在 DoF 渲染中的一个有趣应用。
  - [神经密度-距离场, ECCV2022](https://arxiv.org/abs/2207.14455) | [***``[code]``***](https://ueda0319.github.io/neddf/)
    > 神经领域在 3D 视觉任务中的成功现在是无可争辩的。遵循这一趋势，已经提出了几种针对视觉定位的方法（例如，SLAM）来使用神经场估计距离或密度场。然而，仅通过基于密度场的方法（例如神经辐射场 (NeRF)）很难实现高定位性能，因为它们在大多数空白区域中不提供密度梯度。另一方面，基于距离场的方法，例如神经隐式表面 (NeuS)，在对象的表面形状方面存在局限性。本文提出了神经密度-距离场 (NeDDF)，这是一种新的 3D 表示，它相互约束距离和密度场。我们将距离场公式扩展到没有明确边界表面的形状，例如毛皮或烟雾，这使得从距离场到密度场的显式转换成为可能。通过显式转换实现的一致距离和密度场既能保证初始值的鲁棒性，又能实现高质量的配准。此外，场之间的一致性允许从稀疏点云快速收敛。实验表明，NeDDF 可以实现高定位性能，同时在新颖的视图合成上提供与 NeRF 相当的结果。该代码可在此 https URL 获得。
  - [通过 NeRF Attention 进行端到端视图合成](https://arxiv.org/abs/2207.14741) | [code]
    > 在本文中，我们提出了一个用于视图合成的简单 seq2seq 公式，其中我们将一组光线点作为输入和输出与光线相对应的颜色。在这个 seq2seq 公式上直接应用标准转换器有两个限制。首先，标准注意力不能成功地适应体积渲染过程，因此合成视图中缺少高频分量。其次，将全局注意力应用于所有光线和像素是非常低效的。受神经辐射场 (NeRF) 的启发，我们提出了 NeRF 注意力 (NeRFA) 来解决上述问题。一方面，NeRFA 将体积渲染方程视为软特征调制过程。通过这种方式，特征调制增强了具有类似 NeRF 电感偏置的变压器。另一方面，NeRFA 执行多阶段注意力以减少计算开销。此外，NeRFA 模型采用光线和像素转换器来学习光线和像素之间的相互作用。 NeRFA 在四个数据集上展示了优于 NeRF 和 NerFormer 的性能：DeepVoxels、Blender、LLFF 和 CO3D。此外，NeRFA 在两种设置下建立了新的 state-of-the-art：单场景视图合成和以类别为中心的新颖视图合成。该代码将公开发布。
  - [神经链：从多视图图像中学习头发的几何形状和外观, ECCV2022](https://arxiv.org/pdf/2207.14067) | [***``[code]``***](https://radualexandru.github.io/neural_strands/)
    > 我们提出了 Neural Strands，这是一种新颖的学习框架，用于从多视图图像输入中对精确的头发几何形状和外观进行建模。学习的头发模型可以从具有高保真视图相关效果的任何视点实时渲染。与体积模型不同，我们的模型实现了直观的形状和样式控制。为了实现这些特性，我们提出了一种基于神经头皮纹理的新型头发表示，该神经头皮纹理对每个纹素位置的单个股线的几何形状和外观进行编码。此外，我们引入了一种基于学习发束光栅化的新型神经渲染框架。我们的神经渲染是精确的和抗锯齿的，使渲染视图一致且逼真。将外观与多视图几何先验相结合，我们首次实现了从多视图设置中联合学习外观和显式头发几何形状。我们展示了我们的方法在各种发型的保真度和效率方面的有效性。
  - [拉普拉斯系统的神经格林函数, Computer & Graphics](https://www.sciencedirect.com/science/article/pii/S0097849322001406) | [code]
    > 求解源自拉普拉斯算子的线性方程组是广泛应用的核心。由于线性系统的稀疏性，当解具有大量自由度时，通常采用迭代求解器，例如共轭梯度和多重网格。这些迭代求解器可以看作是拉普拉斯算子格林函数的稀疏近似。在本文中，我们提出了一种机器学习方法，该方法从边界条件中回归格林函数。这是通过格林函数实现的，该函数可以以多尺度方式有效地表示，从而大大降低了与密集矩阵表示相关的成本。此外，由于格林函数完全依赖于边界条件，因此训练所提出的神经网络不需要对线性系统的右侧进行采样。结果表明，我们的方法优于最先进的共轭梯度和多重网格方法。
  - [关于物理概念的可学习性：神经网络能理解什么是真](https://arxiv.org/abs/2207.12186) | [code]
    > 鉴于深度神经网络生成逼真的合成数据的卓越能力，我们重新审视了经典的信号到符号障碍。 DeepFakes 和欺骗突出了物理现实与其抽象表示之间联系的脆弱性，无论是由数字计算机还是生物代理学习。从一个广泛适用的抽象概念定义开始，我们表明标准的前馈架构只能捕获微不足道的概念，无论权重的数量和训练数据的数量如何，尽管它们是非常有效的分类器。另一方面，包含递归的架构可以代表更大的概念类别，但可能仍然无法从有限的数据集中学习它们。我们定性地描述了可以被用随机梯度下降变体训练的现代架构“理解”的概念类别，使用（自由能）拉格朗日来测量信息复杂性。然而，即使一个概念已经被理解，网络也无法将其理解传达给外部代理，除非通过持续的交互和验证。然后，我们将物理对象表征为抽象概念，并使用前面的分析来表明物理对象可以由有限架构编码。然而，为了理解物理概念，传感器必须提供持续令人兴奋的观察，而控制数据采集过程的能力是必不可少的（主动感知）。控制的重要性取决于形式，比听觉或化学感知更有益于视觉。最后，我们得出结论，可以在有限的时间内用有限的资源将物理实体绑定到数字身份，原则上解决了信号到符号的障碍问题，但我们强调了持续验证的必要性。
## Previous weeks
  - [NeRF：将场景表示为用于视图合成的神经辐射场, ECCV2020](https://arxiv.org/abs/2003.08934) | [***``[code]``***](http://tancik.com/nerf)
    > 我们提出了一种方法，该方法通过使用稀疏输入视图集优化底层连续体积场景函数，实现了合成复杂场景的新视图的最新结果。我们的算法使用全连接（非卷积）深度网络表示场景，其输入是单个连续 5D 坐标（空间位置（x,y,z）和观察方向（θ,φ）），其输出是该空间位置的体积密度和与视图相关的发射辐射。我们通过沿相机光线查询 5D 坐标来合成视图，并使用经典的体渲染技术将输出颜色和密度投影到图像中。因为体积渲染是自然可微的，所以优化我们的表示所需的唯一输入是一组具有已知相机姿势的图像。我们描述了如何有效地优化神经辐射场以渲染具有复杂几何形状和外观的场景的逼真的新颖视图，并展示了优于先前在神经渲染和视图合成方面的工作的结果。查看合成结果最好以视频形式观看，因此我们敦促读者观看我们的补充视频以进行令人信服的比较。
  - [野外的 NeRF：无约束照片集的神经辐射场, CVPR2021](https://arxiv.org/abs/2008.02268) | [code]
    > 我们提出了一种基于学习的方法，用于仅使用野外照片的非结构化集合来合成复杂场景的新视图。我们建立在神经辐射场 (NeRF) 的基础上，它使用多层感知器的权重将场景的密度和颜色建模为 3D 坐标的函数。虽然 NeRF 在受控设置下捕获的静态对象的图像上效果很好，但它无法在不受控的图像中模拟许多普遍存在的真实世界现象，例如可变照明或瞬态遮挡物。我们为 NeRF 引入了一系列扩展来解决这些问题，从而能够从互联网上获取的非结构化图像集合中进行准确的重建。我们将我们的系统（称为 NeRF-W）应用于著名地标的互联网照片集，并展示时间一致的新颖视图渲染，这些渲染比现有技术更接近真实感。
  - [Ha-NeRF：野外的幻觉神经辐射场, CVPR2022](https://rover-xingyu.github.io/Ha-NeRF/) | [***``[code]``***](https://github.com/rover-xingyu/Ha-NeRF)
    > 神经辐射场 (NeRF) 最近因其令人印象深刻的新颖视图合成能力而广受欢迎。本文研究了幻觉 NeRF 的问题：即在一天中的不同时间从一组旅游图像中恢复一个真实的 NeRF。现有的解决方案采用具有可控外观嵌入的 NeRF 在各种条件下渲染新颖的视图，但它们无法渲染具有看不见的外观的视图一致图像。为了解决这个问题，我们提出了一个用于构建幻觉 NeRF 的端到端框架，称为 Ha-NeRF。具体来说，我们提出了一个外观幻觉模块来处理随时间变化的外观并将它们转移到新的视图中。考虑到旅游图像的复杂遮挡，我们引入了一个反遮挡模块来准确地分解静态主体以获得可见性。合成数据和真实旅游照片集的实验结果表明，我们的方法可以产生幻觉，并从不同的视图呈现无遮挡的图像。
  - [Nerfies：可变形的神经辐射场, ICCV2021](https://arxiv.org/abs/2011.12948) | [code]
    > 我们提出了第一种能够使用从手机随便捕获的照片/视频来逼真地重建可变形场景的方法。我们的方法通过优化一个额外的连续体积变形场来增强神经辐射场 (NeRF)，该场将每个观察点扭曲成一个规范的 5D NeRF。我们观察到这些类似 NeRF 的变形场容易出现局部最小值，并为基于坐标的模型提出了一种从粗到细的优化方法，可以实现更稳健的优化。通过将几何处理和物理模拟的原理应用于类似 NeRF 的模型，我们提出了变形场的弹性正则化，进一步提高了鲁棒性。我们表明，我们的方法可以将随意捕获的自拍照片/视频转换为可变形的 NeRF 模型，允许从任意视角对主体进行逼真的渲染，我们称之为“nerfies”。我们通过使用带有两部手机的装备收集时间同步数据来评估我们的方法，从而在不同视点产生相同姿势的训练/验证图像。我们表明，我们的方法忠实地重建了非刚性变形的场景，并以高保真度再现了看不见的视图。
  - [D-NeRF：动态场景的神经辐射场, CVPR2021](https://arxiv.org/abs/2011.13961) | [***``[code]``***](https://github.com/albertpumarola/D-NeRF)
    > 将机器学习与几何推理相结合的神经渲染技术已成为从一组稀疏图像中合成场景新视图的最有前途的方法之一。其中，神经辐射场 (NeRF) 尤为突出，它训练深度网络将 5D 输入坐标（表示空间位置和观察方向）映射为体积密度和与视图相关的发射辐射。然而，尽管在生成的图像上实现了前所未有的真实感水平，但 NeRF 仅适用于静态场景，其中可以从不同的图像中查询相同的空间位置。在本文中，我们介绍了 D-NeRF，这是一种将神经辐射场扩展到动态域的方法，允许在场景中移动的 \emph{single} 相机的刚性和非刚性运动下重建和渲染物体的新图像。为此，我们将时间视为系统的附加输入，并将学习过程分为两个主要阶段：一个将场景编码为规范空间，另一个将这个规范表示映射到特定时间的变形场景。两种映射都是使用全连接网络同时学习的。一旦网络经过训练，D-NeRF 就可以渲染新颖的图像，同时控制相机视图和时间变量，从而控制对象的移动。我们展示了我们的方法在物体处​​于刚性、关节和非刚性运动的场景中的有效性。代码、模型权重和动态场景数据集将发布。
  - [用于单目 4D 面部头像重建的动态神经辐射场, CVPR2021](https://gafniguy.github.io/4D-Facial-Avatars/) | [***``[code]``***](https://github.com/gafniguy/4D-Facial-Avatars)
    > 我们提出了用于模拟人脸外观和动态的动态神经辐射场。对说话的人进行数字建模和重建是各种应用程序的关键组成部分。特别是对于 AR 或 VR 中的远程呈现应用，需要忠实再现外观，包括新颖的视点或头部姿势。与显式建模几何和材料属性或纯粹基于图像的最先进方法相比，我们引入了基于场景表示网络的头部隐式表示。为了处理面部的动态，我们将场景表示网络与低维可变形模型相结合，该模型提供对姿势和表情的显式控制。我们使用体积渲染从这种混合表示中生成图像，并证明这种动态神经场景表示只能从单目输入数据中学习，而不需要专门的捕获设置。在我们的实验中，我们表明这种学习的体积表示允许生成照片般逼真的图像，其质量超过了基于视频的最先进的重演方法的质量。
  - [PVA：像素对齐的体积化身, CVPR2021](https://volumetric-avatars.github.io/) | [code]
    > 逼真的人头的采集和渲染是一个极具挑战性的研究问题，对于虚拟远程呈现特别重要。目前，最高质量是通过在多视图数据上以个人特定方式训练的体积方法实现的。与更简单的基于网格的模型相比，这些模型更好地表示精细结构，例如头发。体积模型通常使用全局代码来表示面部表情，以便它们可以由一小组动画参数驱动。虽然这样的架构实现了令人印象深刻的渲染质量，但它们不能轻易地扩展到多身份设置。在本文中，我们设计了一种新颖的方法，用于在仅给定少量输入的情况下预测人头的体积化身。我们通过一种新颖的参数化实现跨身份的泛化，该参数化将神经辐射场与直接从输入中提取的局部像素对齐特征相结合，从而避免了对非常深或复杂网络的需求。我们的方法仅基于光度重新渲染损失以端到端的方式进行训练，无需明确的 3D 监督。我们证明我们的方法在质量方面优于现有的现有技术，并且能够生成忠实的面部表情多身份设置。
  - [用于人体建模的动画神经辐射场, ICCV2021](https://zju3dv.github.io/animatable_nerf/) | [***``[code]``***](https://github.com/zju3dv/animatable_nerf)
    > 本文解决了从多视图视频中重建可动画人体模型的挑战。最近的一些工作提出将非刚性变形场景分解为规范神经辐射场和一组将观察空间点映射到规范空间的变形场，从而使他们能够从图像中学习动态场景。然而，它们将变形场表示为平移矢量场或 SE(3) 场，这使得优化受到高度约束。此外，这些表示不能由输入运动明确控制。相反，我们引入了神经混合权重场来产生变形场。基于骨架驱动的变形，混合权重场与 3D 人体骨骼一起使用，以生成观察到规范和规范到观察的对应关系。由于 3D 人体骨骼更易观察，它们可以规范变形场的学习。此外，学习到的混合权重场可以与输入的骨骼运动相结合，以生成新的变形场来为人体模型设置动画。实验表明，我们的方法明显优于最近的人类合成方法。该代码将在 https://zju3dv.github.io/animatable_nerf/ 上提供。
  - [NeRF++：分析和改进神经辐射场](https://arxiv.org/abs/2010.07492) | [***``[code]``***](https://github.com/Kai-46/nerfplusplus;)
    > 神经辐射场 (NeRF) 为各种捕捉设置实现了令人印象深刻的视图合成结果，包括有界场景的 360 度捕捉以及有界和无界场景的前向捕捉。 NeRF 将表示视图不变不透明度和视图相关颜色体积的多层感知器 (MLP) 拟合到一组训练图像，并基于体积渲染技术对新视图进行采样。在这份技术报告中，我们首先评论了辐射场及其潜在的模糊性，即形状-辐射模糊度，并分析了 NeRF 在避免这种模糊性方面的成功。其次，我们解决了将 NeRF 应用于大规模、无界 3D 场景中对象的 360 度捕获所涉及的参数化问题。我们的方法在这种具有挑战性的场景中提高了视图合成保真度。此 https 网址提供了代码。
  - [动态场景的神经场景图, CVPR2021(oral)](https://arxiv.org/abs/2011.10379) | [***``[code]``***](https://github.com/princeton-computational-imaging/neural-scene-graphs)
    > 最近的隐式神经渲染方法表明，可以通过仅由一组 RGB 图像监督的预测其体积密度和颜色来学习复杂场景的准确视图合成。然而，现有方法仅限于学习将所有场景对象编码为单个神经网络的静态场景的有效表示，并且缺乏将动态场景表示和分解为单个场景对象的能力。在这项工作中，我们提出了第一个将动态场景分解为场景图的神经渲染方法。我们提出了一种学习的场景图表示，它对对象变换和辐射进行编码，以有效地渲染场景的新颖排列和视图。为此，我们学习隐式编码的场景，并结合联合学习的潜在表示来描述具有单个隐式函数的对象。我们在合成和真实汽车数据上评估所提出的方法，验证我们的方法学习动态场景 - 仅通过观察该场景的视频 - 并允许渲染具有看不见的对象集的新颖场景组合的新颖照片般逼真的视图看不见的姿势。
  - [使用隐式场景表示进行就地场景标记和理解, ICCV2021(oral)](https://shuaifengzhi.com/Semantic-NeRF/) | [***``[code]``***](https://github.com/Harry-Zhi/semantic_nerf/)
    > 语义标签与几何和辐射重建高度相关，因为具有相似形状和外观的场景实体更有可能来自相似的类别。最近的隐式神经重建技术很有吸引力，因为它们不需要事先的训练数据，但同样的完全自我监督的方法对于语义来说是不可能的，因为标签是人类定义的属性。
