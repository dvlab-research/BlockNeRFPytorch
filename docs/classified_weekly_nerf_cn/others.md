
每周分类神经辐射场 - others ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
===================================================================================================================================
## 按类别筛选: 
 [全部](../weekly_nerf_cn.md) | [动态](./dynamic.md) | [编辑](./editing.md) | [快速](./fast.md) | [泛化](./generalization.md) | [人体](./human.md) | [视频](./video.md) | [光照](./lighting.md) | [重建](./reconstruction.md) | [纹理](./texture.md) | [语义](./semantic.md) | [姿态-SLAM](./pose-slam.md) | [其他](./others.md) 
## Dec27 - Jan3, 2023
## Dec25 - Dec31, 2022
## Dec18 - Dec24, 2022
  - [紧凑型神经辐射场的掩蔽小波表示](https://arxiv.org/abs/2212.09069) | [***``[code]``***](https://github.com/daniel03c1/masked_wavelet_nerf)
    > 神经辐射场 (NeRF) 已经证明了神经渲染中基于坐标的神经表示（神经场或隐式神经表示）的潜力。 然而，使用多层感知器 (MLP) 来表示 3D 场景或对象需要大量的计算资源和时间。 最近有关于如何通过使用额外的数据结构（例如网格或树）来减少这些计算效率低下的研究。 尽管性能很有前途，但显式数据结构需要大量内存。 在这项工作中，我们提出了一种在不损害具有附加数据结构的优势的情况下减小大小的方法。 详细地说，我们建议在基于网格的神经场上使用小波变换。 基于网格的神经场是为了快速收敛，而其效率已经在高性能标准编解码器中得到证明的小波变换是为了提高网格的参数效率。 此外，为了在保持重建质量的同时实现更高的网格系数稀疏性，我们提出了一种新颖的可训练掩蔽方法。 实验结果表明，非空间网格系数，例如小波系数，能够获得比空间网格系数更高的稀疏度，从而产生更紧凑的表示。 通过我们提出的掩码和压缩管道，我们在 2 MB 的内存预算内实现了最先进的性能。 我们的代码可通过此 https 网址获得。
## Dec11 - Dec17, 2022
## Dec4 - Dec10, 2022
  - [4K-NeRF：超高分辨率下的高保真神经辐射场](https://arxiv.org/abs/2212.04701) | [***``[code]``***](https://github.com/frozoul/4K-NeRF)
    > 在本文中，我们提出了一个新颖而有效的框架，名为 4K-NeRF，以神经辐射场 (NeRF) 的方法为基础，在超高分辨率的具有挑战性的场景中追求高保真视图合成。 基于 NeRF 的方法的渲染过程通常依赖于像素方式，在这种方式中，射线（或像素）在训练和推理阶段都被独立处理，限制了其描述细微细节的表现能力，尤其是在提升到极高的分辨率时。 我们通过更好地探索光线相关性来解决这个问题，以增强受益于使用几何感知局部上下文的高频细节。 特别是，我们使用视图一致编码器在较低分辨率空间中有效地建模几何信息，并通过视图一致解码器恢复精细细节，条件是编码器估计的光线特征和深度。 联合训练与基于补丁的采样进一步促进了我们的方法，将来自面向感知的正则化的监督纳入像素明智的损失之外。 与现代 NeRF 方法的定量和定性比较表明，我们的方法可以显着提高渲染质量以保留高频细节，在 4K 超高分辨率场景下实现最先进的视觉质量。 代码可在 \url{this https URL}
## Nov27 - Dec3, 2022
  - [3D-TOGO：走向文本引导的跨类别 3D 对象生成, AAAI2023](https://arxiv.org/abs/2212.01103) | [code]
    > 文本引导的 3D 对象生成旨在生成由用户定义的标题描述的 3D 对象，这为可视化我们想象的内容铺平了道路。 尽管一些工作致力于解决这一具有挑战性的任务，但这些工作要么使用一些明确的 3D 表示（例如，网格），这些表示缺乏纹理并且需要后期处理来渲染照片般逼真的视图； 或者需要对每个案例进行单独耗时的优化。 在这里，我们首次尝试通过新的 3D-TOGO 模型实现通用文本引导的跨类别 3D 对象生成，该模型集成了文本到视图生成模块和视图到 3D 生成模块。 文本到视图生成模块旨在生成给定输入字幕的目标 3D 对象的不同视图。 提出了先验指导、标题指导和视图对比学习，以实现更好的视图一致性和标题相似性。 同时，views-to-3D 生成模块采用 pixelNeRF 模型，以从先前生成的视图中获取隐式 3D 神经表示。 我们的 3D-TOGO 模型以具有良好纹理的神经辐射场形式生成 3D 对象，并且不需要对每个单独的字幕进行时间成本优化。 此外，3D-TOGO可以通过输入的字幕控制生成的3D对象的类别、颜色和形状。 在最大的 3D 对象数据集（即 ABO）上进行了大量实验，以验证 3D-TOGO 可以根据 PSNR、SSIM、LPIPS 和 CLIP 等 98 个不同类别的输入字幕更好地生成高质量的 3D 对象。 得分，与文本 NeRF 和 Dreamfields 相比。
  - [SinGRAF：学习单个场景的 3D 生成辐射场](https://arxiv.org/abs/2211.17260) | [code]
    > 生成模型在合成逼真的 3D 对象方面显示出巨大的潜力，但它们需要大量的训练数据。 我们介绍了 SinGRAF，这是一种 3D 感知生成模型，使用单个场景的一些输入图像进行训练。 经过训练后，SinGRAF 会生成此 3D 场景的不同实现，在改变场景布局的同时保留输入的外观。 为此，我们以 3D GAN 架构的最新进展为基础，并在训练期间引入了一种新颖的渐进式补丁辨别方法。 通过几个实验，我们证明了 SinGRAF 产生的结果在质量和多样性方面都大大优于最接近的相关作品。
  - [NeAF：学习用于点法线估计的神经角度场, AAAI2023](https://arxiv.org/abs/2211.16869) | [***``[code]``***](https://github.com/lisj575/NeAF)
    > 非结构化点云的法线估计是 3D 计算机视觉中的一项重要任务。 当前的方法通过将局部补丁映射到法向量或使用神经网络学习局部表面拟合来取得令人鼓舞的结果。 然而，这些方法不能很好地推广到看不见的场景，并且对参数设置很敏感。 为了解决这些问题，我们提出了一个隐式函数来学习球坐标系中每个点法线周围的角度场，称为神经角度场（NeAF）。 我们不是直接预测输入点的法线，而是预测地面实况法线和随机采样的查询法线之间的角度偏移。 这种策略推动网络观察更多不同的样本，从而以更稳健的方式获得更高的预测精度。 为了在推理时从学习的角度场预测法线，我们在单位球形空间中随机采样查询向量，并将具有最小角度值的向量作为预测法线。 为了进一步利用 NeAF 学到的先验知识，我们建议通过最小化角度偏移来细化预测的法向量。 合成数据和真实扫描的实验结果显示，在广泛使用的基准下，与最先进的技术相比有了显着改进。
  - [SNAF：具有神经衰减场的稀疏视图 CBCT 重建](https://arxiv.org/abs/2211.17048) | [code]
    > 锥形束计算机断层扫描（CBCT）已广泛应用于临床实践，尤其是牙科诊所，而捕获时X射线的辐射剂量一直是CBCT成像中长期关注的问题。 已经提出了几项研究工作来从稀疏视图 2D 投影重建高质量的 CBCT 图像，但目前最先进的技术存在伪影和缺乏精细细节的问题。 在本文中，我们提出了通过学习神经衰减场来进行稀疏视图 CBCT 重建的 SNAF，我们发明了一种新颖的视图增强策略来克服稀疏输入视图数据不足带来的挑战。 我们的方法在高重建质量（30+ PSNR）方面实现了卓越的性能，只有 20 个输入视图（比临床收集少 25 倍），优于最先进的技术。 我们进一步进行了综合实验和消融分析，以验证我们方法的有效性。
  - [从单目视频重建手持物体, SIGGRAPH-Asia2022](https://dl.acm.org/doi/abs/10.1145/3550469.3555401) | [code]
    > 本文提出了一种从单目视频中重建手持物体的方法。 与许多最近通过训练有素的网络直接预测对象几何形状的方法相比，所提出的方法不需要任何关于对象的先验知识，并且能够恢复更准确和详细的对象几何形状。 关键思想是手部运动自然地提供了对象的多个视图，并且可以通过手部姿势跟踪器可靠地估计该运动。 然后，可以通过解决多视图重建问题来恢复对象几何形状。 我们设计了一种基于隐式神经表示的方法来解决重建问题，并解决手部姿势估计不精确、手部相对运动和小物体的几何优化不足等问题。 我们还提供了一个新收集的具有 3D ground truth 的数据集来验证所提出的方法。 数据集和代码将发布在 https://dihuangdh.github.io/hhor。
  - [一种轻松教授变形金刚多视图几何的方法](https://arxiv.org/abs/2211.15107) | [code]
    > 变形金刚是强大的视觉学习者，这在很大程度上是因为它们明显缺乏手动指定的先验。 由于 3D 形状和视点的近乎无限可能的变化（需要灵活性）以及射影几何的精确性质（遵守刚性法则），这种灵活性在涉及多视图几何的任务中可能会出现问题。 为了解决这个难题，我们提出了一种“轻触”方法，引导视觉变形金刚学习多视图几何，但允许它们在需要时摆脱束缚。 我们通过使用极线来引导 Transformer 的交叉注意力图来实现这一点，惩罚极线外的注意力值并鼓励沿着这些线的更高注意力，因为它们包含几何上合理的匹配。 与以前的方法不同，我们的建议在测试时不需要任何相机姿势信息。 我们专注于姿势不变的对象实例检索，由于查询和检索图像之间的视点存在巨大差异，因此标准 Transformer 网络在这方面存在困难。 在实验上，我们的方法在对象检索方面优于最先进的方法，而且在测试时不需要姿势信息。
  - [NeRF 在 360° 图像上的非均匀采样策略, BMVC2022](https://arxiv.org/abs/2212.03635) | [code]
    > 近年来，随着神经辐射场 (NeRF) 的出现，使用透视图像进行新视图合成的性能得到了显着提高。 本研究提出了两种有效构建 360{\textdegree} 全向图像 NeRF 的新技术。 由于ERP格式的360{\textdegree}图像在高纬度地区存在空间畸变和360{\textdegree}广视角的特点，NeRF的一般光线采样策略是无效的。 因此，NeRF 的视图合成精度有限，学习效率不高。 我们为 NeRF 提出了两种非均匀光线采样方案以适应 360{\textdegree} 图像——失真感知光线采样和内容感知光线采样。 我们分别使用室内和室外场景的 Replica 和 SceneCity 模型创建了评估数据集 Synth360。 在实验中，我们表明我们的提议在准确性和效率方面都成功地构建了 360{\textdegree} 图像 NeRF。 该提案广泛适用于 NeRF 的高级变体。 DietNeRF、AugNeRF 和 NeRF++ 结合所提出的技术进一步提高了性能。 此外，我们展示了我们提出的方法提高了 360{\textdegree} 图像中真实世界场景的质量。 Synth360：这个 https 网址。
## Nov20 - Nov26, 2022
  - [通过神经渲染的无监督连续语义适应](https://arxiv.org/abs/2211.13969) | [code]
    > 越来越多的应用程序依赖于数据驱动模型，这些模型被部署用于跨一系列场景的感知任务。由于训练和部署数据之间的不匹配，在新场景上调整模型对于获得良好性能通常至关重要。在这项工作中，我们研究了语义分割任务的持续多场景适应，假设在部署期间没有可用的地面实况标签，并且应该保持先前场景的性能。我们建议通过融合分割模型的预测，然后使用视图一致的渲染语义标签作为伪标签来调整模型，为每个场景训练一个语义 NeRF 网络。通过与分割模型的联合训练，Semantic-NeRF 模型有效地实现了 2D-3D 知识迁移。此外，由于其紧凑的尺寸，它可以存储在长期记忆中，随后用于从任意角度渲染数据以减少遗忘。我们在 ScanNet 上评估了我们的方法，我们的方法优于基于体素的基线和最先进的无监督域适应方法。
  - [DiffusionSDF：有符号距离函数的条件生成模型](https://arxiv.org/abs/2211.13757) | [code]
    > 概率扩散模型在图像合成、修复和文本到图像任务方面取得了最先进的结果。然而，它们仍处于生成复杂 3D 形状的早期阶段。这项工作提出了 DiffusionSDF，一种用于形状补全、单视图重建和真实扫描点云重建的生成模型。我们使用神经符号距离函数 (SDF) 作为我们的 3D 表示，通过神经网络参数化各种信号（例如，点云、2D 图像）的几何形状。神经 SDF 是隐式函数，扩散它们相当于学习它们的神经网络权重的反转，我们使用自定义调制模块解决了这个问题。广泛的实验表明，我们的方法能够从部分输入进行现实的无条件生成和条件生成。这项工作将扩散模型的领域从学习 2D 显式表示扩展到 3D 隐式表示。
  - [BAD-NeRF：束调整的去模糊神经辐射场](https://arxiv.org/abs/2211.12853) | [code]
    > 神经辐射场 (NeRF) 最近受到了相当大的关注，因为它在给定一组姿势相机图像的情况下，在逼真的 3D 重建和新颖的视图合成方面具有令人印象深刻的能力。早期的工作通常假设输入图像质量很好。然而，图像退化（例如低光条件下的图像运动模糊）在现实场景中很容易发生，这将进一步影响 NeRF 的渲染质量。在本文中，我们提出了一种新颖的束调整去模糊神经辐射场 (BAD-NeRF)，它可以对严重的运动模糊图像和不准确的相机姿势具有鲁棒性。我们的方法对运动模糊图像的物理图像形成过程进行建模，并联合学习 NeRF 的参数并恢复曝光时间内的相机运动轨迹。在实验中，我们表明，通过直接对真实物理图像形成过程进行建模，BAD-NeRF 在合成数据集和真实数据集上都实现了优于先前工作的性能。
  - [OReX：使用神经场从 Planner 横截面重建对象](https://arxiv.org/abs/2211.12886) | [code]
    > 从平面横截面重建 3D 形状是一项受到医学成像和地理信息学等下游应用启发的挑战。输入是在空间平面的稀疏集合上完全定义的输入/输出指示函数，输出是指示函数对整个体积的插值。以前解决这个稀疏和病态问题的工作要么产生低质量的结果，要么依赖于额外的先验，例如目标拓扑、外观信息或输入法线方向。在本文中，我们介绍了 OReX，一种仅从切片重建 3D 形状的方法，以神经场作为插值先验。在输入平面上训练一个简单的神经网络以接收 3D 坐标并返回查询点的内部/外部估计。这个先验在诱导平滑性和自相似性方面很有用。这种方法的主要挑战是高频细节，因为神经先验过度平滑。为了缓解这种情况，我们提供了一种迭代估计架构和一种分层输入采样方案，鼓励从粗到精的训练，允许在后期阶段关注高频。此外，我们识别并分析了源自网格提取步骤的常见波纹状效果。我们通过调整输入输入/输出边界周围指示函数的空间梯度来缓解它，从根本上解决问题。
## Nov13 - Nov19, 2022
  - [大尺度室内场景实时全向漫游, SIGGRAPH-Asia2022](https://dl.acm.org/doi/abs/10.1145/3550340.3564222) | [code]
    > 神经辐射场 (NeRF) 最近在新视图合成方面取得了令人瞩目的成果。然而，之前关于 NeRF 的工作主要集中在以对象为中心的场景。由于位置编码容量有限，它们在面向外的和大规模场景中会遭受明显的性能下降。为了缩小差距，我们以几何感知的方式探索辐射场。我们从从多个 360° 图像中学习的全向神经辐射场估计显式几何。依靠恢复的几何形状，我们使用自适应分而治之的策略来缩小和微调辐射场，进一步提高渲染速度和质量。基线之间的定量和定性比较说明了我们在大型室内场景中的主要性能，并且我们的系统支持实时 VR 漫游。
  - [AligNeRF：通过对齐感知训练的高保真神经辐射场](https://arxiv.org/abs/2211.09682) | [code]
    > 神经辐射场 (NeRF) 是将 3D 场景建模为连续函数的强大表示。尽管 NeRF 能够渲染具有视图相关效果的复杂 3D 场景，但很少有人致力于探索其在高分辨率设置中的局限性。具体来说，现有的基于 NeRF 的方法在重建高分辨率真实场景时面临着一些限制，包括大量的参数、未对齐的输入数据和过度平滑的细节。在这项工作中，我们对使用高分辨率数据训练 NeRF 进行了首次试点研究，并提出了相应的解决方案：1）将多层感知器（MLP）与卷积层结合，可以编码更多的邻域信息，同时减少参数总数； 2) 一种新的训练策略来解决由移动物体或小相机校准误差引起的未对准问题； 3）高频感知损失。我们的方法几乎是免费的，没有引入明显的训练/测试成本，而在不同数据集上的实验表明，与当前最先进的 NeRF 模型相比，它可以恢复更多的高频细节。项目页面：\url{此 https URL。}
  - [3DLatNav：导航用于语义感知 3D 对象操作的生成潜在空间](https://arxiv.org/abs/2211.09770) | [code]
    > 3D 生成模型最近成功地以点云的形式生成逼真的 3D 对象。然而，大多数模型在没有广泛的语义属性标签或其他参考点云的情况下不提供操纵组件对象部分的形状语义的可控性。此外，除了执行简单的潜在向量运算或插值的能力之外，还缺乏对 3D 形状的部分级语义如何在其相应的生成潜在空间中进行编码的理解。在本文中，我们提出了 3DLatNav；一种导航预训练生成潜在空间以实现 3D 对象的受控部分级语义操作的新方法。首先，我们提出了一种使用 3D 形状的潜在表示的部分级弱监督形状语义识别机制。然后，我们将该知识转移到预训练的 3D 对象生成潜在空间，以解开纠缠的嵌入，以线性子空间的形式表示对象组成部分的不同形状语义，尽管在训练期间部分级标签不可用。最后，我们利用那些已识别的子空间来表明，通过将所提出的框架应用于任何预训练的 3D 生成模型，可以实现可控的 3D 对象部分操作。通过两个新的定量指标来评估部分级操作的一致性和定位准确性，我们表明 3DLatNav 在识别编码 3D 对象的部分级形状语义的潜在方向方面优于现有的无监督潜在解缠结方法。通过对最先进的生成模型进行多项消融研究和测试，我们表明 3DLatNav 可以在输入点云上实现受控的部分级语义操作，同时保留对象的其他特征和真实性。
  - [AsyncNeRF：从具有时间姿态函数的异步 RGB-D 序列中学习大规模辐射场](https://arxiv.org/abs/2211.07459) | [code]
    > 大规模辐射场是用于智能交通应用（如自动驾驶或无人机送货）的有前途的测绘工具。但对于大型场景，由于感测范围有限，紧凑型同步 RGB-D 相机并不适用，使用单独的 RGB 和深度传感器不可避免地导致序列不同步。受最近不需要已知内在或外在参数的自校准辐射场训练方法的成功启发，我们提出了第一个自校准 RGB 和深度帧之间的不匹配的解决方案。我们利用重要的特定领域事实，即 RGB 和深度帧实际上是从同一轨迹采样的，并开发了一种称为时间-姿势函数的新型隐式网络。将它与大规模辐射场相结合会产生一种级联两个隐式表示网络的架构。为了验证其有效性，我们构建了一个多样化且逼真的数据集，涵盖各种 RGB-D 不匹配场景。通过对该数据集进行全面的基准测试，我们展示了我们的方法在不同场景中的灵活性以及优于适用的先前对应方法的卓越性能。代码、数据和模型将公开提供。
## Nov6 - Nov12, 2022
  - [NeXT：通过 Multi-skip Transformer 实现高质量的神经辐射场, ECCV2022](https://link.springer.com/chapter/10.1007/978-3-031-19824-3_5) | [***``[code]``***](https://github.com/Crishawy/NeXT)
    > 神经辐射场 (NeRF) 方法通过神经网络表示场景，在新颖的视图合成方面表现出令人印象深刻的性能。然而，大多数现有的基于 NeRF 的方法（包括其变体）将每个样本点单独视为输入，同时忽略了来自相应射线的相邻样本点之间的内在关系，从而阻碍了重建性能。为了解决这个问题，我们探索了一种全新的方案，即 NeXT，引入了一个多跳跃变换器来捕获射线级查询中各个样本点之间的丰富关系。具体来说，提出了射线标记化以将每条射线表示为一系列点嵌入，并将其作为我们提出的 NeXT 的输入。这样，通过内置的自注意力机制捕获样本点之间的关系，以促进重建。此外，我们提出的 NeXT 可以很容易地与其他基于 NeRF 的方法结合，以提高它们的渲染质量。在三个数据集上进行的大量实验表明，NeXT 大大优于所有以前的最先进的工作。特别是，拟议的 NeXT 在 Blender 数据集上的 PSNR 超过了强大的 NeRF 基线 2.74 dB。该代码可在 https://github.com/Crishawy/NeXT 获得。
  - [QRF：具有量子辐射场的隐式神经表示](https://arxiv.org/abs/2211.03418) | [code]
    > 现实世界场景的逼真渲染对于包括混合现实 (MR) 和虚拟现实 (VR) 在内的广泛应用来说是一项巨大的挑战。神经网络长期以来一直在求解微分方程的背景下进行研究，之前已被引入作为照片级渲染的隐式表示。然而，使用经典计算的逼真渲染具有挑战性，因为它需要耗时的光线行进，并且由于维数灾难而遭受计算瓶颈。在本文中，我们提出了量子辐射场 (QRF)，它集成了量子电路、量子激活函数和量子体积渲染，用于隐式场景表示。结果表明，QRF不仅发挥了量子计算速度快、收敛快、并行度高等优势，而且保证了体绘制的高质量。
## Oct30 - Nov5, 2022
  - [HyperSound：使用超网络生成音频信号的隐式神经表示](https://arxiv.org/abs/2211.01839) | [code]
    > 隐式神经表征 (INR) 是一个快速发展的研究领域，它提供了表示多媒体信号的替代方法。 INR 最近的应用包括图像超分辨率、高维信号压缩或 3D 渲染。然而，这些解决方案通常侧重于视觉数据，将它们适应音频领域并非易事。此外，它需要为每个数据样本单独训练模型。为了解决这个限制，我们提出了 HyperSound，这是一种利用超网络为训练时看不见的音频信号生成 INR 的元学习方法。我们表明，我们的方法可以重建声波，其质量可与其他最先进的模型相媲美。
  - [基于注意力的神经元胞自动机, NeurIPS2022](https://arxiv.org/abs/2211.01233) | [code]
    > 元胞自动机 (CA) 最近的扩展结合了现代深度学习的关键思想，极大地扩展了它们的能力并催生了一个新的神经元元自动机 (NCA) 技术家族。受基于 Transformer 的架构的启发，我们的工作提出了一类新的基于注意力的 NCA，使用空间局部化但全局组织的自注意力方案形成。我们介绍了此类的一个实例，名为 Vision Transformer Cellular Automata (ViTCA)。我们展示了跨六个基准数据集的去噪自动编码的定量和定性结果，将 ViTCA 与 U-Net、基于 U-Net 的 CA 基线 (UNetCA) 和 Vision Transformer (ViT) 进行了比较。在比较配置为类似参数复杂性的架构时，ViTCA 架构在所有基准测试和几乎每个评估指标上都产生了卓越的性能。我们对 ViTCA 的各种架构配置进行了消融研究，分析了它对细胞状态的影响，并调查了它的归纳偏差。最后，我们通过线性探针在其聚合细胞状态隐藏表示上检查其学习表示，与我们的 U-Net、ViT 和 UNetCA 基线相比，平均产生更好的结果。
## Oct23 - Oct29, 2022
  - [NeX360：基于神经基础扩展的实时全方位视图合成, TPAMI2022](https://ieeexplore.ieee.org/abstract/document/9931981) | [code]
    > 我们介绍了 NeX，这是一种基于多平面图像 (MPI) 增强的新颖视图合成的新方法，可以实时再现视图相关的效果。与传统的 MPI 不同，我们的技术将每个像素参数化为从神经网络学习的球形基函数的线性组合，以对视图相关的效果进行建模，并使用混合隐式-显式建模策略来改进精细细节。此外，我们还展示了 NeX 的扩展，它利用知识蒸馏来为无限 360 ∘ 场景训练多个 MPI。我们的方法在几个基准数据集上进行了评估：NeRF-Synthetic 数据集、Light Field 数据集、Real Forward-Facing 数据集、Space 数据集以及 Shiny，我们的新数据集包含更具挑战性的视图相关效果，例如彩虹反射在 CD 上。我们的方法在 PSNR、SSIM 和 LPIPS 上优于其他实时渲染方法，可以实时渲染无界 360 ∘ 场景。
  - [NeRFPlayer：具有分解神经辐射场的可流式动态场景表示](https://arxiv.org/abs/2210.15947) | [code]
    > 在 VR 中自由地在真实世界的 4D 时空空间中进行视觉探索一直是一项长期的追求。当仅使用几个甚至单个 RGB 相机来捕捉动态场景时，这项任务特别有吸引力。为此，我们提出了一个能够快速重建、紧凑建模和流式渲染的高效框架。首先，我们建议根据时间特征分解 4D 时空空间。 4D 空间中的点与属于三个类别的概率相关联：静态区域、变形区域和新区域。每个区域都由一个单独的神经场表示和规范化。其次，我们提出了一种基于混合表示的特征流方案，用于有效地对神经场进行建模。我们的方法，创造了 NeRFPlayer，在单手持相机和多相机阵列捕获的动态场景上进行评估，在质量和速度方面实现与最近最先进的方法相当或更优的渲染性能，实现重建每帧 10 秒，实时渲染。
  - [Vox-Fusion：基于体素的神经隐式表示的密集跟踪和映射](https://arxiv.org/abs/2210.15858) | [***``[code]``***](https://github.com/zju3dv/Vox-Fusion)
    > 在这项工作中，我们提出了一个名为 Vox-Fusion 的密集跟踪和映射系统，它将神经隐式表示与传统的体积融合方法无缝融合。我们的方法受到最近开发的隐式映射和定位系统的启发，并进一步扩展了这一思想，使其可以自由应用于实际场景。具体来说，我们利用基于体素的神经隐式表面表示来编码和优化每个体素内的场景。此外，我们采用基于八叉树的结构来划分场景并支持动态扩展，使我们的系统能够像以前的作品一样在不知道环境的情况下跟踪和映射任意场景。此外，我们提出了一个高性能的多进程框架来加速该方法，从而支持一些需要实时性能的应用程序。评估结果表明，我们的方法可以实现比以前的方法更好的准确性和完整性。我们还展示了我们的 Vox-Fusion 可用于增强现实和虚拟现实应用程序。我们的源代码可通过此 https 网址公开获得。
## Oct16 - Oct22, 2022
  - [将多维天气和气候数据压缩到神经网络中](https://arxiv.org/abs/2210.12538) | [code]
    > 天气和气候模拟会产生数 PB 的高分辨率数据，研究人员随后会对这些数据进行分析，以了解气候变化或恶劣天气。我们提出了一种压缩这种多维天气和气候数据的新方法：训练基于坐标的神经网络以过度拟合数据，并将生成的参数作为原始基于网格的数据的紧凑表示。虽然压缩比范围从 300 倍到超过 3,000 倍，但我们的方法在加权 RMSE、MAE 方面优于最先进的压缩器 SZ3。它可以忠实地保存重要的大型大气结构，并且不引入人工制品。当使用生成的神经网络作为 790 倍压缩数据加载器来训练 WeatherBench 预测模型时，其 RMSE 增加不到 2%。三个数量级的压缩使高分辨率气候数据的访问民主化，并实现了许多新的研究方向。
  - [具有超分辨声向的神经声场分解](https://arxiv.org/abs/2210.12345) | [code]
    > 声场分解使用来自有限数量麦克风的信号作为输入来预测任意方向的波形。声场分解是下游任务的基础，包括源定位、源分离和空间音频再现。传统的声场分解方法（例如 Ambisonics）具有有限的空间分解分辨率。本文提出了一种基于学习的神经声场分解 (NeSD) 框架，允许使用来自任意位置的几个麦克风的麦克风胶囊的录音进行具有精细空间方向分辨率的声场分解。 NeSD 系统的输入包括麦克风信号、麦克风位置和查询的方向。 NeSD 的输出包括波形和查询位置的存在概率。我们分别用不同的神经网络对 NeSD 系统进行建模，包括全连接、时间延迟和循环神经网络。我们表明，NeSD 系统在语音、音乐和声音事件数据集的声场分解和源定位方面优于传统的 Ambisonics 和 DOANet 方法。此 https URL 提供了演示。
## Oct9 - Oct15, 2022
  - [神经过程的连续条件视频合成](https://arxiv.org/abs/2210.05810) | [***``[code]``***](https://github.com/NPVS/NPVS)
    > 我们为多个条件视频合成任务提出了一个统一模型，包括视频预测和视频帧插值。我们表明，条件视频合成可以表述为一个神经过程，它将输入时空坐标映射到给定上下文时空坐标和像素值的目标像素值。具体来说，我们将坐标的隐式神经表示馈送到基于 Transformer 的非自回归条件视频合成模型中。我们的任务特定模型优于以前在多个数据集上进行视频插值的工作，并与最先进的视频预测模型具有竞争力的性能。重要的是，该模型能够以任意高帧速率进行插值或预测，即连续合成。我们的源代码可在此 https 网址上找到。
  - [面向 DIBR 的视图合成的几何翘曲误差感知 CNN, ACMMM2022](https://dl.acm.org/doi/abs/10.1145/3503161.3547946) | [code]
    > 基于深度图像渲染（DIBR）的面向视图合成是一种重要的虚拟视图生成技术。它根据深度图将参考视图图像扭曲到目标视点，而不需要许多可用的视点。然而，在 3D 翘曲过程中，像素被翘曲到分数像素位置，然后四舍五入（或插值）到整数像素，导致几何翘曲错误并降低图像质量。这在某种程度上类似于图像超分辨率问题，但具有不固定的小数像素位置。为了解决这个问题，我们提出了一个几何翘曲误差感知 CNN (GWEA) 框架来增强面向 DIBR 的视图合成。首先，利用 DIBR 模块中保留的几何翘曲误差，开发了一种基于可变形卷积的几何翘曲误差感知对齐 (GWEA-DCA) 模块。在可变形卷积中学习的偏移量可以解释几何翘曲误差，以促进从小数像素到整数像素的映射。此外，鉴于翘曲图像中的像素由于翘曲误差的强度不同而具有不同的质量，进一步开发了注意力增强视图混合（GWEA-AttVB）模块，以自适应地融合来自不同翘曲图像的像素。最后，基于部分卷积的空洞填充和细化模块填充剩余的空洞并提高整体图像的质量。实验表明，我们的模型可以合成比现有方法更高质量的图像，并且还进行了消融研究，验证了每个提出的模块的有效性。
## Oct2 - Oct8, 2022
  - [ViewFool：评估视觉识别对对抗性观点的鲁棒性, NeurIPS2022](https://arxiv.org/abs/2210.03895) | [code]
    > 最近的研究表明，视觉识别模型对分布变化缺乏鲁棒性。然而，目前的工作主要考虑模型对 2D 图像转换的鲁棒性，而较少探索 3D 世界中的视点变化。一般来说，视点变化在各种实际应用（例如自动驾驶）中很普遍，因此评估视点鲁棒性势在必行。在本文中，我们提出了一种称为 ViewFool 的新方法来寻找误导视觉识别模型的对抗性视点。通过将现实世界中的物体编码为神经辐射场 (NeRF)，ViewFool 在熵正则化器下表征了不同对抗视点的分布，这有助于处理真实相机姿态的波动并减轻真实物体与其神经之间的现实差距申述。实验验证了常见的图像分类器极易受到生成的对抗性视点的影响，这也表现出很高的跨模型可迁移性。基于 ViewFool，我们引入了 ImageNet-V，这是一种新的分布外数据集，用于对图像分类器的视点鲁棒性进行基准测试。对具有不同架构、目标函数和数据增强的 40 个分类器的评估结果显示，在 ImageNet-V 上进行测试时模型性能显着下降，这为利用 ViewFool 作为一种有效的数据增强策略来提高视点鲁棒性提供了可能性。
  - [用于手术记录的新视图合成](https://link.springer.com/chapter/10.1007/978-3-031-18576-2_7) | [code]
    > 在手术室记录手术是医疗教育和评估的基本任务之一。然而，由于目标在手术过程中被医生或护士的头部或手严重遮挡，因此难以记录描绘手术的区域。我们使用了一个记录系统，该系统在手术灯中嵌入了多个摄像头，假设至少有一个摄像头正在无遮挡地记录目标。在本文中，我们提出 Conditional-BARF (C-BARF) 通过合成来自相机的新颖视图图像来生成无遮挡图像，旨在生成具有平滑相机姿态转换的视频。据我们所知，这是第一个解决从手术场景的多个图像合成新颖视图图像的问题的工作。我们使用三种不同类型手术的原始数据集进行实验。我们的实验表明，我们可以成功地从嵌入在手术灯中的多个摄像头记录的图像中合成新的视图。
  - [用于自监督入住预测的可区分光线投射, ECCV2022](https://arxiv.org/abs/2210.01917) | [***``[code]``***](https://github.com/tarashakhurana/emergent-occ-forecasting)
    > 安全自动驾驶的运动规划需要了解自我车辆周围的环境如何随时间演变。场景中可驱动区域的以自我为中心的感知不仅随着环境中演员的运动而变化，而且随着自我车辆本身的运动而变化。为大规模规划（例如以自我为中心的自由空间）提出的自我监督表示混淆了这两种运动，使得该表示难以用于下游运动规划器。在本文中，我们使用几何占用作为自由空间等依赖于视图的表示的自然替代方案。占用图自然地将环境的运动与自我车辆的运动分开。然而，人们无法直接观察场景的完整 3D 占用情况（由于遮挡），因此难以用作学习信号。我们的主要见解是使用可微分光线投射将未来占用预测“渲染”到未来的 LiDAR 扫描预测中，这可以与自监督学习的地面实况扫描进行比较。可微光线投射的使用允许占用率作为预测网络中的内部表示出现。在没有地面实况占用的情况下，我们定量评估了光线投射 LiDAR 扫描的预测，并显示了多达 15 个 F1 点的改进。对于下游运动规划器，紧急占用可以直接用于引导不可驱动区域，与以自由空间为中心的运动规划器相比，这种表示相对减少了高达 17% 的物体碰撞次数。
  - [用于新视图合成的自我改进多平面到层图像, WACV2023](https://samsunglabs.github.io/MLI/) | [***``[code]``***](https://github.com/SamsungLabs/MLI)
    > 我们提出了一种用于轻量级小说视图合成的新方法，该方法可以推广到任意前向场景。最近的方法在计算上很昂贵，需要逐场景优化，或者产生内存昂贵的表示。我们首先用一组正面平行的半透明平面来表示场景，然后以端到端的方式将它们转换为可变形层。此外，我们采用前馈细化程序，通过聚合来自输入视图的信息来纠正估计的表示。我们的方法在处理新场景时不需要微调，并且可以不受限制地处理任意数量的视图。实验结果表明，我们的方法在常用指标和人工评估方面超过了最近的模型，在推理速度和推断分层几何的紧凑性方面具有显着优势，请参阅此 https URL
  - [NARF22：用于配置感知渲染的神经铰接辐射场, IROS2022](https://progress.eecs.umich.edu/projects/narf/) | [code]
    > 铰接物体对机器人的感知和操作提出了独特的挑战。它们增加的自由度数量使得定位等任务在计算上变得困难，同时也使得现实世界数据集收集的过程无法扩展。为了解决这些可扩展性问题，我们提出了神经铰接辐射场 (NARF22)，这是一个使用完全可微分、配置参数化神经辐射场 (NeRF) 作为提供铰接对象高质量渲染的方法的管道。 NARF22 在推理时不需要明确了解对象结构。我们提出了一种两阶段的基于部件的训练机制，即使底层训练数据只有一个配置表示，它也允许对象渲染模型在配置空间中很好地泛化。我们通过在通过 Fetch 移动操作机器人收集的真实关节工具数据集上训练可配置渲染器来展示 NARF22 的功效。我们通过配置估计和 6 自由度姿态细化任务展示了该模型对基于梯度的推理方法的适用性。项目网页位于：此 https URL。
  - [SinGRAV：从单个自然场景中学习生成辐射量](https://arxiv.org/abs/2210.01202) | [code]
    > 我们提出了一个用于一般自然场景的 3D 生成模型。由于缺乏表征目标场景的必要 3D 数据量，我们建议从单个场景中学习。我们的关键见解是，一个自然场景通常包含多个组成部分，其几何、纹理和空间排列遵循一些清晰的模式，但在同一场景中的不同区域仍然表现出丰富的变化。这表明将生成模型的学习本地化在大量局部区域上。因此，我们利用具有空间局部性偏差的多尺度卷积网络来学习单个场景中多个尺度的局部区域的统计信息。与现有方法相比，我们的学习设置绕过了从许多同质 3D 场景中收集数据以学习共同特征的需要。我们创造了我们的方法 SinGRAV，用于从单个自然场景中学习生成辐射体积。我们展示了 SinGRAV 从单个场景生成合理多样的变化的能力，SingGRAV 相对于最先进的生成神经场景方法的优点，以及 SinGRAV 在各种应用中的多功能性，涵盖 3D 场景编辑、合成和动画。代码和数据将被发布以促进进一步的研究。
  - [IntrinsicNeRF：学习用于可编辑新视图合成的内在神经辐射场](https://arxiv.org/abs/2210.00647) | [***``[code]``***](https://github.com/zju3dv/IntrinsicNeRF)
    > 我们提出了被称为 IntrinsicNeRF 的内在神经辐射场，它将内在分解引入到基于 NeRF 的~\cite{mildenhall2020nerf} 神经渲染方法中，并且可以在现有的逆向渲染结合神经渲染方法的同时在房间规模的场景中执行可编辑的新视图合成~ \cite{zhang2021physg, zhang2022modeling} 只能用于特定对象的场景。鉴于内在分解本质上是一个模棱两可且约束不足的逆问题，我们提出了一种新颖的距离感知点采样和自适应反射率迭代聚类优化方法，该方法使具有传统内在分解约束的 IntrinsicNeRF 能够以无监督的方式进行训练，从而在时间上一致的内在分解结果。为了解决场景中相似反射率的不同相邻实例被错误地聚集在一起的问题，我们进一步提出了一种从粗到细优化的层次聚类方法，以获得快速的层次索引表示。它支持引人注目的实时增强现实应用，例如场景重新着色、材质编辑和照明变化。 Blender 对象和副本场景的大量实验表明，即使对于具有挑战性的序列，我们也可以获得高质量、一致的内在分解结果和高保真新视图合成。项目网页上提供了代码和数据：此 https 网址。
## Sep25 - Oct1, 2022
  - [SCI：用于生物医学数据的频谱集中隐式神经压缩](https://arxiv.org/abs/2209.15180) | [code]
    > 海量医疗数据的海量采集和爆炸式增长，需要有效压缩以实现高效存储、传输和共享。现成的视觉数据压缩技术已被广泛研究，但针对自然图像/视频量身定制，因此在具有不同特征的医学数据上表现出有限的性能。新兴的隐式神经表示 (INR) 正在获得动力，并展示了以特定于目标数据的方式拟合各种视觉数据的高前景，但迄今为止还没有涵盖各种医疗数据的通用压缩方案。为了解决这个问题，我们首先对 INR 的频谱集中特性进行了数学解释，并对面向压缩的 INR 架构的设计进行了分析洞察。此外，我们设计了一个漏斗形神经网络，能够覆盖广泛的复杂医疗数据并实现高压缩比。在此设计的基础上，我们在给定预算下通过优化进行压缩，并提出了一种自适应压缩方法SCI，该方法将目标数据自适应地划分为与所采用的INR的集中频谱包络匹配的块，并在给定压缩比下分配具有高表示精度的参数.实验表明 SCI 优于传统技术的性能以及在各种医学数据中的广泛适用性。
  - [从图像对中提取样式以进行全局正向和反向色调映射, CVMP2022](https://arxiv.org/abs/2209.15165) | [code]
    > 许多图像增强或编辑操作，例如正向和反向色调映射或颜色分级，没有唯一的解决方案，而是有一系列解决方案，每个解决方案代表不同的风格。尽管如此，现有的基于学习的方法试图学习一个独特的映射，而忽略了这种风格。在这项工作中，我们展示了有关风格的信息可以从图像对的集合中提取并编码为 2 维或 3 维向量。这不仅为我们提供了有效的表示，而且为编辑图像样式提供了可解释的潜在空间。我们将一对图像之间的全局颜色映射表示为自定义归一化流，以像素颜色的多项式为条件。我们表明，这样的网络在低维空间中编码图像风格方面比 PCA 或 VAE 更有效，并且让我们获得接近 40 dB 的准确度，这比现有技术提高了大约 7-10 dB方法。
  - [迈向多时空尺度广义 PDE 建模](https://arxiv.org/abs/2209.15616) | [code]
    > 偏微分方程 (PDE) 是描述复杂物理系统模拟的核心。他们昂贵的解决方案技术引起了人们对基于深度神经网络的代理的兴趣增加。然而，训练这些代理人的实际效用取决于他们模拟复杂的多尺度时空现象的能力。已经提出了各种神经网络架构来针对此类现象，最着名的是傅里叶神经算子（FNO），它通过不同傅里叶模式的参数化对局部\和全局空间信息进行自然处理，以及通过以下方式处理局部和全局信息的 U-Nets下采样和上采样路径。然而，跨不同方程参数或不同时间尺度的泛化仍然是一个挑战。在这项工作中，我们对涡流和速度函数形式的流体力学问题的各种 FNO 和 U-Net 方法进行了全面比较。对于 U-Net，我们从计算机视觉中转移了最近的架构改进，最显着的是来自对象分割和生成建模。我们进一步分析了使用 FNO 层来提高 U-Net 架构的性能而不显着降低计算性能的设计考虑因素。最后，我们展示了使用单个代理模型泛化到不同 PDE 参数和时间尺度的有希望的结果。
  - [时间相关 PDE 的隐式神经空间表示](https://arxiv.org/abs/2210.00124) | [code]
    > 数值求解偏微分方程 (PDE) 通常需要空间和时间离散化。传统方法（例如，有限差分、有限元、平滑粒子流体动力学）经常采用显式空间离散化，例如网格、网格和点云，其中每个自由度对应于空间中的一个位置。虽然这些明确的空间对应对于建模和理解来说是直观的，但这些表示对于准确性、内存使用或适应性而言不一定是最佳的。在这项工作中，我们探索隐式神经表示作为替代空间离散化，其中空间信息隐式存储在神经网络权重中。通过隐式神经空间表示，受 PDE 约束的时间步长转化为更新神经网络权重，它自然地与常用的优化时间积分器集成。我们通过涉及大弹性变形、湍流流体和多尺度现象的示例验证了我们在各种经典 PDE 上的方法。虽然计算速度比传统表示慢，但我们的方法表现出更高的准确性、更低的内存消耗和动态自适应分配的自由度，而无需复杂的重新划分网格。
  - [具有隐式神经表示的连续 PDE 动态预测](https://arxiv.org/abs/2209.14855) | [code]
    > 有效的数据驱动 PDE 预测方法通常依赖于固定的空间和/或时间离散化。这增加了现实世界应用的限制，例如需要在任意时空位置进行灵活外推的天气预报。我们通过引入一种新的数据驱动方法 DINo 来解决这个问题，该方法使用空间连续函数的连续时间动态对 PDE 的流进行建模。这是通过在由学习的 ODE 时间驱动的小潜在空间中通过隐式神经表示独立于其离散化嵌入空间观察来实现的。这种对时间和空间的分离和灵活处理使 DINo 成为第一个结合以下优点的数据驱动模型。它在任意空间和时间位置外推；它可以从稀疏的不规则网格或流形中学习；在测试时，它会推广到新的网格或分辨率。在代表性 PDE 系统的各种具有挑战性的泛化场景中，DINo 的表现优于替代神经 PDE 预测器。
  - [面向多边形几何的通用表示学习, GeoInformatica](https://arxiv.org/abs/2209.15458) | [code]
    > 空间数据的神经网络表示学习是地理人工智能 (GeoAI) 问题的普遍需求。近年来，在点、折线和网络的表示学习方面取得了许多进展，而在多边形，尤其是复杂的多边形几何形状方面进展甚微。在这项工作中，我们专注于开发一种通用的多边形编码模型，该模型可以将多边形几何体（有或没有孔，单面或多面体）编码到嵌入空间中。结果嵌入可以直接用于（或微调）下游任务，例如形状分类、空间关系预测等。为了实现模型的泛化性保证，我们确定了一些理想的属性：循环原点不变性、平凡顶点不变性、部分置换不变性和拓扑感知。我们探索了两种不同的编码器设计：一种是在空间域中派生所有表示；另一个利用谱域表示。对于空间域方法，我们提出了 ResNet1D，这是一种基于 CNN 的 1D 多边形编码器，它使用圆形填充来实现简单多边形上的循环原点不变性。对于谱域方法，我们开发了基于非均匀傅里叶变换 (NUFT) 的 NUFTspec，它自然地满足了所有所需的属性。我们对两个任务进行了实验：1）基于MNIST的形状分类； 2）基于两个新数据集——DBSR-46K和DBSR-cplx46K的空间关系预测。我们的结果表明，NUFTspec 和 ResNet1D 的性能优于多个现有的基线，具有显着的优势。虽然 ResNet1D 在形状不变几何修改后模型性能下降，但由于 NUFT 的性质，NUFTspec 对这些修改非常稳健。
  - [通过控制屏障功能和神经辐射场增强基于视觉的控制器的安全性](https://arxiv.org/abs/2209.12266) | [code]
    > 为了在复杂的环境中导航，机器人必须越来越多地使用高维视觉反馈（例如图像）进行控制。然而，依靠高维图像数据做出控制决策会引发重要问题；特别是，我们如何证明视觉反馈控制器的安全性？控制障碍函数 (CBF) 是在状态反馈设置中验证反馈控制器安全性的强大工具，但由于需要预测未来的观察结果以评估障碍函数，CBF 传统上不太适合视觉反馈控制.在这项工作中，我们利用神经辐射场 (NeRFs) 的最新进展来解决这个问题，神经辐射场 (NeRFs) 学习 3D 场景的隐式表示并可以从以前看不见的相机视角渲染图像，为基于 CBF 的单步视觉预测提供控制器。这种新颖的组合能够过滤掉不安全的行为并进行干预以保护安全。我们在实时模拟实验中展示了我们的控制器的效果，它成功地防止了机器人采取危险行动。
  - [WaterNeRF：水下场景的神经辐射场](https://arxiv.org/abs/2209.13091) | [code]
    > 水下成像是海洋机器人执行的一项关键任务，其应用范围广泛，包括水产养殖、海洋基础设施检查和环境监测。然而，水柱效应，例如衰减和反向散射，会极大地改变水下捕获图像的颜色和质量。由于不同的水条件和这些影响的范围依赖性，恢复水下图像是一个具有挑战性的问题。这会影响下游感知任务，包括深度估计和 3D 重建。在本文中，我们推进了神经辐射场 (NeRF) 的最新技术，以实现基于物理的密集深度估计和颜色校正。我们提出的方法 WaterNeRF 估计了基于物理的水下图像形成模型的参数，从而产生了混合数据驱动和基于模型的解决方案。在确定场景结构和辐射场后，我们可以生成退化和校正的水下图像的新视图，以及场景的密集深度。我们在真实的水下数据集上定性和定量地评估所提出的方法。
## Sep18 - Sep24, 2022
  - [感觉怎么样？ 用于越野车辆可穿越性的自我监督成本图学习](https://arxiv.org/abs/2209.10788) | [code]
    > 估计越野环境中的地形可穿越性需要推理机器人与这些地形之间的复杂交互动力学。然而，对于这些交互，构建准确的物理模型或创建信息标签以有监督的方式学习模型具有挑战性。我们提出了一种方法，该方法通过以自我监督的方式将外部感知环境信息与本体感知地形交互反馈相结合来学习预测可遍历性成本图。此外，我们提出了一种将机器人速度纳入成本图预测管道的新方法。我们在具有挑战性的越野地形的大型自主全地形车 (ATV) 上的多个短距离和大规模导航任务中验证了我们的方法，并证明了在单独的大型地面机器人上易于集成。我们的短尺度导航结果表明，使用我们学习的成本图可以使导航整体更顺畅，并为机器人提供对机器人与不同地形类型（如草地和砾石）之间相互作用的更细粒度的理解。我们的大规模导航试验表明，在 400 米到 3150 米的具有挑战性的越野路线中，与基于占用的导航基线相比，我们可以将干预次数减少多达 57%。
  - [wildNeRF：使用稀疏单目数据捕获的野外动态场景的完整视图合成](https://arxiv.org/abs/2209.10399) | [code]
    > 我们提出了一种新的神经辐射模型，该模型可以以自我监督的方式进行训练，用于动态非结构化场景的新视图合成。我们的端到端可训练算法可在几秒钟内学习高度复杂的真实静态场景，并在几分钟内学习具有刚性和非刚性运动的动态场景。通过区分静态像素和以运动为中心的像素，我们从一组稀疏的图像中创建高质量的表示。我们对现有基准进行了广泛的定性和定量评估，并在具有挑战性的 NVIDIA 动态场景数据集上设置了最先进的性能指标。此外，我们在具有挑战性的现实世界数据集（例如 Cholec80 和 SurgicalActions160）上评估我们的模型性能。
  - [密度感知 NeRF 集成：量化神经辐射场中的预测不确定性](https://arxiv.org/abs/2209.08718) | [code]
    > 我们表明，如果考虑到密度感知认知不确定性项，则集成有效地量化了神经辐射场 (NeRFs) 中的模型不确定性。在先前的工作中研究的朴素集成只是简单地平均渲染的 RGB 图像，以量化由观察到的场景的相互矛盾的解释引起的模型不确定性。相比之下，由于缺乏关于训练期间未观察到的场景部分的知识，我们还考虑了沿单个射线的终止概率来识别认知模型的不确定性。我们在已建立的 NeRF 不确定性量化基准中实现了新的最先进的性能，优于需要对 NeRF 架构和训练机制进行复杂更改的方法。我们进一步证明了 NeRF 不确定性可用于次佳视图选择和模型细化。
  - [LATITUDE：在城市规模的 NeRF 中使用截断动态低通滤波器进行机器人全局定位, ICRA2023](https://arxiv.org/abs/2209.08498) | [***``[code]``***](https://github.com/jike5/LATITUDE)
    > 神经辐射场 (NeRFs) 在表示具有高分辨率细节和高效内存的复杂 3D 场景方面取得了巨大成功。然而，当前基于 NeRF 的姿态估计器没有初始姿态预测，并且在优化过程中容易出现局部最优。在本文中，我们提出了 LATITUDE：使用截断动态低通滤波器进行全局定位，它在城市规模的 NeRF 中引入了两阶段定位机制。在位置识别阶段，我们通过训练后的 NeRF 生成的图像训练回归器，为全局定位提供初始值。在姿态优化阶段，我们通过直接优化切平面上的姿态来最小化观察图像和渲染图像之间的残差。为了避免收敛到局部最优，我们引入了截断动态低通滤波器 (TDLF) 用于从粗到细的姿态配准。我们在合成数据和真实世界数据上评估我们的方法，并展示其在大规模城市场景中高精度导航的潜在应用。代码和数据将在此 https 网址上公开提供。
  - [医学影像分割的隐式神经表示, MICCAI2022](https://link.springer.com/chapter/10.1007/978-3-031-16443-9_42) | [code]
    > 医学成像中的 3D 信号（例如 CT 扫描）通常被参数化为体素的离散网格。例如，现有的最先进的器官分割方法学习离散的分割图。不幸的是，这些方法的内存需求随着空间分辨率的增加而呈立方增长，这使得它们不适合处理高分辨率扫描。为了克服这个问题，我们设计了一个隐式器官分割网络 (IOSNet)，它利用连续的隐式神经表示并具有几个有用的属性。首先，IOSNet 解码器内存大致恒定且独立于空间分辨率，因为它将分割图参数化为连续函数。其次，IOSNet 的收敛速度比基于离散体素的方法快得多，因为它能够准确地分割器官而不受器官大小的影响，从而在不需要任何辅助技巧的情况下缓解大小不平衡问题。第三，由于其连续学习表示，IOSNet 自然支持超分辨率（即在推理过程中以任意分辨率采样）。此外，尽管使用了一个简单的轻量级解码器，IOSNet 始终优于离散专业分割架构 UNet。因此，我们的方法表明隐式神经表示非常适合医学成像应用，尤其是处理高分辨率 3D 医学扫描。
## Sep11 - Sep17, 2022
  - [DevNet：通过密度体积构建的自监督单目深度学习, ECCV2022](https://arxiv.org/abs/2209.06351) | [code]
    > 单目图像的自监督深度学习通常依赖于时间相邻图像帧之间的 2D 像素级光度关系。然而，它们既没有充分利用 3D 逐点几何对应，也没有有效地解决由遮挡或照明不一致引起的光度翘曲的模糊性。为了解决这些问题，这项工作提出了密度体积构建网络 (DevNet)，这是一种新颖的自我监督单目深度学习框架，可以考虑 3D 空间信息，并利用相邻相机平截头体之间更强的几何约束。我们的 DevNet 不是直接从单个图像中回归像素值，而是将相机平截头体划分为多个平行平面，并预测每个平面上的逐点遮挡概率密度。最终的深度图是通过沿相应光线对密度进行积分来生成的。在训练过程中，引入了新的正则化策略和损失函数来减轻光度模糊和过拟合。在没有明显扩大模型参数大小或运行时间的情况下，DevNet 在 KITTI-2015 室外数据集和 NYU-V2 室内数据集上都优于几个具有代表性的基线。特别是，在深度估计任务中，KITTI-2015 和 NYU-V2 上的 DevNet 的均方根偏差降低了约 4%。此 https 网址提供了代码。
  - [学习用于视图合成的统一 3D 点云](https://arxiv.org/abs/2209.05013) | [code]
    > 基于 3D 点云表示的视图合成方法已证明是有效的。然而，现有方法通常仅从单个源视图合成新视图，并且将它们泛化以处理多个源视图以追求更高的重建质量并非易事。在本文中，我们提出了一种新的基于深度学习的视图合成范式，它从不同的源视图中学习统一的 3D 点云。具体来说，我们首先通过根据深度图将源视图投影到 3D 空间来构建子点云。然后，我们通过自适应融合子点云联合上定义的局部邻域中的点来学习统一的 3D 点云。此外，我们还提出了一个 3D 几何引导图像恢复模块来填充孔洞并恢复渲染新视图的高频细节。三个基准数据集的实验结果表明，我们的方法在数量上和视觉上都在很大程度上优于最先进的视图合成方法。
  - [用于稀疏视图计算机断层扫描的自监督坐标投影网络](https://arxiv.org/abs/2209.05483) | [code]
    > 在目前的工作中，我们提出了一种自监督坐标投影网络（SCOPE），通过解决逆断层扫描成像问题，从单个 SV 正弦图重建无伪影的 CT 图像。与最近使用隐式神经表示网络 (INR) 解决类似问题的相关工作相比，我们的重要贡献是一种有效且简单的重投影策略，该策略将断层扫描图像重建质量提高到有监督的深度学习 CT 重建工作之上。所提出的策略受到线性代数和逆问题之间简单关系的启发。为了求解欠定线性方程组，我们首先引入INR，通过图像连续性先验来约束解空间并获得粗解。其次，我们建议生成密集视图正弦图，提高线性方程组的秩并产生更稳定的 CT 图像解空间。我们的实验结果表明，重投影策略显着提高了图像重建质量（PSNR 至少 +3 dB）。此外，我们将最近的哈希编码集成到我们的 SCOPE 模型中，这极大地加速了模型训练。最后，我们在并行和扇形 X 射线束 SVCT 重建任务中评估 SCOPE。实验结果表明，所提出的 SCOPE 模型在数量和质量上都优于两种最新的基于 INR 的方法和两种流行的监督 DL 方法。
  - [CU-Net：高效的点云颜色上采样网络](https://arxiv.org/abs/2209.06112) | [code]
    > 增强现实、虚拟现实和远程呈现场景需要点云上采样。尽管几何上采样被很好地研究以致密点云坐标，但颜色的上采样在很大程度上被忽略了。在本文中，我们提出了第一个深度学习点云颜色上采样模型 CU-Net。利用基于稀疏卷积的特征提取器和基于神经隐函数的颜色预测模块，CU-Net 实现了线性时间和空间复杂度。因此，理论上保证 CU-Net 比大多数具有二次复杂度的现有方法更有效。实验结果表明，CU-Net 可以实时为具有近百万个点的照片般逼真的点云着色，同时具有比基线更好的视觉质量。此外，CU-Net 可以适应任意的上采样率和看不见的对象。我们的源代码将很快向公众发布。
## Sep4 - Sep10, 2022
  - [具有深度神经表示的隐式全波形反演](https://arxiv.org/abs/2209.03525) | [code]
    > 全波形反演（FWI）通常代表最先进的地下结构和物理参数成像方法，然而，其实施通常面临巨大挑战，例如建立一个良好的初始模型以摆脱局部最小值，以及评估反演结果的不确定性。在本文中，我们提出了使用连续和隐式定义的深度神经表示的隐式全波形反演（IFWI）算法。与对初始模型敏感的 FWI 相比，IFWI 受益于深度学习优化增加的自由度，从而允许从随机初始化开始，这大大降低了非唯一性和陷入局部最小值的风险。理论和实验分析均表明，在给定随机初始模型的情况下，IFWI 能够收敛到全局最小值，并生成具有精细结构的地下高分辨率图像。此外，IFWI 的不确定性分析可以很容易地通过使用各种深度学习方法近似贝叶斯推理来执行，本文通过添加 dropout 神经元对其进行分析。此外，IFWI具有一定的鲁棒性和较强的泛化能力，在各种二维地质模型的实验中得到了体现。通过适当的设置，IFWI也可以很好地适用于多尺度联合地球物理反演。
## Aug28 - Sep3, 2022
  - [FoV-NeRF：虚拟现实的中心凹神经辐射场, TVCG2022](https://ieeexplore.ieee.org/abstract/document/9872532) | [code]
    > 随着消费者显示器和商业 VR 平台的兴起，虚拟现实 (VR) 正变得无处不在。这种显示需要低延迟和高质量的合成图像渲染，同时减少计算开销。神经渲染的最新进展表明，有望通过基于图像的虚拟或物理环境表示来解锁 3D 计算机图形的新可能性。具体来说，神经辐射场 (NeRF) 表明，可以在不损失与视图相关的效果的情况下实现 3D 场景的照片般逼真的质量和连续视图变化。虽然 NeRF 可以显着受益于 VR 应用的渲染，但它面临着由高视场、高分辨率和立体/以自我为中心的观看带来的独特挑战，通常会导致渲染图像的低质量和高延迟。在 VR 中，这不仅会损害交互体验，还可能导致疾病。为了解决 VR 中的六自由度、以自我为中心和立体 NeRF 的这些问题，我们提出了第一个注视条件 3D 神经表示和视图合成方法。我们将视觉和立体敏锐度的人类心理物理学纳入 3D 风景的以自我为中心的神经表示中。然后，我们共同优化延迟/性能和视觉质量，同时相互桥接人类感知和神经场景合成，以实现感知上高质量的沉浸式交互。我们进行了客观分析和主观研究，以评估我们方法的有效性。我们发现我们的方法显着减少了延迟（与 NeRF 相比减少了高达 99% 的时间），而不会损失高保真渲染（在感知上与全分辨率地面实况相同）。所提出的方法可能是迈向未来实时捕捉、传送和可视化远程环境的 VR/AR 系统的第一步。
  - [克隆：用于占用网格辅助神经表示的相机-激光雷达融合](https://arxiv.org/abs/2209.01194) | [code]
    > 本文提出了 CLONeR，它通过允许对从稀疏输入传感器视图观察到的大型户外驾驶场景进行建模，显着改进了 NeRF。这是通过将 NeRF 框架内的占用和颜色学习解耦为分别使用 LiDAR 和相机数据训练的单独的多层感知器 (MLP) 来实现的。此外，本文提出了一种在 NeRF 模型旁边构建可微分 3D 占用网格图 (OGM) 的新方法，并利用此占用网格改进沿射线的点采样，以在度量空间中进行体积渲染。
## Aug21 - Aug27, 2022
## Aug14 - Aug20, 2022
## Aug7 - Aug13, 2022
  - [HyperTime：时间序列的隐式神经表示](https://arxiv.org/abs/2208.05836) | [code]
    > 隐式神经表示 (INR) 最近已成为一种强大的工具，可提供准确且与分辨率无关的数据编码。它们作为通用逼近器的鲁棒性已在各种数据源中得到证明，并应用于图像、声音和 3D 场景表示。然而，很少有人关注利用这些架构来表示和分析时间序列数据。在本文中，我们使用 INR 分析时间序列的表示，比较不同的激活函数在重建精度和训练收敛速度方面。我们展示了如何利用这些网络对时间序列进行插补，以及在单变量和多变量数据上的应用。最后，我们提出了一种利用 INR 来学习整个时间序列数据集的压缩潜在表示的超网络架构。我们引入了基于 FFT 的损失来指导训练，以便在时间序列中保留所有频率。我们展示了该网络可用于将时间序列编码为 INR，并且可以对它们的嵌入进行插值以从现有的时间序列中生成新的时间序列。我们通过将其用于数据增强来评估我们的生成方法，并表明它与当前最先进的时间序列增强方法具有竞争力。
  - [NIDN：纳米结构的神经逆向设计](https://arxiv.org/abs/2208.05480) | [code]
    > 近十年来，计算工具已成为材料设计的核心，以降低成本实现快速开发周期。机器学习工具在光子学领域尤其兴起。然而，从优化的角度来看，设计所需的麦克斯韦方程的反演特别具有挑战性，需要复杂的软件。我们提出了一种创新的开源软件工具，称为纳米结构的神经逆向设计 (NIDN)，它允许使用基于物理的深度学习方法设计复杂的堆叠材料纳米结构。我们执行基于梯度的神经网络训练，而不是无导数或数据驱动的优化或学习方法，在这种训练中，我们根据其光谱特性直接优化材料及其结构。 NIDN 支持两种不同的求解器，严格的耦合波分析和有限差分时域方法。 NIDN 的实用性和有效性在几个合成示例以及 1550 nm 滤光片和抗反射涂层的设计中得到了证明。结果与实验基线、其他模拟工具和所需的光谱特性相匹配。鉴于其在网络架构和 Maxwell 求解器方面的完全模块化以及开源、许可的可用性，NIDN 将能够支持广泛应用中的计算材料设计过程。
  - [使用隐式神经表示的蒙特卡罗去噪](https://oaktrust.library.tamu.edu/handle/1969.1/196567) | [code]
    > Monte Carlo 路径追踪是计算机图形学中流行的 3D 渲染技术，但它通常需要在图像中的噪声量和计算时间之间进行代价高昂的权衡。因此，尝试“平滑”噪声图像是有用的，通常通过在样本之间构建新数据或对图像应用过滤器。在这项工作中，我们研究了训练神经网络以将固定视点场景的亮度隐式表示为连续函数的可行性。我们使用多层感知器网络实现神经网络，并在由离线 Monte Carlo 渲染器生成的稀疏采样图像上对其进行训练。该训练数据使用图像平面上每个样本的 (x, y) 坐标作为输入，并将样本的 RGB 颜色作为输出。此外，我们为网络提供第一条光线交点的表面法线、深度和反照率，作为像素坐标旁边的额外输入。这些额外的输入维度通过帮助网络考虑深度、法线和漫反射颜色的变化来提高隐式表示的质量。一旦网络在稀疏采样的场景上得到训练，我们就可以对每个像素的网络进行多次密集采样，以创建最终的去噪图像。我们发现该网络可以在具有柔和照明和光泽反射的场景中快速学习和去噪图像，并且只需少量训练即可轻松处理深度、正常和漫反射颜色的不连续性。
## Jul31 - Aug6, 2022
## Jul24 - Jul30, 2022
  - [DoF-NeRF：景深与神经辐射场相遇, ACMMM2022](https://arxiv.org/pdf/2208.00945) | [***``[code]``***](https://github.com/zijinwuzijin/DoF-NeRF)
    > 神经辐射场 (NeRF) 及其变体在表示 3D 场景和合成逼真的新颖视图方面取得了巨大成功。但是，它们通常基于针孔相机模型并假设全焦点输入。这限制了它们的适用性，因为从现实世界捕获的图像通常具有有限的景深 (DoF)。为了缓解这个问题，我们引入了 DoF-NeRF，一种新颖的神经渲染方法，可以处理浅自由度输入并可以模拟自由度效果。特别是，它根据几何光学原理扩展了 NeRF 以模拟镜头的孔径。这样的物理保证允许 DoF-NeRF 操作具有不同焦点配置的视图。得益于显式光圈建模，DoF-NeRF 还可以通过调整虚拟光圈和焦点参数来直接操纵 DoF 效果。它是即插即用的，可以插入到基于 NeRF 的框架中。在合成数据集和真实世界数据集上的实验表明，DoF-NeRF 不仅在全焦点设置中的性能与 NeRF 相当，而且还可以合成以浅自由度输入为条件的全焦点新视图。还演示了 DoF-NeRF 在 DoF 渲染中的一个有趣应用。
  - [神经密度-距离场, ECCV2022](https://arxiv.org/abs/2207.14455) | [***``[code]``***](https://ueda0319.github.io/neddf/)
    > 神经领域在 3D 视觉任务中的成功现在是无可争辩的。遵循这一趋势，已经提出了几种针对视觉定位的方法（例如，SLAM）来使用神经场估计距离或密度场。然而，仅通过基于密度场的方法（例如神经辐射场 (NeRF)）很难实现高定位性能，因为它们在大多数空白区域中不提供密度梯度。另一方面，基于距离场的方法，例如神经隐式表面 (NeuS)，在对象的表面形状方面存在局限性。本文提出了神经密度-距离场 (NeDDF)，这是一种新的 3D 表示，它相互约束距离和密度场。我们将距离场公式扩展到没有明确边界表面的形状，例如毛皮或烟雾，这使得从距离场到密度场的显式转换成为可能。通过显式转换实现的一致距离和密度场既能保证初始值的鲁棒性，又能实现高质量的配准。此外，场之间的一致性允许从稀疏点云快速收敛。实验表明，NeDDF 可以实现高定位性能，同时在新颖的视图合成上提供与 NeRF 相当的结果。该代码可在此 https URL 获得。
  - [通过 NeRF Attention 进行端到端视图合成](https://arxiv.org/abs/2207.14741) | [code]
    > 在本文中，我们提出了一个用于视图合成的简单 seq2seq 公式，其中我们将一组光线点作为输入和输出与光线相对应的颜色。在这个 seq2seq 公式上直接应用标准转换器有两个限制。首先，标准注意力不能成功地适应体积渲染过程，因此合成视图中缺少高频分量。其次，将全局注意力应用于所有光线和像素是非常低效的。受神经辐射场 (NeRF) 的启发，我们提出了 NeRF 注意力 (NeRFA) 来解决上述问题。一方面，NeRFA 将体积渲染方程视为软特征调制过程。通过这种方式，特征调制增强了具有类似 NeRF 电感偏置的变压器。另一方面，NeRFA 执行多阶段注意力以减少计算开销。此外，NeRFA 模型采用光线和像素转换器来学习光线和像素之间的相互作用。 NeRFA 在四个数据集上展示了优于 NeRF 和 NerFormer 的性能：DeepVoxels、Blender、LLFF 和 CO3D。此外，NeRFA 在两种设置下建立了新的 state-of-the-art：单场景视图合成和以类别为中心的新颖视图合成。该代码将公开发布。
  - [神经链：从多视图图像中学习头发的几何形状和外观, ECCV2022](https://arxiv.org/pdf/2207.14067) | [***``[code]``***](https://radualexandru.github.io/neural_strands/)
    > 我们提出了 Neural Strands，这是一种新颖的学习框架，用于从多视图图像输入中对精确的头发几何形状和外观进行建模。学习的头发模型可以从具有高保真视图相关效果的任何视点实时渲染。与体积模型不同，我们的模型实现了直观的形状和样式控制。为了实现这些特性，我们提出了一种基于神经头皮纹理的新型头发表示，该神经头皮纹理对每个纹素位置的单个股线的几何形状和外观进行编码。此外，我们引入了一种基于学习发束光栅化的新型神经渲染框架。我们的神经渲染是精确的和抗锯齿的，使渲染视图一致且逼真。将外观与多视图几何先验相结合，我们首次实现了从多视图设置中联合学习外观和显式头发几何形状。我们展示了我们的方法在各种发型的保真度和效率方面的有效性。
  - [拉普拉斯系统的神经格林函数, Computer & Graphics](https://www.sciencedirect.com/science/article/pii/S0097849322001406) | [code]
    > 求解源自拉普拉斯算子的线性方程组是广泛应用的核心。由于线性系统的稀疏性，当解具有大量自由度时，通常采用迭代求解器，例如共轭梯度和多重网格。这些迭代求解器可以看作是拉普拉斯算子格林函数的稀疏近似。在本文中，我们提出了一种机器学习方法，该方法从边界条件中回归格林函数。这是通过格林函数实现的，该函数可以以多尺度方式有效地表示，从而大大降低了与密集矩阵表示相关的成本。此外，由于格林函数完全依赖于边界条件，因此训练所提出的神经网络不需要对线性系统的右侧进行采样。结果表明，我们的方法优于最先进的共轭梯度和多重网格方法。
  - [关于物理概念的可学习性：神经网络能理解什么是真](https://arxiv.org/abs/2207.12186) | [code]
    > 鉴于深度神经网络生成逼真的合成数据的卓越能力，我们重新审视了经典的信号到符号障碍。 DeepFakes 和欺骗突出了物理现实与其抽象表示之间联系的脆弱性，无论是由数字计算机还是生物代理学习。从一个广泛适用的抽象概念定义开始，我们表明标准的前馈架构只能捕获微不足道的概念，无论权重的数量和训练数据的数量如何，尽管它们是非常有效的分类器。另一方面，包含递归的架构可以代表更大的概念类别，但可能仍然无法从有限的数据集中学习它们。我们定性地描述了可以被用随机梯度下降变体训练的现代架构“理解”的概念类别，使用（自由能）拉格朗日来测量信息复杂性。然而，即使一个概念已经被理解，网络也无法将其理解传达给外部代理，除非通过持续的交互和验证。然后，我们将物理对象表征为抽象概念，并使用前面的分析来表明物理对象可以由有限架构编码。然而，为了理解物理概念，传感器必须提供持续令人兴奋的观察，而控制数据采集过程的能力是必不可少的（主动感知）。控制的重要性取决于形式，比听觉或化学感知更有益于视觉。最后，我们得出结论，可以在有限的时间内用有限的资源将物理实体绑定到数字身份，原则上解决了信号到符号的障碍问题，但我们强调了持续验证的必要性。
## Previous weeks
  - [﻿Plenoxels：没有神经网络的辐射场, CVPR2022(oral)](https://arxiv.org/abs/2112.05131) | [***``[code]``***](https://alexyu.net/plenoxels)
    > 我们介绍了 Plenoxels（全光体素），一种用于照片级真实视图合成的系统。 Plenoxels 将场景表示为具有球谐函数的稀疏 3D 网格。这种表示可以通过梯度方法和正则化从校准图像中优化，而无需任何神经组件。在标准的基准任务中，Plenoxels 的优化速度比神经辐射场快两个数量级，而视觉质量没有损失。
  - [城市辐射场, CVPR2022](https://urban-radiance-fields.github.io/) | [code]
    > 这项工作的目标是从扫描平台捕获的数据中执行 3D 重建和新颖的视图合成，这些平台通常用于城市户外环境（例如街景）中的世界地图绘制。给定一系列由相机和扫描仪在户外场景中移动获得的 RGB 图像序列和激光雷达扫描，我们生成了一个模型，可以从中提取 3D 表面并合成新的 RGB 图像。我们的方法扩展了神经辐射场，该方法已被证明可以在受控环境中为小场景合成逼真的新颖图像，以及利用异步捕获的激光雷达数据、解决捕获图像之间的曝光变化以及利用预测的图像分割来监督密度的新方法在指向天空的光线上。这三个扩展中的每一个都在街景数据的实验中提供了显着的性能改进。与传统方法（例如~COLMAP）和最近的神经表示（例如~Mip-NeRF）相比，我们的系统产生最先进的 3D 表面重建并合成更高质量的新视图。
  - [NeRF：将场景表示为用于视图合成的神经辐射场, ECCV2020](https://arxiv.org/abs/2003.08934) | [***``[code]``***](http://tancik.com/nerf)
    > 我们提出了一种方法，该方法通过使用稀疏输入视图集优化底层连续体积场景函数，实现了合成复杂场景的新视图的最新结果。我们的算法使用全连接（非卷积）深度网络表示场景，其输入是单个连续 5D 坐标（空间位置（x,y,z）和观察方向（θ,φ）），其输出是该空间位置的体积密度和与视图相关的发射辐射。我们通过沿相机光线查询 5D 坐标来合成视图，并使用经典的体渲染技术将输出颜色和密度投影到图像中。因为体积渲染是自然可微的，所以优化我们的表示所需的唯一输入是一组具有已知相机姿势的图像。我们描述了如何有效地优化神经辐射场以渲染具有复杂几何形状和外观的场景的逼真的新颖视图，并展示了优于先前在神经渲染和视图合成方面的工作的结果。查看合成结果最好以视频形式观看，因此我们敦促读者观看我们的补充视频以进行令人信服的比较。
  - [野外的 NeRF：无约束照片集的神经辐射场, CVPR2021](https://arxiv.org/abs/2008.02268) | [code]
    > 我们提出了一种基于学习的方法，用于仅使用野外照片的非结构化集合来合成复杂场景的新视图。我们建立在神经辐射场 (NeRF) 的基础上，它使用多层感知器的权重将场景的密度和颜色建模为 3D 坐标的函数。虽然 NeRF 在受控设置下捕获的静态对象的图像上效果很好，但它无法在不受控的图像中模拟许多普遍存在的真实世界现象，例如可变照明或瞬态遮挡物。我们为 NeRF 引入了一系列扩展来解决这些问题，从而能够从互联网上获取的非结构化图像集合中进行准确的重建。我们将我们的系统（称为 NeRF-W）应用于著名地标的互联网照片集，并展示时间一致的新颖视图渲染，这些渲染比现有技术更接近真实感。
  - [Ha-NeRF：野外的幻觉神经辐射场, CVPR2022](https://rover-xingyu.github.io/Ha-NeRF/) | [***``[code]``***](https://github.com/rover-xingyu/Ha-NeRF)
    > 神经辐射场 (NeRF) 最近因其令人印象深刻的新颖视图合成能力而广受欢迎。本文研究了幻觉 NeRF 的问题：即在一天中的不同时间从一组旅游图像中恢复一个真实的 NeRF。现有的解决方案采用具有可控外观嵌入的 NeRF 在各种条件下渲染新颖的视图，但它们无法渲染具有看不见的外观的视图一致图像。为了解决这个问题，我们提出了一个用于构建幻觉 NeRF 的端到端框架，称为 Ha-NeRF。具体来说，我们提出了一个外观幻觉模块来处理随时间变化的外观并将它们转移到新的视图中。考虑到旅游图像的复杂遮挡，我们引入了一个反遮挡模块来准确地分解静态主体以获得可见性。合成数据和真实旅游照片集的实验结果表明，我们的方法可以产生幻觉，并从不同的视图呈现无遮挡的图像。
  - [Nerfies：可变形的神经辐射场, ICCV2021](https://arxiv.org/abs/2011.12948) | [code]
    > 我们提出了第一种能够使用从手机随便捕获的照片/视频来逼真地重建可变形场景的方法。我们的方法通过优化一个额外的连续体积变形场来增强神经辐射场 (NeRF)，该场将每个观察点扭曲成一个规范的 5D NeRF。我们观察到这些类似 NeRF 的变形场容易出现局部最小值，并为基于坐标的模型提出了一种从粗到细的优化方法，可以实现更稳健的优化。通过将几何处理和物理模拟的原理应用于类似 NeRF 的模型，我们提出了变形场的弹性正则化，进一步提高了鲁棒性。我们表明，我们的方法可以将随意捕获的自拍照片/视频转换为可变形的 NeRF 模型，允许从任意视角对主体进行逼真的渲染，我们称之为“nerfies”。我们通过使用带有两部手机的装备收集时间同步数据来评估我们的方法，从而在不同视点产生相同姿势的训练/验证图像。我们表明，我们的方法忠实地重建了非刚性变形的场景，并以高保真度再现了看不见的视图。
  - [D-NeRF：动态场景的神经辐射场, CVPR2021](https://arxiv.org/abs/2011.13961) | [***``[code]``***](https://github.com/albertpumarola/D-NeRF)
    > 将机器学习与几何推理相结合的神经渲染技术已成为从一组稀疏图像中合成场景新视图的最有前途的方法之一。其中，神经辐射场 (NeRF) 尤为突出，它训练深度网络将 5D 输入坐标（表示空间位置和观察方向）映射为体积密度和与视图相关的发射辐射。然而，尽管在生成的图像上实现了前所未有的真实感水平，但 NeRF 仅适用于静态场景，其中可以从不同的图像中查询相同的空间位置。在本文中，我们介绍了 D-NeRF，这是一种将神经辐射场扩展到动态域的方法，允许在场景中移动的 \emph{single} 相机的刚性和非刚性运动下重建和渲染物体的新图像。为此，我们将时间视为系统的附加输入，并将学习过程分为两个主要阶段：一个将场景编码为规范空间，另一个将这个规范表示映射到特定时间的变形场景。两种映射都是使用全连接网络同时学习的。一旦网络经过训练，D-NeRF 就可以渲染新颖的图像，同时控制相机视图和时间变量，从而控制对象的移动。我们展示了我们的方法在物体处​​于刚性、关节和非刚性运动的场景中的有效性。代码、模型权重和动态场景数据集将发布。
  - [用于单目 4D 面部头像重建的动态神经辐射场, CVPR2021](https://gafniguy.github.io/4D-Facial-Avatars/) | [***``[code]``***](https://github.com/gafniguy/4D-Facial-Avatars)
    > 我们提出了用于模拟人脸外观和动态的动态神经辐射场。对说话的人进行数字建模和重建是各种应用程序的关键组成部分。特别是对于 AR 或 VR 中的远程呈现应用，需要忠实再现外观，包括新颖的视点或头部姿势。与显式建模几何和材料属性或纯粹基于图像的最先进方法相比，我们引入了基于场景表示网络的头部隐式表示。为了处理面部的动态，我们将场景表示网络与低维可变形模型相结合，该模型提供对姿势和表情的显式控制。我们使用体积渲染从这种混合表示中生成图像，并证明这种动态神经场景表示只能从单目输入数据中学习，而不需要专门的捕获设置。在我们的实验中，我们表明这种学习的体积表示允许生成照片般逼真的图像，其质量超过了基于视频的最先进的重演方法的质量。
  - [PVA：像素对齐的体积化身, CVPR2021](https://volumetric-avatars.github.io/) | [code]
    > 逼真的人头的采集和渲染是一个极具挑战性的研究问题，对于虚拟远程呈现特别重要。目前，最高质量是通过在多视图数据上以个人特定方式训练的体积方法实现的。与更简单的基于网格的模型相比，这些模型更好地表示精细结构，例如头发。体积模型通常使用全局代码来表示面部表情，以便它们可以由一小组动画参数驱动。虽然这样的架构实现了令人印象深刻的渲染质量，但它们不能轻易地扩展到多身份设置。在本文中，我们设计了一种新颖的方法，用于在仅给定少量输入的情况下预测人头的体积化身。我们通过一种新颖的参数化实现跨身份的泛化，该参数化将神经辐射场与直接从输入中提取的局部像素对齐特征相结合，从而避免了对非常深或复杂网络的需求。我们的方法仅基于光度重新渲染损失以端到端的方式进行训练，无需明确的 3D 监督。我们证明我们的方法在质量方面优于现有的现有技术，并且能够生成忠实的面部表情多身份设置。
  - [用于人体建模的动画神经辐射场, ICCV2021](https://zju3dv.github.io/animatable_nerf/) | [***``[code]``***](https://github.com/zju3dv/animatable_nerf)
    > 本文解决了从多视图视频中重建可动画人体模型的挑战。最近的一些工作提出将非刚性变形场景分解为规范神经辐射场和一组将观察空间点映射到规范空间的变形场，从而使他们能够从图像中学习动态场景。然而，它们将变形场表示为平移矢量场或 SE(3) 场，这使得优化受到高度约束。此外，这些表示不能由输入运动明确控制。相反，我们引入了神经混合权重场来产生变形场。基于骨架驱动的变形，混合权重场与 3D 人体骨骼一起使用，以生成观察到规范和规范到观察的对应关系。由于 3D 人体骨骼更易观察，它们可以规范变形场的学习。此外，学习到的混合权重场可以与输入的骨骼运动相结合，以生成新的变形场来为人体模型设置动画。实验表明，我们的方法明显优于最近的人类合成方法。该代码将在 https://zju3dv.github.io/animatable_nerf/ 上提供。
  - [NeRF++：分析和改进神经辐射场](https://arxiv.org/abs/2010.07492) | [***``[code]``***](https://github.com/Kai-46/nerfplusplus;)
    > 神经辐射场 (NeRF) 为各种捕捉设置实现了令人印象深刻的视图合成结果，包括有界场景的 360 度捕捉以及有界和无界场景的前向捕捉。 NeRF 将表示视图不变不透明度和视图相关颜色体积的多层感知器 (MLP) 拟合到一组训练图像，并基于体积渲染技术对新视图进行采样。在这份技术报告中，我们首先评论了辐射场及其潜在的模糊性，即形状-辐射模糊度，并分析了 NeRF 在避免这种模糊性方面的成功。其次，我们解决了将 NeRF 应用于大规模、无界 3D 场景中对象的 360 度捕获所涉及的参数化问题。我们的方法在这种具有挑战性的场景中提高了视图合成保真度。此 https 网址提供了代码。
  - [动态场景的神经场景图, CVPR2021(oral)](https://arxiv.org/abs/2011.10379) | [***``[code]``***](https://github.com/princeton-computational-imaging/neural-scene-graphs)
    > 最近的隐式神经渲染方法表明，可以通过仅由一组 RGB 图像监督的预测其体积密度和颜色来学习复杂场景的准确视图合成。然而，现有方法仅限于学习将所有场景对象编码为单个神经网络的静态场景的有效表示，并且缺乏将动态场景表示和分解为单个场景对象的能力。在这项工作中，我们提出了第一个将动态场景分解为场景图的神经渲染方法。我们提出了一种学习的场景图表示，它对对象变换和辐射进行编码，以有效地渲染场景的新颖排列和视图。为此，我们学习隐式编码的场景，并结合联合学习的潜在表示来描述具有单个隐式函数的对象。我们在合成和真实汽车数据上评估所提出的方法，验证我们的方法学习动态场景 - 仅通过观察该场景的视频 - 并允许渲染具有看不见的对象集的新颖场景组合的新颖照片般逼真的视图看不见的姿势。
  - [使用隐式场景表示进行就地场景标记和理解, ICCV2021(oral)](https://shuaifengzhi.com/Semantic-NeRF/) | [***``[code]``***](https://github.com/Harry-Zhi/semantic_nerf/)
    > 语义标签与几何和辐射重建高度相关，因为具有相似形状和外观的场景实体更有可能来自相似的类别。最近的隐式神经重建技术很有吸引力，因为它们不需要事先的训练数据，但同样的完全自我监督的方法对于语义来说是不可能的，因为标签是人类定义的属性。
