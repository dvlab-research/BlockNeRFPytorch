
每周分类神经辐射场 - others ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
===================================================================================================================================
## 按类别筛选: 
 [全部](../weekly_nerf_cn.md) | [动态](./dynamic.md) | [编辑](./editing.md) | [快速](./fast.md) | [泛化](./generalization.md) | [人体](./human.md) | [视频](./video.md) | [光照](./lighting.md) | [重建](./reconstruction.md) | [纹理](./texture.md) | [语义](./semantic.md) | [姿态-SLAM](./pose-slam.md) | [其他](./others.md) 
## Oct2- Oct8, 2022
  - [用于自监督入住预测的可区分光线投射, ECCV2022](https://arxiv.org/abs/2210.01917) | [***``[code]``***](https://github.com/tarashakhurana/emergent-occ-forecasting)
    > 安全自动驾驶的运动规划需要了解自我车辆周围的环境如何随时间演变。场景中可驱动区域的以自我为中心的感知不仅随着环境中演员的运动而变化，而且随着自我车辆本身的运动而变化。为大规模规划（例如以自我为中心的自由空间）提出的自我监督表示混淆了这两种运动，使得该表示难以用于下游运动规划器。在本文中，我们使用几何占用作为自由空间等依赖于视图的表示的自然替代方案。占用图自然地将环境的运动与自我车辆的运动分开。然而，人们无法直接观察场景的完整 3D 占用情况（由于遮挡），因此难以用作学习信号。我们的主要见解是使用可微分光线投射将未来占用预测“渲染”到未来的 LiDAR 扫描预测中，这可以与自监督学习的地面实况扫描进行比较。可微光线投射的使用允许占用率作为预测网络中的内部表示出现。在没有地面实况占用的情况下，我们定量评估了光线投射 LiDAR 扫描的预测，并显示了多达 15 个 F1 点的改进。对于下游运动规划器，紧急占用可以直接用于引导不可驱动区域，与以自由空间为中心的运动规划器相比，这种表示相对减少了高达 17% 的物体碰撞次数。
  - [用于新视图合成的自我改进多平面到层图像, WACV2023](https://samsunglabs.github.io/MLI/) | [***``[code]``***](https://github.com/SamsungLabs/MLI)
    > 我们提出了一种用于轻量级小说视图合成的新方法，该方法可以推广到任意前向场景。最近的方法在计算上很昂贵，需要逐场景优化，或者产生内存昂贵的表示。我们首先用一组正面平行的半透明平面来表示场景，然后以端到端的方式将它们转换为可变形层。此外，我们采用前馈细化程序，通过聚合来自输入视图的信息来纠正估计的表示。我们的方法在处理新场景时不需要微调，并且可以不受限制地处理任意数量的视图。实验结果表明，我们的方法在常用指标和人工评估方面超过了最近的模型，在推理速度和推断分层几何的紧凑性方面具有显着优势，请参阅此 https URL
  - [NARF22：用于配置感知渲染的神经铰接辐射场, IROS2022](https://progress.eecs.umich.edu/projects/narf/) | [code]
    > 铰接物体对机器人的感知和操作提出了独特的挑战。它们增加的自由度数量使得定位等任务在计算上变得困难，同时也使得现实世界数据集收集的过程无法扩展。为了解决这些可扩展性问题，我们提出了神经铰接辐射场 (NARF22)，这是一个使用完全可微分、配置参数化神经辐射场 (NeRF) 作为提供铰接对象高质量渲染的方法的管道。 NARF22 在推理时不需要明确了解对象结构。我们提出了一种两阶段的基于部件的训练机制，即使底层训练数据只有一个配置表示，它也允许对象渲染模型在配置空间中很好地泛化。我们通过在通过 Fetch 移动操作机器人收集的真实关节工具数据集上训练可配置渲染器来展示 NARF22 的功效。我们通过配置估计和 6 自由度姿态细化任务展示了该模型对基于梯度的推理方法的适用性。项目网页位于：此 https URL。
  - [SinGRAV：从单个自然场景中学习生成辐射量](https://arxiv.org/abs/2210.01202) | [code]
    > 我们提出了一个用于一般自然场景的 3D 生成模型。由于缺乏表征目标场景的必要 3D 数据量，我们建议从单个场景中学习。我们的关键见解是，一个自然场景通常包含多个组成部分，其几何、纹理和空间排列遵循一些清晰的模式，但在同一场景中的不同区域仍然表现出丰富的变化。这表明将生成模型的学习本地化在大量局部区域上。因此，我们利用具有空间局部性偏差的多尺度卷积网络来学习单个场景中多个尺度的局部区域的统计信息。与现有方法相比，我们的学习设置绕过了从许多同质 3D 场景中收集数据以学习共同特征的需要。我们创造了我们的方法 SinGRAV，用于从单个自然场景中学习生成辐射体积。我们展示了 SinGRAV 从单个场景生成合理多样的变化的能力，SingGRAV 相对于最先进的生成神经场景方法的优点，以及 SinGRAV 在各种应用中的多功能性，涵盖 3D 场景编辑、合成和动画。代码和数据将被发布以促进进一步的研究。
  - [IntrinsicNeRF：学习用于可编辑新视图合成的内在神经辐射场](https://arxiv.org/abs/2210.00647) | [***``[code]``***](https://github.com/zju3dv/IntrinsicNeRF)
    > 我们提出了被称为 IntrinsicNeRF 的内在神经辐射场，它将内在分解引入到基于 NeRF 的~\cite{mildenhall2020nerf} 神经渲染方法中，并且可以在现有的逆向渲染结合神经渲染方法的同时在房间规模的场景中执行可编辑的新视图合成~ \cite{zhang2021physg, zhang2022modeling} 只能用于特定对象的场景。鉴于内在分解本质上是一个模棱两可且约束不足的逆问题，我们提出了一种新颖的距离感知点采样和自适应反射率迭代聚类优化方法，该方法使具有传统内在分解约束的 IntrinsicNeRF 能够以无监督的方式进行训练，从而在时间上一致的内在分解结果。为了解决场景中相似反射率的不同相邻实例被错误地聚集在一起的问题，我们进一步提出了一种从粗到细优化的层次聚类方法，以获得快速的层次索引表示。它支持引人注目的实时增强现实应用，例如场景重新着色、材质编辑和照明变化。 Blender 对象和副本场景的大量实验表明，即使对于具有挑战性的序列，我们也可以获得高质量、一致的内在分解结果和高保真新视图合成。项目网页上提供了代码和数据：此 https 网址。
## Sep25 - Oct1, 2022
  - [SCI：用于生物医学数据的频谱集中隐式神经压缩](https://arxiv.org/abs/2209.15180) | [code]
    > 海量医疗数据的海量采集和爆炸式增长，需要有效压缩以实现高效存储、传输和共享。现成的视觉数据压缩技术已被广泛研究，但针对自然图像/视频量身定制，因此在具有不同特征的医学数据上表现出有限的性能。新兴的隐式神经表示 (INR) 正在获得动力，并展示了以特定于目标数据的方式拟合各种视觉数据的高前景，但迄今为止还没有涵盖各种医疗数据的通用压缩方案。为了解决这个问题，我们首先对 INR 的频谱集中特性进行了数学解释，并对面向压缩的 INR 架构的设计进行了分析洞察。此外，我们设计了一个漏斗形神经网络，能够覆盖广泛的复杂医疗数据并实现高压缩比。在此设计的基础上，我们在给定预算下通过优化进行压缩，并提出了一种自适应压缩方法SCI，该方法将目标数据自适应地划分为与所采用的INR的集中频谱包络匹配的块，并在给定压缩比下分配具有高表示精度的参数.实验表明 SCI 优于传统技术的性能以及在各种医学数据中的广泛适用性。
  - [从图像对中提取样式以进行全局正向和反向色调映射, CVMP2022](https://arxiv.org/abs/2209.15165) | [code]
    > 许多图像增强或编辑操作，例如正向和反向色调映射或颜色分级，没有唯一的解决方案，而是有一系列解决方案，每个解决方案代表不同的风格。尽管如此，现有的基于学习的方法试图学习一个独特的映射，而忽略了这种风格。在这项工作中，我们展示了有关风格的信息可以从图像对的集合中提取并编码为 2 维或 3 维向量。这不仅为我们提供了有效的表示，而且为编辑图像样式提供了可解释的潜在空间。我们将一对图像之间的全局颜色映射表示为自定义归一化流，以像素颜色的多项式为条件。我们表明，这样的网络在低维空间中编码图像风格方面比 PCA 或 VAE 更有效，并且让我们获得接近 40 dB 的准确度，这比现有技术提高了大约 7-10 dB方法。
  - [迈向多时空尺度广义 PDE 建模](https://arxiv.org/abs/2209.15616) | [code]
    > 偏微分方程 (PDE) 是描述复杂物理系统模拟的核心。他们昂贵的解决方案技术引起了人们对基于深度神经网络的代理的兴趣增加。然而，训练这些代理人的实际效用取决于他们模拟复杂的多尺度时空现象的能力。已经提出了各种神经网络架构来针对此类现象，最着名的是傅里叶神经算子（FNO），它通过不同傅里叶模式的参数化对局部\和全局空间信息进行自然处理，以及通过以下方式处理局部和全局信息的 U-Nets下采样和上采样路径。然而，跨不同方程参数或不同时间尺度的泛化仍然是一个挑战。在这项工作中，我们对涡流和速度函数形式的流体力学问题的各种 FNO 和 U-Net 方法进行了全面比较。对于 U-Net，我们从计算机视觉中转移了最近的架构改进，最显着的是来自对象分割和生成建模。我们进一步分析了使用 FNO 层来提高 U-Net 架构的性能而不显着降低计算性能的设计考虑因素。最后，我们展示了使用单个代理模型泛化到不同 PDE 参数和时间尺度的有希望的结果。
  - [时间相关 PDE 的隐式神经空间表示](https://arxiv.org/abs/2210.00124) | [code]
    > 数值求解偏微分方程 (PDE) 通常需要空间和时间离散化。传统方法（例如，有限差分、有限元、平滑粒子流体动力学）经常采用显式空间离散化，例如网格、网格和点云，其中每个自由度对应于空间中的一个位置。虽然这些明确的空间对应对于建模和理解来说是直观的，但这些表示对于准确性、内存使用或适应性而言不一定是最佳的。在这项工作中，我们探索隐式神经表示作为替代空间离散化，其中空间信息隐式存储在神经网络权重中。通过隐式神经空间表示，受 PDE 约束的时间步长转化为更新神经网络权重，它自然地与常用的优化时间积分器集成。我们通过涉及大弹性变形、湍流流体和多尺度现象的示例验证了我们在各种经典 PDE 上的方法。虽然计算速度比传统表示慢，但我们的方法表现出更高的准确性、更低的内存消耗和动态自适应分配的自由度，而无需复杂的重新划分网格。
  - [具有隐式神经表示的连续 PDE 动态预测](https://arxiv.org/abs/2209.14855) | [code]
    > 有效的数据驱动 PDE 预测方法通常依赖于固定的空间和/或时间离散化。这增加了现实世界应用的限制，例如需要在任意时空位置进行灵活外推的天气预报。我们通过引入一种新的数据驱动方法 DINo 来解决这个问题，该方法使用空间连续函数的连续时间动态对 PDE 的流进行建模。这是通过在由学习的 ODE 时间驱动的小潜在空间中通过隐式神经表示独立于其离散化嵌入空间观察来实现的。这种对时间和空间的分离和灵活处理使 DINo 成为第一个结合以下优点的数据驱动模型。它在任意空间和时间位置外推；它可以从稀疏的不规则网格或流形中学习；在测试时，它会推广到新的网格或分辨率。在代表性 PDE 系统的各种具有挑战性的泛化场景中，DINo 的表现优于替代神经 PDE 预测器。
  - [面向多边形几何的通用表示学习, GeoInformatica](https://arxiv.org/abs/2209.15458) | [code]
    > 空间数据的神经网络表示学习是地理人工智能 (GeoAI) 问题的普遍需求。近年来，在点、折线和网络的表示学习方面取得了许多进展，而在多边形，尤其是复杂的多边形几何形状方面进展甚微。在这项工作中，我们专注于开发一种通用的多边形编码模型，该模型可以将多边形几何体（有或没有孔，单面或多面体）编码到嵌入空间中。结果嵌入可以直接用于（或微调）下游任务，例如形状分类、空间关系预测等。为了实现模型的泛化性保证，我们确定了一些理想的属性：循环原点不变性、平凡顶点不变性、部分置换不变性和拓扑感知。我们探索了两种不同的编码器设计：一种是在空间域中派生所有表示；另一个利用谱域表示。对于空间域方法，我们提出了 ResNet1D，这是一种基于 CNN 的 1D 多边形编码器，它使用圆形填充来实现简单多边形上的循环原点不变性。对于谱域方法，我们开发了基于非均匀傅里叶变换 (NUFT) 的 NUFTspec，它自然地满足了所有所需的属性。我们对两个任务进行了实验：1）基于MNIST的形状分类； 2）基于两个新数据集——DBSR-46K和DBSR-cplx46K的空间关系预测。我们的结果表明，NUFTspec 和 ResNet1D 的性能优于多个现有的基线，具有显着的优势。虽然 ResNet1D 在形状不变几何修改后模型性能下降，但由于 NUFT 的性质，NUFTspec 对这些修改非常稳健。
  - [通过控制屏障功能和神经辐射场增强基于视觉的控制器的安全性](https://arxiv.org/abs/2209.12266) | [code]
    > 为了在复杂的环境中导航，机器人必须越来越多地使用高维视觉反馈（例如图像）进行控制。然而，依靠高维图像数据做出控制决策会引发重要问题；特别是，我们如何证明视觉反馈控制器的安全性？控制障碍函数 (CBF) 是在状态反馈设置中验证反馈控制器安全性的强大工具，但由于需要预测未来的观察结果以评估障碍函数，CBF 传统上不太适合视觉反馈控制.在这项工作中，我们利用神经辐射场 (NeRFs) 的最新进展来解决这个问题，神经辐射场 (NeRFs) 学习 3D 场景的隐式表示并可以从以前看不见的相机视角渲染图像，为基于 CBF 的单步视觉预测提供控制器。这种新颖的组合能够过滤掉不安全的行为并进行干预以保护安全。我们在实时模拟实验中展示了我们的控制器的效果，它成功地防止了机器人采取危险行动。
  - [WaterNeRF：水下场景的神经辐射场](https://arxiv.org/abs/2209.13091) | [code]
    > 水下成像是海洋机器人执行的一项关键任务，其应用范围广泛，包括水产养殖、海洋基础设施检查和环境监测。然而，水柱效应，例如衰减和反向散射，会极大地改变水下捕获图像的颜色和质量。由于不同的水条件和这些影响的范围依赖性，恢复水下图像是一个具有挑战性的问题。这会影响下游感知任务，包括深度估计和 3D 重建。在本文中，我们推进了神经辐射场 (NeRF) 的最新技术，以实现基于物理的密集深度估计和颜色校正。我们提出的方法 WaterNeRF 估计了基于物理的水下图像形成模型的参数，从而产生了混合数据驱动和基于模型的解决方案。在确定场景结构和辐射场后，我们可以生成退化和校正的水下图像的新视图，以及场景的密集深度。我们在真实的水下数据集上定性和定量地评估所提出的方法。
## Sep18 - Sep24, 2022
  - [感觉怎么样？ 用于越野车辆可穿越性的自我监督成本图学习](https://arxiv.org/abs/2209.10788) | [code]
    > 估计越野环境中的地形可穿越性需要推理机器人与这些地形之间的复杂交互动力学。然而，对于这些交互，构建准确的物理模型或创建信息标签以有监督的方式学习模型具有挑战性。我们提出了一种方法，该方法通过以自我监督的方式将外部感知环境信息与本体感知地形交互反馈相结合来学习预测可遍历性成本图。此外，我们提出了一种将机器人速度纳入成本图预测管道的新方法。我们在具有挑战性的越野地形的大型自主全地形车 (ATV) 上的多个短距离和大规模导航任务中验证了我们的方法，并证明了在单独的大型地面机器人上易于集成。我们的短尺度导航结果表明，使用我们学习的成本图可以使导航整体更顺畅，并为机器人提供对机器人与不同地形类型（如草地和砾石）之间相互作用的更细粒度的理解。我们的大规模导航试验表明，在 400 米到 3150 米的具有挑战性的越野路线中，与基于占用的导航基线相比，我们可以将干预次数减少多达 57%。
  - [wildNeRF：使用稀疏单目数据捕获的野外动态场景的完整视图合成](https://arxiv.org/abs/2209.10399) | [code]
    > 我们提出了一种新的神经辐射模型，该模型可以以自我监督的方式进行训练，用于动态非结构化场景的新视图合成。我们的端到端可训练算法可在几秒钟内学习高度复杂的真实静态场景，并在几分钟内学习具有刚性和非刚性运动的动态场景。通过区分静态像素和以运动为中心的像素，我们从一组稀疏的图像中创建高质量的表示。我们对现有基准进行了广泛的定性和定量评估，并在具有挑战性的 NVIDIA 动态场景数据集上设置了最先进的性能指标。此外，我们在具有挑战性的现实世界数据集（例如 Cholec80 和 SurgicalActions160）上评估我们的模型性能。
  - [密度感知 NeRF 集成：量化神经辐射场中的预测不确定性](https://arxiv.org/abs/2209.08718) | [code]
    > 我们表明，如果考虑到密度感知认知不确定性项，则集成有效地量化了神经辐射场 (NeRFs) 中的模型不确定性。在先前的工作中研究的朴素集成只是简单地平均渲染的 RGB 图像，以量化由观察到的场景的相互矛盾的解释引起的模型不确定性。相比之下，由于缺乏关于训练期间未观察到的场景部分的知识，我们还考虑了沿单个射线的终止概率来识别认知模型的不确定性。我们在已建立的 NeRF 不确定性量化基准中实现了新的最先进的性能，优于需要对 NeRF 架构和训练机制进行复杂更改的方法。我们进一步证明了 NeRF 不确定性可用于次佳视图选择和模型细化。
  - [LATITUDE：在城市规模的 NeRF 中使用截断动态低通滤波器进行机器人全局定位, ICRA2023](https://arxiv.org/abs/2209.08498) | [***``[code]``***](https://github.com/jike5/LATITUDE)
    > 神经辐射场 (NeRFs) 在表示具有高分辨率细节和高效内存的复杂 3D 场景方面取得了巨大成功。然而，当前基于 NeRF 的姿态估计器没有初始姿态预测，并且在优化过程中容易出现局部最优。在本文中，我们提出了 LATITUDE：使用截断动态低通滤波器进行全局定位，它在城市规模的 NeRF 中引入了两阶段定位机制。在位置识别阶段，我们通过训练后的 NeRF 生成的图像训练回归器，为全局定位提供初始值。在姿态优化阶段，我们通过直接优化切平面上的姿态来最小化观察图像和渲染图像之间的残差。为了避免收敛到局部最优，我们引入了截断动态低通滤波器 (TDLF) 用于从粗到细的姿态配准。我们在合成数据和真实世界数据上评估我们的方法，并展示其在大规模城市场景中高精度导航的潜在应用。代码和数据将在此 https 网址上公开提供。
  - [医学影像分割的隐式神经表示, MICCAI2022](https://link.springer.com/chapter/10.1007/978-3-031-16443-9_42) | [code]
    > 医学成像中的 3D 信号（例如 CT 扫描）通常被参数化为体素的离散网格。例如，现有的最先进的器官分割方法学习离散的分割图。不幸的是，这些方法的内存需求随着空间分辨率的增加而呈立方增长，这使得它们不适合处理高分辨率扫描。为了克服这个问题，我们设计了一个隐式器官分割网络 (IOSNet)，它利用连续的隐式神经表示并具有几个有用的属性。首先，IOSNet 解码器内存大致恒定且独立于空间分辨率，因为它将分割图参数化为连续函数。其次，IOSNet 的收敛速度比基于离散体素的方法快得多，因为它能够准确地分割器官而不受器官大小的影响，从而在不需要任何辅助技巧的情况下缓解大小不平衡问题。第三，由于其连续学习表示，IOSNet 自然支持超分辨率（即在推理过程中以任意分辨率采样）。此外，尽管使用了一个简单的轻量级解码器，IOSNet 始终优于离散专业分割架构 UNet。因此，我们的方法表明隐式神经表示非常适合医学成像应用，尤其是处理高分辨率 3D 医学扫描。
## Sep11 - Sep17, 2022
  - [DevNet：通过密度体积构建的自监督单目深度学习, ECCV2022](https://arxiv.org/abs/2209.06351) | [code]
    > 单目图像的自监督深度学习通常依赖于时间相邻图像帧之间的 2D 像素级光度关系。然而，它们既没有充分利用 3D 逐点几何对应，也没有有效地解决由遮挡或照明不一致引起的光度翘曲的模糊性。为了解决这些问题，这项工作提出了密度体积构建网络 (DevNet)，这是一种新颖的自我监督单目深度学习框架，可以考虑 3D 空间信息，并利用相邻相机平截头体之间更强的几何约束。我们的 DevNet 不是直接从单个图像中回归像素值，而是将相机平截头体划分为多个平行平面，并预测每个平面上的逐点遮挡概率密度。最终的深度图是通过沿相应光线对密度进行积分来生成的。在训练过程中，引入了新的正则化策略和损失函数来减轻光度模糊和过拟合。在没有明显扩大模型参数大小或运行时间的情况下，DevNet 在 KITTI-2015 室外数据集和 NYU-V2 室内数据集上都优于几个具有代表性的基线。特别是，在深度估计任务中，KITTI-2015 和 NYU-V2 上的 DevNet 的均方根偏差降低了约 4%。此 https 网址提供了代码。
  - [学习用于视图合成的统一 3D 点云](https://arxiv.org/abs/2209.05013) | [code]
    > 基于 3D 点云表示的视图合成方法已证明是有效的。然而，现有方法通常仅从单个源视图合成新视图，并且将它们泛化以处理多个源视图以追求更高的重建质量并非易事。在本文中，我们提出了一种新的基于深度学习的视图合成范式，它从不同的源视图中学习统一的 3D 点云。具体来说，我们首先通过根据深度图将源视图投影到 3D 空间来构建子点云。然后，我们通过自适应融合子点云联合上定义的局部邻域中的点来学习统一的 3D 点云。此外，我们还提出了一个 3D 几何引导图像恢复模块来填充孔洞并恢复渲染新视图的高频细节。三个基准数据集的实验结果表明，我们的方法在数量上和视觉上都在很大程度上优于最先进的视图合成方法。
  - [用于稀疏视图计算机断层扫描的自监督坐标投影网络](https://arxiv.org/abs/2209.05483) | [code]
    > 在目前的工作中，我们提出了一种自监督坐标投影网络（SCOPE），通过解决逆断层扫描成像问题，从单个 SV 正弦图重建无伪影的 CT 图像。与最近使用隐式神经表示网络 (INR) 解决类似问题的相关工作相比，我们的重要贡献是一种有效且简单的重投影策略，该策略将断层扫描图像重建质量提高到有监督的深度学习 CT 重建工作之上。所提出的策略受到线性代数和逆问题之间简单关系的启发。为了求解欠定线性方程组，我们首先引入INR，通过图像连续性先验来约束解空间并获得粗解。其次，我们建议生成密集视图正弦图，提高线性方程组的秩并产生更稳定的 CT 图像解空间。我们的实验结果表明，重投影策略显着提高了图像重建质量（PSNR 至少 +3 dB）。此外，我们将最近的哈希编码集成到我们的 SCOPE 模型中，这极大地加速了模型训练。最后，我们在并行和扇形 X 射线束 SVCT 重建任务中评估 SCOPE。实验结果表明，所提出的 SCOPE 模型在数量和质量上都优于两种最新的基于 INR 的方法和两种流行的监督 DL 方法。
  - [CU-Net：高效的点云颜色上采样网络](https://arxiv.org/abs/2209.06112) | [code]
    > 增强现实、虚拟现实和远程呈现场景需要点云上采样。尽管几何上采样被很好地研究以致密点云坐标，但颜色的上采样在很大程度上被忽略了。在本文中，我们提出了第一个深度学习点云颜色上采样模型 CU-Net。利用基于稀疏卷积的特征提取器和基于神经隐函数的颜色预测模块，CU-Net 实现了线性时间和空间复杂度。因此，理论上保证 CU-Net 比大多数具有二次复杂度的现有方法更有效。实验结果表明，CU-Net 可以实时为具有近百万个点的照片般逼真的点云着色，同时具有比基线更好的视觉质量。此外，CU-Net 可以适应任意的上采样率和看不见的对象。我们的源代码将很快向公众发布。
## Previous weeks
  - [城市辐射场, CVPR2022](https://urban-radiance-fields.github.io/) | [code]
    > 这项工作的目标是从扫描平台捕获的数据中执行 3D 重建和新颖的视图合成，这些平台通常用于城市户外环境（例如街景）中的世界地图绘制。给定一系列由相机和扫描仪在户外场景中移动获得的 RGB 图像序列和激光雷达扫描，我们生成了一个模型，可以从中提取 3D 表面并合成新的 RGB 图像。我们的方法扩展了神经辐射场，该方法已被证明可以在受控环境中为小场景合成逼真的新颖图像，以及利用异步捕获的激光雷达数据、解决捕获图像之间的曝光变化以及利用预测的图像分割来监督密度的新方法在指向天空的光线上。这三个扩展中的每一个都在街景数据的实验中提供了显着的性能改进。与传统方法（例如~COLMAP）和最近的神经表示（例如~Mip-NeRF）相比，我们的系统产生最先进的 3D 表面重建并合成更高质量的新视图。
## Sep4 - Sep10, 2022
  - [具有深度神经表示的隐式全波形反演](https://arxiv.org/abs/2209.03525) | [code]
    > 全波形反演（FWI）通常代表最先进的地下结构和物理参数成像方法，然而，其实施通常面临巨大挑战，例如建立一个良好的初始模型以摆脱局部最小值，以及评估反演结果的不确定性。在本文中，我们提出了使用连续和隐式定义的深度神经表示的隐式全波形反演（IFWI）算法。与对初始模型敏感的 FWI 相比，IFWI 受益于深度学习优化增加的自由度，从而允许从随机初始化开始，这大大降低了非唯一性和陷入局部最小值的风险。理论和实验分析均表明，在给定随机初始模型的情况下，IFWI 能够收敛到全局最小值，并生成具有精细结构的地下高分辨率图像。此外，IFWI 的不确定性分析可以很容易地通过使用各种深度学习方法近似贝叶斯推理来执行，本文通过添加 dropout 神经元对其进行分析。此外，IFWI具有一定的鲁棒性和较强的泛化能力，在各种二维地质模型的实验中得到了体现。通过适当的设置，IFWI也可以很好地适用于多尺度联合地球物理反演。
## Aug28 - Sep3, 2022
  - [FoV-NeRF：虚拟现实的中心凹神经辐射场, TVCG2022](https://ieeexplore.ieee.org/abstract/document/9872532) | [code]
    > 随着消费者显示器和商业 VR 平台的兴起，虚拟现实 (VR) 正变得无处不在。这种显示需要低延迟和高质量的合成图像渲染，同时减少计算开销。神经渲染的最新进展表明，有望通过基于图像的虚拟或物理环境表示来解锁 3D 计算机图形的新可能性。具体来说，神经辐射场 (NeRF) 表明，可以在不损失与视图相关的效果的情况下实现 3D 场景的照片般逼真的质量和连续视图变化。虽然 NeRF 可以显着受益于 VR 应用的渲染，但它面临着由高视场、高分辨率和立体/以自我为中心的观看带来的独特挑战，通常会导致渲染图像的低质量和高延迟。在 VR 中，这不仅会损害交互体验，还可能导致疾病。为了解决 VR 中的六自由度、以自我为中心和立体 NeRF 的这些问题，我们提出了第一个注视条件 3D 神经表示和视图合成方法。我们将视觉和立体敏锐度的人类心理物理学纳入 3D 风景的以自我为中心的神经表示中。然后，我们共同优化延迟/性能和视觉质量，同时相互桥接人类感知和神经场景合成，以实现感知上高质量的沉浸式交互。我们进行了客观分析和主观研究，以评估我们方法的有效性。我们发现我们的方法显着减少了延迟（与 NeRF 相比减少了高达 99% 的时间），而不会损失高保真渲染（在感知上与全分辨率地面实况相同）。所提出的方法可能是迈向未来实时捕捉、传送和可视化远程环境的 VR/AR 系统的第一步。
  - [克隆：用于占用网格辅助神经表示的相机-激光雷达融合](https://arxiv.org/abs/2209.01194) | [code]
    > 本文提出了 CLONeR，它通过允许对从稀疏输入传感器视图观察到的大型户外驾驶场景进行建模，显着改进了 NeRF。这是通过将 NeRF 框架内的占用和颜色学习解耦为分别使用 LiDAR 和相机数据训练的单独的多层感知器 (MLP) 来实现的。此外，本文提出了一种在 NeRF 模型旁边构建可微分 3D 占用网格图 (OGM) 的新方法，并利用此占用网格改进沿射线的点采样，以在度量空间中进行体积渲染。
## Aug21 - Aug27, 2022
## Previous weeks
  - [﻿Plenoxels：没有神经网络的辐射场, CVPR2022(oral)](https://arxiv.org/abs/2112.05131) | [***``[code]``***](https://alexyu.net/plenoxels)
    > 我们介绍了 Plenoxels（全光体素），一种用于照片级真实视图合成的系统。 Plenoxels 将场景表示为具有球谐函数的稀疏 3D 网格。这种表示可以通过梯度方法和正则化从校准图像中优化，而无需任何神经组件。在标准的基准任务中，Plenoxels 的优化速度比神经辐射场快两个数量级，而视觉质量没有损失。
## Aug21 - Aug27, 2022
## Aug14 - Aug20, 2022
## Aug7 - Aug13, 2022
  - [HyperTime：时间序列的隐式神经表示](https://arxiv.org/abs/2208.05836) | [code]
    > 隐式神经表示 (INR) 最近已成为一种强大的工具，可提供准确且与分辨率无关的数据编码。它们作为通用逼近器的鲁棒性已在各种数据源中得到证明，并应用于图像、声音和 3D 场景表示。然而，很少有人关注利用这些架构来表示和分析时间序列数据。在本文中，我们使用 INR 分析时间序列的表示，比较不同的激活函数在重建精度和训练收敛速度方面。我们展示了如何利用这些网络对时间序列进行插补，以及在单变量和多变量数据上的应用。最后，我们提出了一种利用 INR 来学习整个时间序列数据集的压缩潜在表示的超网络架构。我们引入了基于 FFT 的损失来指导训练，以便在时间序列中保留所有频率。我们展示了该网络可用于将时间序列编码为 INR，并且可以对它们的嵌入进行插值以从现有的时间序列中生成新的时间序列。我们通过将其用于数据增强来评估我们的生成方法，并表明它与当前最先进的时间序列增强方法具有竞争力。
  - [NIDN：纳米结构的神经逆向设计](https://arxiv.org/abs/2208.05480) | [code]
    > 近十年来，计算工具已成为材料设计的核心，以降低成本实现快速开发周期。机器学习工具在光子学领域尤其兴起。然而，从优化的角度来看，设计所需的麦克斯韦方程的反演特别具有挑战性，需要复杂的软件。我们提出了一种创新的开源软件工具，称为纳米结构的神经逆向设计 (NIDN)，它允许使用基于物理的深度学习方法设计复杂的堆叠材料纳米结构。我们执行基于梯度的神经网络训练，而不是无导数或数据驱动的优化或学习方法，在这种训练中，我们根据其光谱特性直接优化材料及其结构。 NIDN 支持两种不同的求解器，严格的耦合波分析和有限差分时域方法。 NIDN 的实用性和有效性在几个合成示例以及 1550 nm 滤光片和抗反射涂层的设计中得到了证明。结果与实验基线、其他模拟工具和所需的光谱特性相匹配。鉴于其在网络架构和 Maxwell 求解器方面的完全模块化以及开源、许可的可用性，NIDN 将能够支持广泛应用中的计算材料设计过程。
  - [使用隐式神经表示的蒙特卡罗去噪](https://oaktrust.library.tamu.edu/handle/1969.1/196567) | [code]
    > Monte Carlo 路径追踪是计算机图形学中流行的 3D 渲染技术，但它通常需要在图像中的噪声量和计算时间之间进行代价高昂的权衡。因此，尝试“平滑”噪声图像是有用的，通常通过在样本之间构建新数据或对图像应用过滤器。在这项工作中，我们研究了训练神经网络以将固定视点场景的亮度隐式表示为连续函数的可行性。我们使用多层感知器网络实现神经网络，并在由离线 Monte Carlo 渲染器生成的稀疏采样图像上对其进行训练。该训练数据使用图像平面上每个样本的 (x, y) 坐标作为输入，并将样本的 RGB 颜色作为输出。此外，我们为网络提供第一条光线交点的表面法线、深度和反照率，作为像素坐标旁边的额外输入。这些额外的输入维度通过帮助网络考虑深度、法线和漫反射颜色的变化来提高隐式表示的质量。一旦网络在稀疏采样的场景上得到训练，我们就可以对每个像素的网络进行多次密集采样，以创建最终的去噪图像。我们发现该网络可以在具有柔和照明和光泽反射的场景中快速学习和去噪图像，并且只需少量训练即可轻松处理深度、正常和漫反射颜色的不连续性。
## Jul31 - Aug6, 2022
## Jul24 - Jul30, 2022
  - [DoF-NeRF：景深与神经辐射场相遇, ACMMM2022](https://arxiv.org/pdf/2208.00945) | [***``[code]``***](https://github.com/zijinwuzijin/DoF-NeRF)
    > 神经辐射场 (NeRF) 及其变体在表示 3D 场景和合成逼真的新颖视图方面取得了巨大成功。但是，它们通常基于针孔相机模型并假设全焦点输入。这限制了它们的适用性，因为从现实世界捕获的图像通常具有有限的景深 (DoF)。为了缓解这个问题，我们引入了 DoF-NeRF，一种新颖的神经渲染方法，可以处理浅自由度输入并可以模拟自由度效果。特别是，它根据几何光学原理扩展了 NeRF 以模拟镜头的孔径。这样的物理保证允许 DoF-NeRF 操作具有不同焦点配置的视图。得益于显式光圈建模，DoF-NeRF 还可以通过调整虚拟光圈和焦点参数来直接操纵 DoF 效果。它是即插即用的，可以插入到基于 NeRF 的框架中。在合成数据集和真实世界数据集上的实验表明，DoF-NeRF 不仅在全焦点设置中的性能与 NeRF 相当，而且还可以合成以浅自由度输入为条件的全焦点新视图。还演示了 DoF-NeRF 在 DoF 渲染中的一个有趣应用。
  - [神经密度-距离场, ECCV2022](https://arxiv.org/abs/2207.14455) | [***``[code]``***](https://ueda0319.github.io/neddf/)
    > 神经领域在 3D 视觉任务中的成功现在是无可争辩的。遵循这一趋势，已经提出了几种针对视觉定位的方法（例如，SLAM）来使用神经场估计距离或密度场。然而，仅通过基于密度场的方法（例如神经辐射场 (NeRF)）很难实现高定位性能，因为它们在大多数空白区域中不提供密度梯度。另一方面，基于距离场的方法，例如神经隐式表面 (NeuS)，在对象的表面形状方面存在局限性。本文提出了神经密度-距离场 (NeDDF)，这是一种新的 3D 表示，它相互约束距离和密度场。我们将距离场公式扩展到没有明确边界表面的形状，例如毛皮或烟雾，这使得从距离场到密度场的显式转换成为可能。通过显式转换实现的一致距离和密度场既能保证初始值的鲁棒性，又能实现高质量的配准。此外，场之间的一致性允许从稀疏点云快速收敛。实验表明，NeDDF 可以实现高定位性能，同时在新颖的视图合成上提供与 NeRF 相当的结果。该代码可在此 https URL 获得。
  - [通过 NeRF Attention 进行端到端视图合成](https://arxiv.org/abs/2207.14741) | [code]
    > 在本文中，我们提出了一个用于视图合成的简单 seq2seq 公式，其中我们将一组光线点作为输入和输出与光线相对应的颜色。在这个 seq2seq 公式上直接应用标准转换器有两个限制。首先，标准注意力不能成功地适应体积渲染过程，因此合成视图中缺少高频分量。其次，将全局注意力应用于所有光线和像素是非常低效的。受神经辐射场 (NeRF) 的启发，我们提出了 NeRF 注意力 (NeRFA) 来解决上述问题。一方面，NeRFA 将体积渲染方程视为软特征调制过程。通过这种方式，特征调制增强了具有类似 NeRF 电感偏置的变压器。另一方面，NeRFA 执行多阶段注意力以减少计算开销。此外，NeRFA 模型采用光线和像素转换器来学习光线和像素之间的相互作用。 NeRFA 在四个数据集上展示了优于 NeRF 和 NerFormer 的性能：DeepVoxels、Blender、LLFF 和 CO3D。此外，NeRFA 在两种设置下建立了新的 state-of-the-art：单场景视图合成和以类别为中心的新颖视图合成。该代码将公开发布。
  - [神经链：从多视图图像中学习头发的几何形状和外观, ECCV2022](https://arxiv.org/pdf/2207.14067) | [***``[code]``***](https://radualexandru.github.io/neural_strands/)
    > 我们提出了 Neural Strands，这是一种新颖的学习框架，用于从多视图图像输入中对精确的头发几何形状和外观进行建模。学习的头发模型可以从具有高保真视图相关效果的任何视点实时渲染。与体积模型不同，我们的模型实现了直观的形状和样式控制。为了实现这些特性，我们提出了一种基于神经头皮纹理的新型头发表示，该神经头皮纹理对每个纹素位置的单个股线的几何形状和外观进行编码。此外，我们引入了一种基于学习发束光栅化的新型神经渲染框架。我们的神经渲染是精确的和抗锯齿的，使渲染视图一致且逼真。将外观与多视图几何先验相结合，我们首次实现了从多视图设置中联合学习外观和显式头发几何形状。我们展示了我们的方法在各种发型的保真度和效率方面的有效性。
  - [拉普拉斯系统的神经格林函数, Computer & Graphics](https://www.sciencedirect.com/science/article/pii/S0097849322001406) | [code]
    > 求解源自拉普拉斯算子的线性方程组是广泛应用的核心。由于线性系统的稀疏性，当解具有大量自由度时，通常采用迭代求解器，例如共轭梯度和多重网格。这些迭代求解器可以看作是拉普拉斯算子格林函数的稀疏近似。在本文中，我们提出了一种机器学习方法，该方法从边界条件中回归格林函数。这是通过格林函数实现的，该函数可以以多尺度方式有效地表示，从而大大降低了与密集矩阵表示相关的成本。此外，由于格林函数完全依赖于边界条件，因此训练所提出的神经网络不需要对线性系统的右侧进行采样。结果表明，我们的方法优于最先进的共轭梯度和多重网格方法。
  - [关于物理概念的可学习性：神经网络能理解什么是真](https://arxiv.org/abs/2207.12186) | [code]
    > 鉴于深度神经网络生成逼真的合成数据的卓越能力，我们重新审视了经典的信号到符号障碍。 DeepFakes 和欺骗突出了物理现实与其抽象表示之间联系的脆弱性，无论是由数字计算机还是生物代理学习。从一个广泛适用的抽象概念定义开始，我们表明标准的前馈架构只能捕获微不足道的概念，无论权重的数量和训练数据的数量如何，尽管它们是非常有效的分类器。另一方面，包含递归的架构可以代表更大的概念类别，但可能仍然无法从有限的数据集中学习它们。我们定性地描述了可以被用随机梯度下降变体训练的现代架构“理解”的概念类别，使用（自由能）拉格朗日来测量信息复杂性。然而，即使一个概念已经被理解，网络也无法将其理解传达给外部代理，除非通过持续的交互和验证。然后，我们将物理对象表征为抽象概念，并使用前面的分析来表明物理对象可以由有限架构编码。然而，为了理解物理概念，传感器必须提供持续令人兴奋的观察，而控制数据采集过程的能力是必不可少的（主动感知）。控制的重要性取决于形式，比听觉或化学感知更有益于视觉。最后，我们得出结论，可以在有限的时间内用有限的资源将物理实体绑定到数字身份，原则上解决了信号到符号的障碍问题，但我们强调了持续验证的必要性。
## Previous weeks
  - [NeRF：将场景表示为用于视图合成的神经辐射场, ECCV2020](https://arxiv.org/abs/2003.08934) | [***``[code]``***](http://tancik.com/nerf)
    > 我们提出了一种方法，该方法通过使用稀疏输入视图集优化底层连续体积场景函数，实现了合成复杂场景的新视图的最新结果。我们的算法使用全连接（非卷积）深度网络表示场景，其输入是单个连续 5D 坐标（空间位置（x,y,z）和观察方向（θ,φ）），其输出是该空间位置的体积密度和与视图相关的发射辐射。我们通过沿相机光线查询 5D 坐标来合成视图，并使用经典的体渲染技术将输出颜色和密度投影到图像中。因为体积渲染是自然可微的，所以优化我们的表示所需的唯一输入是一组具有已知相机姿势的图像。我们描述了如何有效地优化神经辐射场以渲染具有复杂几何形状和外观的场景的逼真的新颖视图，并展示了优于先前在神经渲染和视图合成方面的工作的结果。查看合成结果最好以视频形式观看，因此我们敦促读者观看我们的补充视频以进行令人信服的比较。
  - [野外的 NeRF：无约束照片集的神经辐射场, CVPR2021](https://arxiv.org/abs/2008.02268) | [code]
    > 我们提出了一种基于学习的方法，用于仅使用野外照片的非结构化集合来合成复杂场景的新视图。我们建立在神经辐射场 (NeRF) 的基础上，它使用多层感知器的权重将场景的密度和颜色建模为 3D 坐标的函数。虽然 NeRF 在受控设置下捕获的静态对象的图像上效果很好，但它无法在不受控的图像中模拟许多普遍存在的真实世界现象，例如可变照明或瞬态遮挡物。我们为 NeRF 引入了一系列扩展来解决这些问题，从而能够从互联网上获取的非结构化图像集合中进行准确的重建。我们将我们的系统（称为 NeRF-W）应用于著名地标的互联网照片集，并展示时间一致的新颖视图渲染，这些渲染比现有技术更接近真实感。
  - [Ha-NeRF：野外的幻觉神经辐射场, CVPR2022](https://rover-xingyu.github.io/Ha-NeRF/) | [***``[code]``***](https://github.com/rover-xingyu/Ha-NeRF)
    > 神经辐射场 (NeRF) 最近因其令人印象深刻的新颖视图合成能力而广受欢迎。本文研究了幻觉 NeRF 的问题：即在一天中的不同时间从一组旅游图像中恢复一个真实的 NeRF。现有的解决方案采用具有可控外观嵌入的 NeRF 在各种条件下渲染新颖的视图，但它们无法渲染具有看不见的外观的视图一致图像。为了解决这个问题，我们提出了一个用于构建幻觉 NeRF 的端到端框架，称为 Ha-NeRF。具体来说，我们提出了一个外观幻觉模块来处理随时间变化的外观并将它们转移到新的视图中。考虑到旅游图像的复杂遮挡，我们引入了一个反遮挡模块来准确地分解静态主体以获得可见性。合成数据和真实旅游照片集的实验结果表明，我们的方法可以产生幻觉，并从不同的视图呈现无遮挡的图像。
  - [Nerfies：可变形的神经辐射场, ICCV2021](https://arxiv.org/abs/2011.12948) | [code]
    > 我们提出了第一种能够使用从手机随便捕获的照片/视频来逼真地重建可变形场景的方法。我们的方法通过优化一个额外的连续体积变形场来增强神经辐射场 (NeRF)，该场将每个观察点扭曲成一个规范的 5D NeRF。我们观察到这些类似 NeRF 的变形场容易出现局部最小值，并为基于坐标的模型提出了一种从粗到细的优化方法，可以实现更稳健的优化。通过将几何处理和物理模拟的原理应用于类似 NeRF 的模型，我们提出了变形场的弹性正则化，进一步提高了鲁棒性。我们表明，我们的方法可以将随意捕获的自拍照片/视频转换为可变形的 NeRF 模型，允许从任意视角对主体进行逼真的渲染，我们称之为“nerfies”。我们通过使用带有两部手机的装备收集时间同步数据来评估我们的方法，从而在不同视点产生相同姿势的训练/验证图像。我们表明，我们的方法忠实地重建了非刚性变形的场景，并以高保真度再现了看不见的视图。
  - [D-NeRF：动态场景的神经辐射场, CVPR2021](https://arxiv.org/abs/2011.13961) | [***``[code]``***](https://github.com/albertpumarola/D-NeRF)
    > 将机器学习与几何推理相结合的神经渲染技术已成为从一组稀疏图像中合成场景新视图的最有前途的方法之一。其中，神经辐射场 (NeRF) 尤为突出，它训练深度网络将 5D 输入坐标（表示空间位置和观察方向）映射为体积密度和与视图相关的发射辐射。然而，尽管在生成的图像上实现了前所未有的真实感水平，但 NeRF 仅适用于静态场景，其中可以从不同的图像中查询相同的空间位置。在本文中，我们介绍了 D-NeRF，这是一种将神经辐射场扩展到动态域的方法，允许在场景中移动的 \emph{single} 相机的刚性和非刚性运动下重建和渲染物体的新图像。为此，我们将时间视为系统的附加输入，并将学习过程分为两个主要阶段：一个将场景编码为规范空间，另一个将这个规范表示映射到特定时间的变形场景。两种映射都是使用全连接网络同时学习的。一旦网络经过训练，D-NeRF 就可以渲染新颖的图像，同时控制相机视图和时间变量，从而控制对象的移动。我们展示了我们的方法在物体处​​于刚性、关节和非刚性运动的场景中的有效性。代码、模型权重和动态场景数据集将发布。
  - [用于单目 4D 面部头像重建的动态神经辐射场, CVPR2021](https://gafniguy.github.io/4D-Facial-Avatars/) | [***``[code]``***](https://github.com/gafniguy/4D-Facial-Avatars)
    > 我们提出了用于模拟人脸外观和动态的动态神经辐射场。对说话的人进行数字建模和重建是各种应用程序的关键组成部分。特别是对于 AR 或 VR 中的远程呈现应用，需要忠实再现外观，包括新颖的视点或头部姿势。与显式建模几何和材料属性或纯粹基于图像的最先进方法相比，我们引入了基于场景表示网络的头部隐式表示。为了处理面部的动态，我们将场景表示网络与低维可变形模型相结合，该模型提供对姿势和表情的显式控制。我们使用体积渲染从这种混合表示中生成图像，并证明这种动态神经场景表示只能从单目输入数据中学习，而不需要专门的捕获设置。在我们的实验中，我们表明这种学习的体积表示允许生成照片般逼真的图像，其质量超过了基于视频的最先进的重演方法的质量。
  - [PVA：像素对齐的体积化身, CVPR2021](https://volumetric-avatars.github.io/) | [code]
    > 逼真的人头的采集和渲染是一个极具挑战性的研究问题，对于虚拟远程呈现特别重要。目前，最高质量是通过在多视图数据上以个人特定方式训练的体积方法实现的。与更简单的基于网格的模型相比，这些模型更好地表示精细结构，例如头发。体积模型通常使用全局代码来表示面部表情，以便它们可以由一小组动画参数驱动。虽然这样的架构实现了令人印象深刻的渲染质量，但它们不能轻易地扩展到多身份设置。在本文中，我们设计了一种新颖的方法，用于在仅给定少量输入的情况下预测人头的体积化身。我们通过一种新颖的参数化实现跨身份的泛化，该参数化将神经辐射场与直接从输入中提取的局部像素对齐特征相结合，从而避免了对非常深或复杂网络的需求。我们的方法仅基于光度重新渲染损失以端到端的方式进行训练，无需明确的 3D 监督。我们证明我们的方法在质量方面优于现有的现有技术，并且能够生成忠实的面部表情多身份设置。
  - [用于人体建模的动画神经辐射场, ICCV2021](https://zju3dv.github.io/animatable_nerf/) | [***``[code]``***](https://github.com/zju3dv/animatable_nerf)
    > 本文解决了从多视图视频中重建可动画人体模型的挑战。最近的一些工作提出将非刚性变形场景分解为规范神经辐射场和一组将观察空间点映射到规范空间的变形场，从而使他们能够从图像中学习动态场景。然而，它们将变形场表示为平移矢量场或 SE(3) 场，这使得优化受到高度约束。此外，这些表示不能由输入运动明确控制。相反，我们引入了神经混合权重场来产生变形场。基于骨架驱动的变形，混合权重场与 3D 人体骨骼一起使用，以生成观察到规范和规范到观察的对应关系。由于 3D 人体骨骼更易观察，它们可以规范变形场的学习。此外，学习到的混合权重场可以与输入的骨骼运动相结合，以生成新的变形场来为人体模型设置动画。实验表明，我们的方法明显优于最近的人类合成方法。该代码将在 https://zju3dv.github.io/animatable_nerf/ 上提供。
  - [NeRF++：分析和改进神经辐射场](https://arxiv.org/abs/2010.07492) | [***``[code]``***](https://github.com/Kai-46/nerfplusplus;)
    > 神经辐射场 (NeRF) 为各种捕捉设置实现了令人印象深刻的视图合成结果，包括有界场景的 360 度捕捉以及有界和无界场景的前向捕捉。 NeRF 将表示视图不变不透明度和视图相关颜色体积的多层感知器 (MLP) 拟合到一组训练图像，并基于体积渲染技术对新视图进行采样。在这份技术报告中，我们首先评论了辐射场及其潜在的模糊性，即形状-辐射模糊度，并分析了 NeRF 在避免这种模糊性方面的成功。其次，我们解决了将 NeRF 应用于大规模、无界 3D 场景中对象的 360 度捕获所涉及的参数化问题。我们的方法在这种具有挑战性的场景中提高了视图合成保真度。此 https 网址提供了代码。
  - [动态场景的神经场景图, CVPR2021(oral)](https://arxiv.org/abs/2011.10379) | [***``[code]``***](https://github.com/princeton-computational-imaging/neural-scene-graphs)
    > 最近的隐式神经渲染方法表明，可以通过仅由一组 RGB 图像监督的预测其体积密度和颜色来学习复杂场景的准确视图合成。然而，现有方法仅限于学习将所有场景对象编码为单个神经网络的静态场景的有效表示，并且缺乏将动态场景表示和分解为单个场景对象的能力。在这项工作中，我们提出了第一个将动态场景分解为场景图的神经渲染方法。我们提出了一种学习的场景图表示，它对对象变换和辐射进行编码，以有效地渲染场景的新颖排列和视图。为此，我们学习隐式编码的场景，并结合联合学习的潜在表示来描述具有单个隐式函数的对象。我们在合成和真实汽车数据上评估所提出的方法，验证我们的方法学习动态场景 - 仅通过观察该场景的视频 - 并允许渲染具有看不见的对象集的新颖场景组合的新颖照片般逼真的视图看不见的姿势。
  - [使用隐式场景表示进行就地场景标记和理解, ICCV2021(oral)](https://shuaifengzhi.com/Semantic-NeRF/) | [***``[code]``***](https://github.com/Harry-Zhi/semantic_nerf/)
    > 语义标签与几何和辐射重建高度相关，因为具有相似形状和外观的场景实体更有可能来自相似的类别。最近的隐式神经重建技术很有吸引力，因为它们不需要事先的训练数据，但同样的完全自我监督的方法对于语义来说是不可能的，因为标签是人类定义的属性。
