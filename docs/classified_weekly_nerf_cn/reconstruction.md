
每周分类神经辐射场 - reconstruction ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
===========================================================================================================================================
## 按类别筛选: 
 [全部](../weekly_nerf_cn.md) | [动态](./dynamic.md) | [编辑](./editing.md) | [快速](./fast.md) | [泛化](./generalization.md) | [人体](./human.md) | [视频](./video.md) | [光照](./lighting.md) | [重建](./reconstruction.md) | [纹理](./texture.md) | [语义](./semantic.md) | [姿态-SLAM](./pose-slam.md) | [其他](./others.md) 
## Sep4 - Sep10, 2022
  - [具有学习几何先验的 3D 纹理形状恢复](https://arxiv.org/abs/2209.03254) | [code]
    > 从部分扫描中恢复 3D 纹理形状对于许多实际应用至关重要。现有方法已经证明了隐式函数表示的有效性，但它们存在严重遮挡和不同对象类型的部分输入，这极大地阻碍了它们在现实世界中的应用价值。本技术报告介绍了我们通过结合学习几何先验来解决这些限制的方法。为此，我们从学习的姿势预测中生成一个 SMPL 模型，并将其融合到部分输入中，以添加人体的先验知识。我们还提出了一种新颖的完整性感知边界框自适应，用于处理不同级别的尺度和部分扫描的局部性。
  - [SIRA：来自单个图像的可重新点亮的头像](https://arxiv.org/abs/2209.03027) | [code]
    > 从单个图像中恢复人头的几何形状，同时分解材料和照明是一个严重不适定的问题，需要解决先验信息。基于 3D 可变形模型 (3DMM) 的方法，以及它们与可微渲染器的组合，已显示出可喜的结果。然而，3DMM 的表现力是有限的，它们通常会产生过度平滑且与身份无关的 3D 形状，仅限于面部区域。最近已经通过使用多层感知器参数化几何形状的神经场获得了高度准确的全头重建。这些表示的多功能性也被证明对于解开几何、材料和照明是有效的。然而，这些方法需要几十个输入图像。在本文中，我们介绍了 SIRA，这是一种从单个图像重建具有高保真几何形状和分解光和表面材料的人头头像的方法。我们的关键成分是两个基于神经场的数据驱动统计模型，可解决单视图 3D 表面重建和外观分解的模糊性。实验表明，SIRA 在 3D 头部重建中获得了最先进的结果，同时它成功地解开了全局照明、漫反射和镜面反射率。此外，我们的重建适用于基于物理的外观编辑和头部模型重新照明。
## Aug28 - Sep3, 2022
  - [使用有符号射线距离函数 (SRDF) 的多视图重建](https://arxiv.org/abs/2209.00082) | [code]
    > 在本文中，我们解决了多视图 3D 形状重建的问题。尽管最近与隐式形状表示相关的可微渲染方法提供了突破性的性能，但它们的计算量仍然很大，并且通常在估计的几何形状上缺乏精度。为了克服这些限制，我们研究了一种新的计算方法，它建立在一种新的体积形状表示上，就像最近的可微渲染方法一样，但用深度图参数化以更好地实现形状表面。与此表示相关的形状能量评估给定彩色图像的 3D 几何形状，不需要外观预测，但在优化时仍然受益于体积积分。在实践中，我们提出了一种隐式形状表示，SRDF，它基于我们通过沿相机光线的深度参数化的有符号距离。相关的形状能量考虑了深度预测一致性和光度一致性之间的一致性，这在体积表示中的 3D 位置。可以考虑各种照片一致性先验，例如基于中值的基线，或更详细的标准，如学习函数。该方法保留了深度图的像素精度，并且是可并行化的。我们在标准数据集上的实验表明，它提供了关于最近使用隐式形状表示的方法以及传统的多视图立体方法的最先进的结果。
  - [Dual-Space NeRF：在不同空间中学习动画化身和场景照明, 3DV2022](https://arxiv.org/abs/2208.14851) | [code]
    > 在规范空间中对人体进行建模是捕捉和动画的常见做法。但是当涉及到神经辐射场 (NeRF) 时，仅仅在标准空间中学习一个静态的 NeRF 是不够的，因为即使场景照明是恒定的，当人移动时身体的照明也会发生变化。以前的方法通过学习每帧嵌入来缓解光照的不一致性，但这种操作并不能推广到看不见的姿势。鉴于光照条件在世界空间中是静态的，而人体在规范空间中是一致的，我们提出了一种双空间 NeRF，它在两个独立的空间中使用两个 MLP 对场景光照和人体进行建模。为了弥合这两个空间，以前的方法主要依赖于线性混合蒙皮 (LBS) 算法。然而，动态神经领域的 LBS 的混合权重是难以处理的，因此通常用另一个 MLP 来记忆，这不能推广到新的姿势。尽管可以借用 SMPL 等参数网格的混合权重，但插值操作会引入更多伪影。在本文中，我们建议使用重心映射，它可以直接泛化到看不见的姿势，并且出人意料地取得了比具有神经混合权重的 LBS 更好的结果。 Human3.6M 和 ZJU-MoCap 数据集的定量和定性结果显示了我们方法的有效性。
  - [NerfCap：使用动态神经辐射场捕获人类表现, TVCG2022](https://ieeexplore.ieee.org/abstract/document/9870173) | [code]
    > 本文解决了从稀疏的多视图或单目视频中捕捉人类表演的挑战。给定表演者的模板网格，以前的方法通过将模板网格非刚性地注册到具有 2D 轮廓或密集光度对齐的图像来捕获人体运动。然而，详细的表面变形无法从轮廓中恢复，而光度对齐则受到视频外观变化引起的不稳定性的影响。为了解决这些问题，我们提出了 NerfCap，这是一种基于表演者动态神经辐射场 (NeRF) 表示的新型表演捕捉方法。具体来说，通过优化变形场和规范 NeRF 的外观模型，从模板几何初始化规范 NeRF 并注册到视频帧。为了捕捉大型身体运动和详细的表面变形，NerfCap 将线性混合蒙皮与嵌入式图形变形相结合。与受限于固定拓扑和纹理的基于网格的方法相比，NerfCap 能够灵活地捕捉视频中复杂的几何形状和外观变化，并合成更逼真的图像。此外，NerfCap 可以通过将合成视频与输入视频进行匹配，以自我监督的方式进行端到端的预训练。各种数据集的实验结果表明，NerfCap 在表面重建精度和新视图合成质量方面都优于先前的工作。
## Aug21 - Aug27, 2022
## Previous weeks
## Aug21 - Aug27, 2022
## Aug14 - Aug20, 2022
  - [Vox-Surf：基于体素的隐式表面表示](https://arxiv.org/abs/2208.10925) | [code]
    > 虚拟内容创建和交互在 AR 和 VR 等现代 3D 应用中发挥着重要作用。从真实场景中恢复详细的 3D 模型可以显着扩展其应用范围，并且已经在计算机视觉和计算机图形学界进行了数十年的研究。我们提出了 Vox-Surf，一种基于体素的隐式表面表示。我们的 Vox-Surf 将空间划分为有限的有界体素。每个体素在其角顶点中存储几何和外观信息。由于从体素表示继承而来的稀疏性，Vox-Surf 几乎适用于任何场景，并且可以从多个视图图像中轻松训练。我们利用渐进式训练过程逐步提取重要体素进行进一步优化，从而只保留有效体素，这大大减少了采样点的数量并提高了渲染速度。精细体素也可以视为碰撞检测的边界体积。实验表明，与其他方法相比，Vox-Surf 表示可以以更少的内存和更快的渲染速度学习精细的表面细节和准确的颜色。我们还表明，Vox-Surf 在场景编辑和 AR 应用中可以更实用。
  - [从单目视频中对动画 3D 人体进行神经捕获, ECCV2022](https://arxiv.org/abs/2208.08728) | [code]
    > 我们提出了一种从单目视频输入构建可动画 3D 人体表示的新颖范例，这样它就可以以任何看不见的姿势和视图进行渲染。我们的方法基于动态神经辐射场 (NeRF)，该动态神经辐射场 (NeRF) 由作为几何代理的基于网格的参数化 3D 人体模型装配。以前的方法通常依赖多视图视频或准确的 3D 几何信息作为附加输入；此外，大多数方法在推广到看不见的姿势时质量会下降。我们认为，泛化的关键是用于查询动态 NeRF 的良好输入嵌入：良好的输入嵌入应该定义全体积空间中的单射映射，由姿态变化下的表面网格变形引导。基于这一观察，我们建议嵌入输入查询及其与网格顶点上一组测地最近邻所跨越的局部表面区域的关系。通过包含位置和相对距离信息，我们的嵌入定义了距离保留的变形映射，并很好地推广到看不见的姿势。为了减少对额外输入的依赖，我们首先使用现成的工具初始化每帧 3D 网格，然后提出一个管道来联合优化 NeRF 并细化初始网格。大量实验表明，我们的方法可以在看不见的姿势和视图下合成合理的人类渲染结果。
## Aug7 - Aug13, 2022
  - [OmniVoxel：一种快速精确的全向神经辐射场重建方法, GCCE 2022](https://arxiv.org/abs/2208.06335) | [code]
    > 本文提出了一种利用等矩形全向图像重建神经辐射场的方法。具有辐射场的隐式神经场景表示可以在有限的空间区域内连续重建场景的 3D 形状。然而，在商用 PC 硬件上训练完全隐式表示需要大量时间和计算资源（每个场景 15 ~ 20 小时）。因此，我们提出了一种显着加速这一过程的方法（每个场景 20 ∼ 40 分钟）。我们没有使用完全隐式的光线表示来重建辐射场，而是采用包含张量中的密度和颜色特征的特征体素。考虑到全向 equirectangular 输入和相机布局，我们使用球面体素化来表示，而不是三次表示。我们的体素化方法可以平衡内景和外景的重建质量。此外，我们对颜色特征采用轴对齐位置编码方法来提高整体图像质量。我们的方法在具有随机相机姿势的合成数据集上实现了令人满意的经验性能。此外，我们在包含复杂几何形状的真实场景中测试了我们的方法，并实现了最先进的性能。我们的代码和完整的数据集将与论文发表的同时发布。
  - [通过可微分渲染进行表面捕获的快速梯度下降, 3DV2022](https://hal.inria.fr/hal-03748662/) | [code]
    > 差分渲染最近已成为一种强大的工具，用于从多个视图进行基于图像的渲染或几何重建，具有非常高的质量。到目前为止，此类方法已在通用对象数据库上进行了基准测试，并有望应用于一些真实数据，但尚未应用于可能受益的特定应用程序。在本文中，我们研究了如何为原始多相机性能捕获制作差分渲染系统。我们以实际可用性和可重复性的方式解决了几个关键问题，例如处理速度、模型的可解释性和一般输出模型质量。这导致我们对差分渲染框架做出了一些贡献。特别是，我们展示了差分渲染和经典优化的统一视图是可能的，从而导致可以分析计算完整的非随机梯度步骤并将完整的每帧数据存储在视频内存中的公式和实现，从而产生简单有效的实现.我们还使用稀疏存储和从粗到细的方案来实现极高的分辨率，同时包含内存和计算时间。我们通过实验表明，在质量上与最先进的多视图人体表面捕获方法相媲美的结果可以在很短的时间内实现，通常每帧大约一分钟。
  - [PlaneFormers：从稀疏视图平面到 3D 重建, ECCV2022](https://arxiv.org/abs/2208.04307) | [code]
    > 我们提出了一种从具有有限重叠的图像中对场景进行平面表面重建的方法。这种重建任务具有挑战性，因为它需要联合推理单图像 3D 重建、图像之间的对应关系以及图像之间的相对相机位姿。过去的工作提出了基于优化的方法。我们介绍了一种更简单的方法，PlaneFormer，它使用一个应用于 3D 感知平面令牌的转换器来执行 3D 推理。我们的实验表明，我们的方法比以前的工作要有效得多，并且几个特定于 3D 的设计决策对其成功至关重要。
  - [PS-NeRV：视频的补丁风格化神经表示](https://arxiv.org/abs/2208.03742) | [code]
    > 我们研究如何使用隐式神经表示 (INR) 来表示视频。经典的 INR 方法通常利用 MLP 将输入坐标映射到输出像素。虽然最近的一些作品试图用 CNN 直接重建整个图像。然而，我们认为上述像素级和图像级策略都不利于视频数据。相反，我们提出了一种补丁解决方案 PS-NeRV，它将视频表示为补丁和相应补丁坐标的函数。它自然继承了image-wise方法的优点，并以快速的解码速度实现了出色的重建性能。整个方法包括传统的模块，如位置嵌入、MLPs 和 CNNs，同时还引入了 AdaIN 来增强中间特征。这些简单而重要的变化可以帮助网络轻松适应高频细节。大量实验证明了它在视频压缩和视频修复等视频相关任务中的有效性。
## Jul31 - Aug6, 2022
  - [PRIF: Primary Ray-based Implicit Function](https://research.google/pubs/pub51556/) | [code]
    > 我们引入了一种新的隐式形状表示，称为基于初级光线的隐式函数 (PRIF)。与大多数基于符号距离函数 (SDF) 处理空间位置的现有方法相比，我们的表示在定向射线上运行。具体来说，PRIF 被制定为直接生成给定输入射线的表面命中点，而无需昂贵的球体跟踪操作，从而实现高效的形状提取和可微渲染。我们证明了经过训练以编码 PRIF 的神经网络在各种任务中取得了成功，包括单一形状表示、类别形状生成、稀疏或嘈杂观察的形状补全、相机姿态估计的逆渲染以及颜色的神经渲染。
## Jul24 - Jul30, 2022
  - [脱离网格：用于 3D 血管建模的连续隐式神经表示, MICCAI STACOM 2022](https://arxiv.org/abs/2207.14663) | [code]
    > 个性化 3D 血管模型对于心血管疾病患者的诊断、预后和治疗计划非常有价值。传统上，此类模型是用网格和体素掩码等显式表示或径向基函数或原子（管状）形状等隐式表示构建的。在这里，我们建议在可微的隐式神经表示 (INR) 中通过其有符号距离函数 (SDF) 的零水平集来表示表面。这使我们能够用隐式、连续、轻量级且易于与深度学习算法集成的表示来对复杂的血管结构进行建模。我们在这里通过三个实际示例展示了这种方法的潜力。首先，我们从 CT 图像中获得了腹主动脉瘤 (AAA) 的准确且防水的表面，并从表面上的 200 个点显示出稳健的拟合。其次，我们同时将嵌套的血管壁安装在单个 INR 中，没有交叉点。第三，我们展示了如何将单个动脉的 3D 模型平滑地融合到单个防水表面中。我们的结果表明，INR 是一种灵活的表示形式，具有最小交互注释的潜力复杂血管结构的研究和操作。
  - [GAUDI：沉浸式 3D 场景生成的神经架构师](https://arxiv.org/abs/2207.13751) | [***``[code]``***](https://github.com/apple/ml-gaudi)
    > 我们介绍了 GAUDI，这是一种生成模型，能够捕捉复杂而逼真的 3D 场景的分布，可以从移动的相机中沉浸式地渲染。我们用一种可扩展但功能强大的方法来解决这个具有挑战性的问题，我们首先优化一个潜在的表示，以解开辐射场和相机姿势。然后使用这种潜在表示来学习生成模型，该模型可以无条件和有条件地生成 3D 场景.我们的模型通过消除相机姿态分布可以跨样本共享的假设来概括以前专注于单个对象的工作。我们展示了 GAUDI 在跨多个数据集的无条件生成设置中获得了最先进的性能，并允许在给定条件变量（如稀疏图像观察或描述场景的文本）的情况下有条件地生成 3D 场景。
  - [AlignSDF：用于手对象重建的姿势对齐有符号距离场, ECCV2022](https://arxiv.org/abs/2207.12909) | [***``[code]``***](https://zerchen.github.io/projects/alignsdf.html)
    > 最近的工作在从单目彩色图像联合重建手和操纵对象方面取得了令人瞩目的进展。现有方法侧重于参数网格或符号距离场 (SDF) 方面的两种替代表示。一方面，参数模型可以从先验知识中受益，但代价是有限的形状变形和网格分辨率。因此，网格模型可能无法精确重建细节，例如手和物体的接触面。另一方面，基于 SDF 的方法可以表示任意细节，但缺乏明确的先验。在这项工作中，我们的目标是使用参数表示提供的先验改进 SDF 模型。特别是，我们提出了一个联合学习框架，可以解开姿势和形状。我们从参数模型中获取手和物体的姿势，并使用它们在 3D 空间中对齐 SDF。我们表明，这种对齐的 SDF 更好地专注于重建形状细节并提高手和物体的重建精度。我们评估了我们的方法，并在具有挑战性的 ObMan 和 DexYCB 基准上展示了对现有技术的显着改进。
  - [NeuMesh：学习基于解缠结神经网格的隐式场，用于几何和纹理编辑, ECCV2022(oral)](https://arxiv.org/abs/2207.11911) | [code]
    > 最近，神经隐式渲染技术得到了迅速发展，并在新颖的视图合成和 3D 场景重建中显示出巨大的优势。然而，现有的用于编辑目的的神经渲染方法提供的功能有限，例如，刚性变换，或者不适用于日常生活中一般对象的细粒度编辑。在本文中，我们提出了一种新颖的基于网格的表示，通过在网格顶点上使用解开几何和纹理代码对神经隐场进行编码，这促进了一组编辑功能，包括网格引导的几何编辑、带有纹理交换的指定纹理编辑、填充和绘画操作。为此，我们开发了几种技术包括可学习的符号指标以放大基于网格的表示的空间可区分性，蒸馏和微调机制以实现稳定收敛，以及空间感知优化策略以实现精确的纹理编辑。对真实数据和合成数据的大量实验和编辑示例证明了我们的方法在表示质量和编辑能力方面的优越性。代码可在项目网页上找到：此 https URL。
## Previous weeks
  - [非刚性神经辐射场：单目视频变形场景的重建和新视图合成，, ICCV2021](https://vcai.mpi-inf.mpg.de/projects/nonrigid_nerf/) | [***``[code]``***](https://github.com/facebookresearch/nonrigid_nerf)
    > 我们提出了非刚性神经辐射场 (NR-NeRF)，这是一种用于一般非刚性动态场景的重建和新颖的视图合成方法。我们的方法将动态场景的 RGB 图像作为输入（例如，来自单目视频记录），并创建高质量的时空几何和外观表示。我们表明，单个手持消费级相机足以从新颖的虚拟相机视图合成动态场景的复杂渲染，例如一个“子弹时间”的视频效果。 NR-NeRF 将动态场景分解为规范体积及其变形。场景变形被实现为光线弯曲，其中直线光线被非刚性变形。我们还提出了一种新的刚性网络来更好地约束场景的刚性区域，从而获得更稳定的结果。射线弯曲和刚性网络在没有明确监督的情况下进行训练。我们的公式可以实现跨视图和时间的密集对应估计，以及引人注目的视频编辑应用程序，例如运动夸张。我们的代码将是开源的。
  - [神经关节辐射场, ICCV2021](https://arxiv.org/abs/2104.03110) | [***``[code]``***](https://github.com/nogu-atsu/NARF#code)
    > 我们提出了神经关节辐射场 (NARF)，这是一种新颖的可变形 3D 表示，用于从图像中学习到的关节对象。虽然 3D 隐式表示的最新进展使得学习复杂对象的模型成为可能，但学习关节对象的姿势可控表示仍然是一个挑战，因为当前的方法需要 3D 形状监督并且无法呈现外观。在制定 3D 关节对象的隐式表示时，我们的方法在求解每个 3D 位置的辐射场时仅考虑最相关对象部分的刚性变换。通过这种方式，所提出的方法可以表示与姿势相关的变化，而不会显着增加计算复杂度。 NARF 是完全可微的，可以从带有姿势注释的图像中训练出来。此外，通过使用自动编码器，它可以学习对象类的多个实例的外观变化。实验表明，所提出的方法是有效的，并且可以很好地推广到新的姿势。
  - [GRF：学习用于 3D 场景表示和渲染的一般辐射场, ICCV2021(oral)](https://arxiv.org/abs/2010.04595) | [***``[code]``***](https://github.com/alextrevithick/GRF)
    > 我们提出了一个简单而强大的神经网络，它仅从 2D 观察中隐式表示和渲染 3D 对象和场景。该网络将 3D 几何建模为一般辐射场，它以一组具有相机位姿和内在函数的 2D 图像作为输入，为 3D 空间的每个点构建内部表示，然后渲染该点的相应外观和几何观察从任意位置。我们方法的关键是学习 2D 图像中每个像素的局部特征，然后将这些特征投影到 3D 点，从而产生一般和丰富的点表示。我们还集成了一种注意力机制来聚合来自多个 2D 视图的像素特征，从而隐式考虑视觉遮挡。大量实验表明，我们的方法可以为新物体、看不见的类别和具有挑战性的现实世界场景生成高质量和逼真的新视图。
  - [MVSNeRF：从多视图立体快速概括辐射场重建, ICCV2021](https://apchenstu.github.io/mvsnerf/) | [***``[code]``***](https://github.com/apchenstu/mvsnerf)
    > 我们提出了 MVSNeRF，一种新颖的神经渲染方法，可以有效地重建神经辐射场以进行视图合成。与先前的神经辐射场工作考虑对密集捕获的图像进行逐场景优化不同，我们提出了一个通用的深度神经网络，它可以通过快速网络推理仅从三个附近的输入视图重建辐射场。我们的方法利用平面扫描成本体积（广泛用于多视图立体）进行几何感知场景推理，并将其与基于物理的体积渲染相结合用于神经辐射场重建。我们在 DTU 数据集中的真实对象上训练我们的网络，并在三个不同的数据集上对其进行测试，以评估其有效性和普遍性。我们的方法可以跨场景（甚至是室内场景，与我们的对象训练场景完全不同）进行泛化，并仅使用三个输入图像生成逼真的视图合成结果，显着优于可泛化辐射场重建的并行工作。此外，如果捕捉到密集的图像，我们估计的辐射场表示可以很容易地进行微调；与 NeRF 相比，这导致具有更高渲染质量和更短优化时间的快速每场景重建。
  - [使用 NeRF 实现新视图合成的连续深度 MPI, ICCV2021](https://arxiv.org/abs/2103.14910) | [***``[code]``***](https://github.com/vincentfung13/MINE)
    > 在本文中，我们建议 MINE 通过从单个图像进行密集 3D 重建来执行新颖的视图合成和深度估计。我们的方法是通过引入神经辐射场 (NeRF) 对多平面图像 (MPI) 进行连续深度泛化。给定单个图像作为输入，MINE 预测任意深度值的 4 通道图像（RGB 和体积密度）以联合重建相机平截头体并填充被遮挡的内容。然后可以使用可微分渲染轻松地将重建和修复的截锥体渲染为新颖的 RGB 或深度视图。在 RealEstate10K、KITTI 和 Flowers Light Fields 上进行的大量实验表明，我们的 MINE 在新颖的视图合成中大大优于最先进的技术。我们还在 iBims-1 和 NYU-v2 的深度估计方面取得了具有竞争力的结果，而无需注释深度监督。我们的源代码可在此 https 网址获得
  - [UNISURF：统一神经隐式表面和辐射场以进行多视图重建, ICCV2021(oral)](https://arxiv.org/abs/2104.10078) | [***``[code]``***](https://github.com/autonomousvision/unisurf)
    > 神经隐式 3D 表示已成为从多视图图像重建表面和合成新视图的强大范例。不幸的是，DVR 或 IDR 等现有方法需要精确的每像素对象掩码作为监督。同时，神经辐射场已经彻底改变了新的视图合成。然而，NeRF 的估计体积密度不允许精确的表面重建。我们的主要见解是隐式表面模型和辐射场可以以统一的方式制定，从而使用相同的模型实现表面和体积渲染。这种统一的视角实现了新颖、更有效的采样程序，并能够在没有输入掩码的情况下重建准确的表面。我们在 DTU、BlendedMVS 和合成室内数据集上比较我们的方法。我们的实验表明，我们在重建质量方面优于 NeRF，同时在不需要掩码的情况下与 IDR 相当。
  - [NeuS：通过体渲染学习神经隐式表面以进行多视图重建, NeurIPS2021](https://arxiv.org/abs/2106.10689) | [***``[code]``***](https://github.com/Totoro97/NeuS)
    > 我们提出了一种新的神经表面重建方法，称为 NeuS，用于从 2D 图像输入中重建具有高保真度的对象和场景。现有的神经表面重建方法，如 DVR 和 IDR，需要前景掩码作为监督，容易陷入局部最小值，因此难以重建具有严重自遮挡或薄结构的物体。同时，最近用于新视图合成的神经方法，例如 NeRF 及其变体，使用体积渲染来生成具有优化鲁棒性的神经场景表示，即使对于高度复杂的对象也是如此。然而，从这种学习到的隐式表示中提取高质量的表面是很困难的，因为表示中没有足够的表面约束。在 NeuS 中，我们建议将表面表示为有符号距离函数 (SDF) 的零级集，并开发一种新的体绘制方法来训练神经 SDF 表示。我们观察到传统的体绘制方法会导致表面重建的固有几何误差（即偏差），因此提出了一种新的公式，该公式在一阶近似中没有偏差，从而即使没有掩模监督也能实现更准确的表面重建.在 DTU 数据集和 BlendedMVS 数据集上的实验表明，NeuS 在高质量表面重建方面优于最先进的技术，特别是对于具有复杂结构和自遮挡的物体和场景。
  - [神经隐式表面的体积渲染, NeurIPS2021](https://arxiv.org/abs/2106.12052) | [code]
    > 神经体绘制最近变得越来越流行，因为它成功地从一组稀疏的输入图像中合成了场景的新视图。到目前为止，通过神经体绘制技术学习的几何图形是使用通用密度函数建模的。此外，几何本身是使用密度函数的任意水平集提取的，这会导致嘈杂的、通常是低保真度的重建。本文的目标是改进神经体绘制中的几何表示和重建。我们通过将体积密度建模为几何形状的函数来实现这一点。这与之前将几何建模为体积密度函数的工作形成对比。更详细地说，我们将体积密度函数定义为应用于有符号距离函数 (SDF) 表示的拉普拉斯累积分布函数 (CDF)。这种简单的密度表示具有三个好处：（i）它为在神经体绘制过程中学习的几何图形提供了有用的归纳偏差； (ii) 它有助于限制不透明度近似误差，从而实现对视线的准确采样。准确的采样对于提供几何和辐射的精确耦合很重要； (iii) 它允许在体积渲染中对形状和外观进行有效的无监督解开。将这种新的密度表示应用于具有挑战性的场景多视图数据集产生了高质量的几何重建，优于相关的基线。此外，由于两者的分离，可以在场景之间切换形状和外观。
