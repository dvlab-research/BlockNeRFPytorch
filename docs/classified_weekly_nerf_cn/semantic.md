
每周分类神经辐射场 - semantic ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
=====================================================================================================================================
## 按类别筛选: 
 [全部](../weekly_nerf_cn.md) | [动态](./dynamic.md) | [编辑](./editing.md) | [快速](./fast.md) | [泛化](./generalization.md) | [人体](./human.md) | [视频](./video.md) | [光照](./lighting.md) | [重建](./reconstruction.md) | [纹理](./texture.md) | [语义](./semantic.md) | [姿态-SLAM](./pose-slam.md) | [其他](./others.md) 
## Oct2- Oct8, 2022
  - [神经匹配字段：视觉对应匹配字段的隐式表示, NeurIPS2022](https://arxiv.org/abs/2210.02689) | [***``[code]``***](https://ku-cvlab.github.io/NeMF/)
    > 现有的语义对应管道通常包括提取高级语义特征以保持对类内变化和背景杂波的不变性。然而，这种架构不可避免地会导致低分辨率匹配字段，该字段还需要临时插值过程作为将其转换为高分辨率的后处理，这肯定会限制匹配结果的整体性能。为了克服这个问题，受隐式神经表示最近成功的启发，我们提出了一种新的语义对应方法，称为神经匹配场 (NeMF)。然而，4D 匹配场的复杂性和高维性是主要障碍，我们提出了一种成本嵌入网络来处理粗略的成本量，以作为通过以下全连接网络建立高精度匹配场的指导。然而，学习高维匹配字段仍然具有挑战性，主要是由于计算复杂性，因为简单的穷举推理需要从 4D 空间中的所有像素中查询以推断像素级对应关系。为了克服这个问题，我们提出了充分的训练和推理程序，在训练阶段，我们随机抽取匹配的候选者，在推理阶段，我们在测试时迭代地执行基于 PatchMatch 的推理和坐标优化。通过这些结合，在语义对应的几个标准基准上获得了具有竞争力的结果。此 https URL 提供了代码和预训练的权重。
## Sep25 - Oct1, 2022
  - [了解体素网格 NeRF 模型的纯 CLIP 指导](https://arxiv.org/abs/2209.15172) | [code]
    > 我们使用 CLIP 探索文本到 3D 对象生成的任务。具体来说，我们在不访问任何数据集的情况下使用 CLIP 进行指导，我们将这种设置称为纯 CLIP 指导。虽然之前的工作采用了这种设置，但没有系统研究防止 CLIP 中产生对抗性生成的机制。我们说明了不同的基于图像的增强如何防止对抗性生成问题，以及生成的结果如何受到影响。我们测试了不同的 CLIP 模型架构，并表明集成不同的模型进行指导可以防止更大模型中的对抗性生成并产生更清晰的结果。此外，我们实现了一个隐式体素网格模型，以展示神经网络如何提供额外的正则化层，从而产生更好的几何结构和生成对象的连贯性。与之前的工作相比，我们以更高的记忆效率和更快的训练速度获得了更连贯的结果。
  - [具有三层采样和全景表示的城市级增量神经映射](https://arxiv.org/abs/2209.14072) | [code]
    > 神经隐式表示最近引起了机器人界的广泛关注，因为它们具有表现力、连续性和紧凑性。然而，基于稀疏 LiDAR 输入的城市规模增量隐式密集映射仍然是一个未充分探索的挑战。为此，我们成功构建了第一个具有全景表示的城市规模增量神经映射系统，该系统由环境级和实例级建模组成。给定一个稀疏的 LiDAR 点云流，它维护一个动态生成模型，将 3D 坐标映射到有符号距离场 (SDF) 值。为了解决在城市尺度空间中表示不同层次几何信息的困难，我们提出了一种定制的三层采样策略来动态采样全局、局部和近地表域。同时，为了实现高保真映射，引入了特定类别的先验以更好地对几何细节进行建模，从而实现全景表示。我们评估了公共 SemanticKITTI 数据集，并使用定量和定性结果证明了新提出的三层采样策略和全景表示的重要性。代码和数据将公开。
  - [360FusionNeRF：具有联合引导的全景神经辐射场](https://arxiv.org/abs/2209.14265) | [code]
    > 我们提出了一种基于神经辐射场 (NeRF) 从单个 360 度全景图像合成新视图的方法。类似设置中的先前研究依赖于多层感知的邻域插值能力来完成由遮挡引起的缺失区域，这导致其预测中的伪影。我们提出了 360FusionNeRF，这是一个半监督学习框架，我们在其中引入几何监督和语义一致性来指导渐进式训练过程。首先，将输入图像重新投影到 360 度图像，并在其他相机位置提取辅助深度图。除了 NeRF 颜色指导之外，深度监督还改进了合成视图的几何形状。此外，我们引入了语义一致性损失，鼓励对新视图进行逼真的渲染。我们使用预训练的视觉编码器（例如 CLIP）提取这些语义特征，CLIP 是一种视觉转换器，通过自然语言监督从网络挖掘出的数亿张不同的 2D 照片进行训练。实验表明，我们提出的方法可以在保留场景特征的同时产生未观察到的区域的合理完成。在跨各种场景进行训练时，360FusionNeRF 在转移到合成 Structured3D 数据集（PSNR~5%，SSIM~3% LPIPS~13%）、真实世界的 Matterport3D 数据集（PSNR~3%）时始终保持最先进的性能, SSIM~3% LPIPS~9%) 和 Replica360 数据集 (PSNR~8%, SSIM~2% LPIPS~18%)。
  - [烘焙特征：通过渲染特征图加速体积分割](https://arxiv.org/abs/2209.12744) | [code]
    > 最近提出了一些方法，即仅使用彩色图像和专家监督以稀疏语义注释像素的形式将 3D 体积密集分割成类。虽然令人印象深刻，但这些方法仍然需要相对大量的监督，并且在实践中分割对象可能需要几分钟。这样的系统通常只优化它们在它们适合的特定场景上的表示，而不利用来自先前看到的图像的任何先验信息。在本文中，我们建议使用在现有大型数据集上训练的模型提取的特征来提高分割性能。我们通过体积渲染特征图并监督从每个输入图像中提取的特征，将这种特征表示烘焙到神经辐射场 (NeRF) 中。我们表明，通过将这种表示烘焙到 NeRF 中，我们使后续的分类任务变得更加容易。我们的实验表明，与现有方法相比，我们的方法在广泛的场景中以更少的语义注释实现了更高的分割精度。
## Sep18 - Sep24, 2022
  - [NeRF-SOS：复杂场景上的任意视图自监督对象分割](https://zhiwenfan.github.io/NeRF-SOS/) | [***``[code]``***](https://github.com/VITA-Group/NeRF-SOS)
    > 神经体积表示已经显示了多层感知器 (MLP) 可以使用多视图校准图像进行优化以表示场景几何和外观的潜力，而无需明确的 3D 监督。对象分割可以基于学习到的辐射场丰富许多下游应用。然而，引入手工分割来定义复杂现实世界场景中的感兴趣区域并非易事且成本高昂，因为它需要每个视图注释。本文针对复杂的现实世界场景使用 NeRF 进行对象分割的自监督学习探索。我们的框架称为带有自监督对象分割 NeRF-SOS 的 NeRF，它结合了对象分割和神经辐射场来分割场景中任何视图中的对象。通过在外观和几何级别上提出一种新颖的协作对比损失，NeRF-SOS 鼓励 NeRF 模型从其密度场和自我监督的预训练 2D 视觉特征中提取紧凑的几何感知分割簇。自监督对象分割框架可以应用于各种 NeRF 模型，这些模型既可以产生逼真的渲染结果，又可以在室内和室外场景中提供令人信服的分割图。 LLFF、Tank & Temple 和 BlendedMVS 数据集的广泛结果验证了 NeRF-SOS 的有效性。它始终超越其他基于 2D 的自我监督基线，并预测比现有监督对应物更精细的语义掩码。请参阅我们项目页面上的视频以获取更多详细信息：此 https URL。
  - [医学影像分割的隐式神经表示, MICCAI2022](https://link.springer.com/chapter/10.1007/978-3-031-16443-9_42) | [code]
    > 医学成像中的 3D 信号（例如 CT 扫描）通常被参数化为体素的离散网格。例如，现有的最先进的器官分割方法学习离散的分割图。不幸的是，这些方法的内存需求随着空间分辨率的增加而呈立方增长，这使得它们不适合处理高分辨率扫描。为了克服这个问题，我们设计了一个隐式器官分割网络 (IOSNet)，它利用连续的隐式神经表示并具有几个有用的属性。首先，IOSNet 解码器内存大致恒定且独立于空间分辨率，因为它将分割图参数化为连续函数。其次，IOSNet 的收敛速度比基于离散体素的方法快得多，因为它能够准确地分割器官而不受器官大小的影响，从而在不需要任何辅助技巧的情况下缓解大小不平衡问题。第三，由于其连续学习表示，IOSNet 自然支持超分辨率（即在推理过程中以任意分辨率采样）。此外，尽管使用了一个简单的轻量级解码器，IOSNet 始终优于离散专业分割架构 UNet。因此，我们的方法表明隐式神经表示非常适合医学成像应用，尤其是处理高分辨率 3D 医学扫描。
## Sep11 - Sep17, 2022
## Previous weeks
## Sep4 - Sep10, 2022
  - [神经特征融合领域：自监督 2D 图像表示的 3D 蒸馏, 3DV2022(oral)](https://arxiv.org/abs/2209.03494) | [***``[code]``***](https://github.com/dichotomies/N3F)
    > 我们提出了神经特征融合场 (N3F)，这是一种在将密集 2D 图像特征提取器应用于可重构为 3D 场景的多张图像分析时改进密集 2D 图像特征提取器的方法。给定一个图像特征提取器，例如使用自我监督进行预训练，N3F 使用它作为教师来学习在 3D 空间中定义的学生网络。 3D 学生网络类似于提取所述特征的神经辐射场，并且可以使用通常的可微渲染机器进行训练。因此，N3F 很容易适用于大多数神经渲染公式，包括 vanilla NeRF 及其对复杂动态场景的扩展。我们表明，我们的方法不仅能够在不使用手动标签的情况下在特定场景的神经领域的上下文中实现语义理解，而且在自我监督的 2D 基线上持续改进。这通过考虑不同序列中的各种任务（例如 2D 对象检索、3D 分割和场景编辑）来证明，包括 EPIC-KITCHENS 基准测试中的以自我为中心的长视频。
## Aug28 - Sep3, 2022
## Aug21 - Aug27, 2022
## Previous weeks
## Aug21 - Aug27, 2022
  - [DreamBooth：为主题驱动生成微调文本到图像的扩散模型](https://dreambooth.github.io/) | [code]
    > 大型文本到图像模型在人工智能的演进中实现了显着的飞跃，能够从给定的文本提示中对图像进行高质量和多样化的合成。然而，这些模型缺乏模仿给定参考集中对象的外观并在不同上下文中合成它们的新颖再现的能力。在这项工作中，我们提出了一种“个性化”文本到图像扩散模型的新方法（专门针对用户的需求）。给定主题的几张图像作为输入，我们微调预训练的文本到图像模型（Imagen，尽管我们的方法不限于特定模型），以便它学会将唯一标识符与该特定主题绑定.一旦对象被嵌入模型的输出域中，唯一标识符就可以用于合成在不同场景中情境化的对象的完全新颖的真实感图像。通过利用嵌入在模型中的语义先验和新的自生类特定先验保存损失，我们的技术能够在参考图像中没有出现的不同场景、姿势、视图和照明条件下合成主体。我们将我们的技术应用于几个以前无懈可击的任务，包括主题重新上下文化、文本引导视图合成、外观修改和艺术渲染（同时保留主题的关键特征）。项目页面：此 https 网址
## Aug14 - Aug20, 2022
## Aug7 - Aug13, 2022
## Jul31 - Aug6, 2022
  - [NeSF: 用于 3D 场景的可概括语义分割的神经语义场](https://research.google/pubs/pub51563/) | [code]
    > 我们提出了 NeSF，一种从预训练的密度场和稀疏的 2D 语义监督产生 3D 语义场的方法。我们的方法通过利用将 3D 信息存储在神经域中的神经表示来避开传统的场景表示。尽管仅由 2D 信号监督，我们的方法能够从新颖的相机姿势生成 3D 一致的语义图，并且可以在任意 3D 点进行查询。值得注意的是，NeSF 与任何产生密度场的方法兼容，并且随着预训练密度场质量的提高，其准确性也会提高。我们的实证分析证明了在令人信服的合成场景上与竞争性 2D 和 3D 语义分割基线相当的质量，同时还提供了现有方法无法提供的功能。
## Jul24 - Jul30, 2022
## Previous weeks
  - [节食 NeRF：语义一致的 Few-Shot 视图合成, ICCV2021](https://www.ajayj.com/dietnerf) | [***``[code]``***](https://github.com/ajayjain/DietNeRF)
    > 我们提出了 DietNeRF，一种从几张图像估计的 3D 神经场景表示。神经辐射场 (NeRF) 通过多视图一致性学习场景的连续体积表示，并且可以通过光线投射从新颖的视点进行渲染。虽然 NeRF 在给定许多图像的情况下具有令人印象深刻的重建几何和精细细节的能力，对于具有挑战性的 360° 场景最多可重建 100 个，但当只有少数输入视图可用时，它通常会为其图像重建目标找到退化的解决方案。为了提高few-shot质量，我们提出了DietNeRF。我们引入了一种辅助语义一致性损失，它鼓励以新颖的姿势进行逼真的渲染。 DietNeRF 在单个场景上进行训练，以 (1) 从相同的姿势正确渲染给定的输入视图，以及 (2) 在不同的随机姿势中匹配高级语义属性。我们的语义损失使我们能够从任意姿势监督 DietNeRF。我们使用预训练的视觉编码器提取这些语义，例如 CLIP，这是一种视觉转换器，通过自然语言监督从网络挖掘出的数亿张不同的单视图 2D 照片进行训练。在实验中，DietNeRF 在从头开始学习时提高了少镜头视图合成的感知质量，在多视图数据集上进行预训练时，可以用少至一张观察到的图像渲染新视图，并生成完全未观察到的区域的合理完成。
  - [物体辐射场的无监督发现, ICLR2022](https://arxiv.org/abs/2107.07905) | [code]
    > 我们研究从单个图像推断以对象为中心的场景表示的问题，旨在推导出解释图像形成过程的表示，捕捉场景的 3D 性质，并且在没有监督的情况下学习。由于将复杂的 3D 到 2D 图像形成过程集成到强大的推理方案（如深度网络）中存在根本性挑战，大多数现有的场景分解方法都缺乏这些特征中的一个或多个。在本文中，我们提出了对象辐射场 (uORF) 的无监督发现，将神经 3D 场景表示和渲染的最新进展与深度推理网络相结合，用于无监督 3D 场景分解。在没有注释的多视图 RGB 图像上进行训练，uORF 学习从单个图像分解具有不同纹理背景的复杂场景。我们展示了 uORF 在无监督 3D 场景分割、新视图合成和三个数据集上的场景编辑方面表现良好。
  - [使用隐式场景表示进行就地场景标记和理解, ICCV2021(oral)](https://shuaifengzhi.com/Semantic-NeRF/) | [***``[code]``***](https://github.com/Harry-Zhi/semantic_nerf/)
    > 语义标签与几何和辐射重建高度相关，因为具有相似形状和外观的场景实体更有可能来自相似的类别。最近的隐式神经重建技术很有吸引力，因为它们不需要事先的训练数据，但同样的完全自我监督的方法对于语义来说是不可能的，因为标签是人类定义的属性。
