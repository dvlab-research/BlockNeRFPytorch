
每周分类神经辐射场 - pose-slam ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
======================================================================================================================================
## 按类别筛选: 
 [全部](../weekly_nerf_cn.md) | [动态](./dynamic.md) | [编辑](./editing.md) | [快速](./fast.md) | [泛化](./generalization.md) | [人体](./human.md) | [视频](./video.md) | [光照](./lighting.md) | [重建](./reconstruction.md) | [纹理](./texture.md) | [语义](./semantic.md) | [姿态-SLAM](./pose-slam.md) | [其他](./others.md) 
## Dec27 - Jan3, 2023
## Dec25 - Dec31, 2022
## Dec18 - Dec24, 2022
## Dec11 - Dec17, 2022
## Dec4 - Dec10, 2022
  - [用于相机重定位的快速轻量级场景回归器](https://arxiv.org/abs/2212.01830) | [***``[code]``***](https://github.com/aislab/feat2map)
    > 涉及先前 3D 重建的相机重定位在许多混合现实和机器人应用中起着至关重要的作用。 对于一些存储和/或通信带宽有限的应用程序，直接根据预建 3D 模型估计相机姿势可能非常昂贵。 尽管最近的场景和绝对姿态回归方法在有效的相机定位方面变得流行，但它们中的大多数都是计算资源密集型的，并且难以获得具有高精度约束的实时推理。 本研究提出了一种简单的场景回归方法，只需要一个多层感知器网络来映射场景坐标，即可实现准确的相机姿态估计。 所提出的方法使用稀疏描述符来回归场景坐标，而不是密集的 RGB 图像。 使用稀疏特征有几个优点。 首先，拟议的回归网络比以前的研究报告的要小得多。 这使我们的系统高效且可扩展。 其次，预建的 3D 模型提供了最可靠和稳健的 2D-3D 匹配。 因此，向它们学习可以导致对等效特征的认识并显着提高泛化性能。 提供了对我们的方法的详细分析和使用现有数据集的广泛评估，以支持所提出的方法。 可在此 https URL 获取实施细节
## Nov27 - Dec3, 2022
## Nov20 - Nov26, 2022
  - [RUST：来自未定图像的潜在神经场景表示](https://arxiv.org/abs/2211.14306) | [code]
    > 从 2D 观察中推断 3D 场景的结构是计算机视觉中的一项基本挑战。最近流行的基于神经场景表示的方法已经取得了巨大的影响，并已应用于各种应用程序。这个领域剩下的主要挑战之一是训练一个单一的模型，它可以提供潜在的表示，有效地泛化到单个场景之外。 Scene Representation Transformer (SRT) 在这个方向上显示出希望，但将其扩展到更大的不同场景集是具有挑战性的，并且需要准确定位的地面实况数据。为了解决这个问题，我们提出了 RUST（Really Unposed Scene representation Transformer），这是一种仅在 RGB 图像上训练的新颖视图合成的无姿势方法。我们的主要见解是，可以训练一个姿势编码器，它可以窥视目标图像并学习潜在姿势嵌入，解码器将其用于视图合成。我们对学习到的潜在姿势结构进行了实证研究，并表明它允许有意义的测试时间相机转换和准确的显式姿势读出。或许令人惊讶的是，RUST 实现了与获得完美相机姿势的方法相似的质量，从而释放了大规模训练摊销神经场景表示的潜力。
  - [ActiveRMAP：用于主动映射和规划的辐射场](https://arxiv.org/abs/2211.12656) | [code]
    > 通过离线/在线映射方法，可以从一组 2D 图像中对场景进行高质量的 3D 重建。在本文中，我们从隐式表示的角度探索主动映射，最近在各种应用中产生了令人信服的结果。最流行的隐式表示之一——神经辐射场 (NeRF)，首先展示了使用多层感知器的照片级真实感渲染结果，并将有前途的离线 3D 重建作为辐射场的副产品。最近，研究人员还将这种隐式表示应用于在线重建和定位（即隐式 SLAM 系统）。然而，将隐式表示用于主动视觉任务的研究仍然非常有限。在本文中，我们对将神经辐射场应用于主动映射和规划问题特别感兴趣，这些问题是主动系统中紧密耦合的任务。我们首次提出了一个仅使用 RGB 的主动视觉框架，该框架使用辐射场表示以在线方式进行主动 3D 重建和规划。具体来说，我们将此联合任务制定为迭代双阶段优化问题，我们交替优化辐射场表示和路径规划。实验结果表明，与其他离线方法相比，所提出的方法取得了有竞争力的结果，并且优于使用 NeRF 的主动重建方法。
  - [束调整神经辐射场的局部到全局配准](https://arxiv.org/abs/2211.11505) | [***``[code]``***](https://github.com/rover-xingyu/L2G-NeRF)
    > Neural Radiance Fields (NeRF) 实现了逼真的新视图合成；然而，精确相机位姿的要求限制了它的应用。尽管存在用于联合学习神经 3D 表示和注册相机帧的分析综合扩展，但如果初始化不当，它们很容易受到次优解决方案的影响。我们提出了 L2G-NeRF，这是一种用于束调整神经辐射场的局部到全局配准方法：首先，逐像素灵活对齐，然后逐帧约束参数对齐。通过优化光度重建误差的深度网络以无监督的方式学习逐像素局部对齐。使用可微分参数估计求解器对逐像素对应执行逐帧全局对齐以找到全局变换。对合成数据和真实世界数据的实验表明，我们的方法在高保真重建和解决大型相机姿态失调方面优于当前最先进的方法。我们的模块是一个易于使用的插件，可以应用于 NeRF 变体和其他神经领域应用程序。此 https URL 提供了代码和补充材料。
  - [Neural Puppeteer：基于关键点的动态形状神经渲染, ACCV2022](https://openaccess.thecvf.com/content/ACCV2022/html/Giebenhain_Neural_Puppeteer_Keypoint-Based_Neural_Rendering_of_Dynamic_Shapes_ACCV_2022_paper.html) | [***``[code]``***](https://github.com/urs-waldmann/NePu/)
    > 我们介绍了 Neural Puppeteer，这是一种用于铰接形状的高效神经渲染管道。通过逆向渲染，我们可以单独从多视图 2D 轮廓预测 3D 关键点，而不需要纹理信息。此外，我们可以使用一个相同的训练模型轻松预测同一类形状的 3D 关键点，并更容易地从合成数据的训练中进行概括，我们通过成功地将零样本合成应用于现实世界的实验来证明这一点。我们通过将模型拟合到不同动物和人类的合成视频来展示我们方法的灵活性，并获得优于我们基线的定量结果。我们的方法将 3D 关键点与各个局部特征向量和全局潜在代码结合使用，以有效表示时变和铰接的形状，例如人类和动物。与之前的工作相比，我们不在 3D 域中进行重建，而是将 3D 特征投影到 2D 相机中，并根据这些投影特征对 2D RGB-D 图像进行重建，这比体积渲染要快得多。我们的合成数据集将公开可用，以进一步发展不断发展的动物姿势和形状重建领域。
## Nov13 - Nov19, 2022
## Nov6 - Nov12, 2022
## Oct30 - Nov5, 2022
  - [nerf2nerf：神经辐射场的成对配准](https://arxiv.org/abs/2211.01600) | [code]
    > 我们引入了一种神经场成对配准技术，该技术扩展了经典的基于优化的局部配准（即 ICP）以在神经辐射场 (NeRF) 上运行——从校准图像集合训练的神经 3D 场景表示。 NeRF 不分解照明和颜色，因此为了使配准不受照明影响，我们引入了“表面场”的概念——从预训练的 NeRF 模型中提取的场，该模型测量点在表面上的可能性物体的表面。然后，我们将 nerf2nerf 注册作为一种稳健的优化，迭代地寻求对齐两个场景的表面场的刚性转换。我们通过引入预训练的 NeRF 场景数据集来评估我们的技术的有效性——我们的合成场景可以对经典配准技术进行定量评估和比较，而我们的真实场景则证明了我们的技术在现实场景中的有效性。其他结果位于：此 https 网址
  - [GARF：用于高保真重建和姿态估计的高斯激活辐射场, ECCV2022](https://arxiv.org/abs/2204.05735) | [code]
    > 尽管神经辐射场 (NeRF) 在现实世界场景的逼真新颖视图合成中显示出令人信服的结果，但大多数现有方法都需要准确的先验相机姿势。尽管存在联合恢复辐射场和相机姿态的方法 (BARF)，但它们依赖于繁琐的从粗到细的辅助位置嵌入来确保良好的性能。我们提出了高斯激活神经辐射场 (GARF)，这是一种新的无位置嵌入神经辐射场架构 - 采用高斯激活 - 在高保真重建和姿态估计方面优于当前最先进的技术。
  - [深入研究 Radiance Grid 以进行实时视图合成并保留细节, ECCV2022](https://link.springer.com/chapter/10.1007/978-3-031-19784-0_42) | [code]
    > 神经辐射场 (NeRF) [31] 系列在表示场景和合成高质量新颖视图方面令人印象深刻。然而，大多数以前的作品都无法保留纹理细节并且训练速度慢。最近的一种方法 SNeRG [11] 表明，将经过训练的 NeRF 烘焙为稀疏神经辐射网格可以实现实时视图合成，同时略微降低渲染质量。在本文中，我们深入研究了 Radiance Grid 表示并提出了一系列改进，这些改进共同提高了速度和质量方面的性能。首先，我们提出了一种分层稀疏辐射网格 (HrSRG) 表示，它对信息空间具有更高的体素分辨率，对其他空间具有更少的体素。 HrSRG 利用受 [30, 55] 启发的分层体素网格构建过程，并且可以在不占用过多内存的情况下以高分辨率描述场景。此外，我们表明直接优化体素网格会在渲染图像中产生出奇的好纹理细节。这种直接优化是内存友好的，并且需要比传统 NeRF 少多个数量级的时间，因为它只涉及一个微型 MLP。最后，我们发现阻止精细细节恢复的一个关键因素是由相机姿势错误引起的图像中未对齐的 2D 像素。我们建议使用感知损失来增加对错位的容忍度，从而提高渲染图像的视觉质量。
## Oct23 - Oct29, 2022
  - [EpipolarNVS：利用对极几何进行单图像新视图合成, BMVC2022](https://arxiv.org/abs/2210.13077) | [code]
    > 新视图合成 (NVS) 可以通过不同的方法来解决，具体取决于一般设置：单个源图像到短视频序列、精确或嘈杂的相机姿势信息、基于 3D 的信息（如点云等）。最具挑战性的场景，我们在这项工作中所处的场景，只考虑一个独特的源图像来从另一个角度生成一个新颖的图像。然而，在这种棘手的情况下，最新的基于学习的解决方案往往难以集成相机视点转换。事实上，外部信息通常通过低维向量按原样传递。甚至可能会发生这样的情况，当参数化为欧拉角时，这样的相机姿势会通过单热表示进行量化。这种普通的编码选择阻止了学习的架构在连续的基础上（从相机姿势的角度）推断新的视图。我们声称它存在一种优雅的方式来通过利用 3D 相关概念（例如对极约束）更好地编码相对相机姿势。因此，我们引入了一种创新方法，将视点变换编码为 2D 特征图像。这种相机编码策略为网络提供了关于相机如何在两个视图之间的空间中移动的有意义的见解。通过将相机姿势信息编码为有限数量的彩色对极线，我们通过实验证明我们的策略优于普通编码。
  - [NeRF-SLAM：具有神经辐射场的实时密集单目 SLAM](https://arxiv.org/abs/2210.13641) | [code]
    > 我们提出了一种新颖的几何和光度学 3D 映射管道，用于从单目图像进行准确和实时的场景重建。为实现这一目标，我们利用了密集单眼 SLAM 和实时分层体积神经辐射场的最新进展。我们的见解是，密集的单目 SLAM 通过提供准确的姿态估计和具有相关不确定性的深度图，提供正确的信息以实时拟合场景的神经辐射场。通过我们提出的基于不确定性的深度损失，我们不仅实现了良好的光度精度，而且还实现了很高的几何精度。事实上，我们提出的管道实现了比竞争方法更好的几何和光度精度（PSNR 提高了 179%，L1 深度提高了 86%），同时实时工作并且仅使用单目图像。
## Oct16 - Oct22, 2022
  - [用于学习 3D LiDAR 数据场景先验的生成范围成像, WACV2023](https://arxiv.org/abs/2210.11750) | [code]
    > 3D LiDAR 传感器对于自主移动机器人的强大视觉是必不可少的。然而，部署基于 LiDAR 的感知算法通常会由于与训练环境的域差距而失败，例如角度分辨率不一致和属性缺失。现有的研究通过学习域间映射解决了这个问题，而可迁移性受到训练配置的限制，并且训练容易受到称为光线下降的特殊有损噪声的影响。为了解决这个问题，本文提出了一种适用于数据级域迁移的 LiDAR 距离图像生成模型。受 LiDAR 测量基于逐点距离成像这一事实的启发，我们训练了一个基于隐式图像表示的生成对抗网络以及可微的射线下落效应。与基于点和基于图像的最先进的生成模型相比，我们展示了我们模型的保真度和多样性。我们还展示了上采样和恢复应用程序。此外，我们介绍了用于 LiDAR 语义分割的 Sim2Real 应用程序。我们证明了我们的方法作为一个逼真的光线滴模拟器是有效的，并且优于最先进的方法。
  - [通过多视图未校准光度立体和渐变 SDF 进行高质量 RGB-D 重建, WACV2023](https://arxiv.org/abs/2210.12202) | [code]
    > 在许多应用中，对精细重建的需求很高。然而，大多数现有的 RGB-D 重建方法依赖于预先计算的准确相机位姿来恢复详细的表面几何形状，其中在优化不同数量时需要调整表面的表示。在本文中，我们提出了一种新颖的基于多视图 RGB-D 的重建方法，该方法通过利用梯度符号距离场 (gradient-SDF) 来处理相机位姿、光照、反照率和表面法线估计。所提出的方法使用特定的基于物理的模型来制定图像渲染过程，并使用其体积表示来优化实际表面上的表面数量，而不是仅估计实际表面附近的表面数量的其他工作。为了验证我们的方法，我们研究了两个用于自然光和点光源应用的基于物理的图像形成模型。在合成数据集和真实世界数据集上的实验结果表明，所提出的方法可以比现有技术更忠实地恢复表面的高质量几何形状，并进一步提高估计相机位姿的准确性。
  - [从单个图像进行机器人对象操作的神经场, ICRA2023](https://arxiv.org/abs/2210.12126) | [code]
    > 我们为对象渲染、3D 重建和抓取姿势预测提供了一个统一且紧凑的表示，可以在几秒钟内从单个图像中推断出来。我们通过利用神经辐射场 (NeRF) 文献的最新进展来实现这一点，这些文献学习类别级先验并以最少的数据和时间对新对象进行微调。我们的见解是，我们可以学习紧凑的形状表示并从中提取有意义的附加信息，例如抓取姿势。我们相信这是第一个使用单个视点（仅 RGB）直接从基于 NeRF 的表示中检索抓取姿势的工作，而不是通过辅助网络和/或表示。与现有技术相比，我们的方法小两到三个数量级，同时在视图重建和抓取方面实现了相当的性能。伴随我们的方法，我们还提出了一个新的渲染鞋数据集，用于训练 sim-2-real NeRF 方法，该方法具有不同宽度的抓手的抓取姿势。
  - [用于鲁棒姿态估计的神经辐射场的并行反演, ICRA2023](https://arxiv.org/abs/2210.10108) | [code]
    > 我们提出了一种基于快速神经辐射场 (NeRF) 的并行优化方法，用于估计 6-DoF 目标姿势。给定单个观察到的目标 RGB 图像，我们可以通过最小化从快速 NeRF 模型渲染的像素与观察图像中的像素之间的残差来预测相机的平移和旋转。我们将基于动量的相机外部优化程序集成到 Instant Neural Graphics Primitives 中，这是最近异常快速的 NeRF 实现。通过在姿态估计任务中引入并行蒙特卡罗采样，我们的方法克服了局部最小值并在更广泛的搜索空间中提高了效率。我们还展示了采用更强大的基于像素的损失函数来减少错误的重要性。实验表明，我们的方法可以在合成和真实世界的基准测试中实现改进的泛化性和鲁棒性。
  - [神经接触场：使用触觉感应跟踪外部接触](https://arxiv.org/abs/2210.09297) | [code]
    > 我们提出了神经接触场，一种将神经场和触觉传感结合在一起的方法，以解决跟踪对象与环境之间的外部接触的问题。了解外部接触发生在哪里是迈向可以主动控制它以促进下游操作任务的方法的第一步。用于定位环境接触的先前工作通常假定接触类型（例如点或线），不捕获接触/非接触过渡，并且仅适用于基本几何形状的对象。神经接触场是第一种无需对接触类型做出任何假设即可跟踪任意多模态外部接触的方法。我们的主要见解是估计物体形状潜在空间中任何 3D 点的接触概率，给定基于视觉的触觉输入，该输入感知外部接触引起的局部运动。在实验中，我们发现神经接触场能够定位多个接触块，而无需对接触的几何形状做出任何假设，并在看不见的环境配置中捕获具有看不见的形状的已知类别对象的接触/非接触转换。除了神经接触场之外，我们还发布了模拟外部接触交互的 YCB-Extrinsic-Contact 数据集，以便在该领域进行进一步研究。项目存储库：此 https 网址
  - [动力学增强神经对象的微分物理模拟](https://arxiv.org/abs/2210.09420) | [code]
    > 我们提出了一种可微分管道，用于模拟将其几何形状表示为参数化为深度网络的连续密度场的对象的运动。这包括神经辐射场 (NeRFs) 和其他相关模型。从密度场，我们估计物体的动力学特性，包括它的质量、质心和惯性矩阵。然后，我们引入了一种基于密度场的可微接触模型，用于计算碰撞产生的法向力和摩擦力。这允许机器人从运动物体的静止图像和视频中自主构建视觉和动态准确的物体模型。生成的动态增强神经对象 (DANO) 使用现有的可微分模拟引擎 Dojo 进行模拟，并与其他标准模拟对象（例如指定为 URDF 的球体、平面和机器人）交互。机器人可以使用这种模拟来优化神经物体的抓取和操纵轨迹，或者通过基于梯度的真实到模拟传输来改进神经物体模型。我们演示了从肥皂在桌子上滑动的真实视频中学习一块肥皂的摩擦系数的管道。我们还通过从合成数据中与熊猫机器人手臂的交互来了解斯坦福兔子的摩擦系数和质量，并在模拟中优化熊猫手臂的轨迹，以将兔子推到目标位置。
## Oct9 - Oct15, 2022
  - [ExAug：通过几何经验增强的机器人条件导航策略](https://arxiv.org/abs/2210.07450) | [code]
    > 机器学习技术依赖于庞大而多样的数据集进行泛化。计算机视觉、自然语言处理和其他应用程序通常可以重用公共数据集来训练许多不同的模型。然而，由于物理配置的差异，利用公共数据集在新机器人平台上训练机器人控制策略或执行新任务具有挑战性。在这项工作中，我们提出了一个新颖的框架 ExAug，以从不同环境中的多个数据集中增强不同机器人平台的体验。 ExAug 利用了一个简单的原理：通过以点云的形式提取 3D 信息，我们可以创建更复杂和结构化的增强，利用生成合成图像和几何感知惩罚，这在相同情况下适用于不同的机器人，具有不同的尺寸、转弯半径和摄像头位置。在有障碍物的室内和室外环境中，在两个带有三个不同摄像头的新机器人平台上评估训练后的策略。
  - [NOCaL：里程计和相机内在学的免校准半监督学习](https://arxiv.org/abs/2210.07435) | [code]
    > 有许多新兴的成像技术可以使机器人技术受益。然而，对定制模型、校准和低级处理的需求是它们采用的主要障碍。在这项工作中，我们展示了 NOCaL、神经里程计和使用光场的校准，这是一种半监督学习架构，能够在没有校准的情况下解释以前看不见的相机。 NOCaL 学习估计相机参数、相对姿势和场景外观。它采用在大量现有摄像机和场景上预训练的场景渲染超网络，并使用小型监督训练集来适应以前看不见的摄像机来强制度量尺度。我们使用传统相机在渲染和捕获的图像上演示 NOCaL，演示免校准里程计和新颖的视图合成。这项工作是朝着自动解释一般相机几何形状和新兴成像技术迈出的关键一步。
  - [GeoAug：具有几何约束的 Few-Shot NeRF 的数据增强, ECCV2022](https://link.springer.com/chapter/10.1007/978-3-031-19790-1_20) | [code]
    > 神经辐射场 (NeRF) 通过学习仅具有姿势 RGB 图像的隐式体积表示，显示出渲染特定场景新视图的非凡能力。尽管 NeRF 令人印象深刻且简单，但在训练图像很少的情况下，它通常会收敛到几何不正确的次优解决方案。我们在此提出 GeoAug：一种用于 NeRF 的数据增强方法，它丰富了基于多视图几何约束的训练数据。 GeoAug 提供用于训练的随机人工（新姿势、RGB 图像）对，其中 RGB 图像来自附近的训练视图。新姿势的渲染被扭曲到具有深度图和相对姿势的附近训练视图，以匹配 RGB 图像监督。我们的方法通过在训练期间引入更多数据来降低过度拟合的风险，同时还为深度图提供了额外的隐式监督。在实验中，我们的方法显着提高了以少量训练视图为条件的神经辐射场的性能。
  - [逼真的神经域随机化, ECCV2022](https://link.springer.com/chapter/10.1007/978-3-031-19806-9_18) | [code]
    > 合成数据是人工监督的可扩展替代方案，但它需要克服模拟到真实领域的差距。虚拟世界和现实世界之间的这种差异可以通过两种看似相反的方法来解决：提高模拟的真实性或完全通过域随机化来超越真实性。在本文中，我们展示了神经渲染方面的最新进展实现了一种新的统一方法，我们称之为逼真的神经域随机化 (PNDR)。我们建议学习神经网络的组合，它充当基于物理的光线追踪器，仅从场景几何中生成高质量的渲染。我们的方法是模块化的，由用于材料、照明和渲染的不同神经网络组成，因此可以在可微的管道中随机化不同的关键图像生成组件。一旦经过训练，我们的方法可以与其他方法相结合，用于在线生成照片般逼真的图像增强，并且比通过传统的光线追踪更有效。我们通过两个下游任务证明了 PNDR 的有用性：6D 对象检测和单目深度估计。我们的实验表明，使用 PNDR 进行训练可以泛化到新场景，并且在现实世界传输方面明显优于现有技术。
  - [X-NeRF：多场景 360 的显式神经辐射场∘ RGB-D 视图不足, WACV2023](https://arxiv.org/abs/2210.05135) | [***``[code]``***](https://github.com/HaoyiZhu/XNeRF)
    > 神经辐射场 (NeRFs) 尽管在新颖的视图合成方面表现出色，但通常需要密集的输入视图。许多论文分别为每个场景训练一个模型，很少有人探索将多模态数据纳入这个问题。在本文中，我们关注一个很少讨论但很重要的设置：我们能否训练一个模型来表示多个场景、360∘ 视图和 RGB-D 图像不足？我们将不足的视图称为少数极其稀疏且几乎不重叠的视图。为了解决这个问题，提出了一种完全显式的方法 X-NeRF，它学习一般的场景完成过程而不是基于坐标的映射。给定一些不足的 RGB-D 输入视图，X-NeRF 首先将它们转换为稀疏点云张量，然后应用 3D 稀疏生成卷积神经网络 (CNN) 将其完成到可以快速进行体积渲染的显式辐射场在推理期间不运行网络。为了避免过度拟合，除了常见的渲染损失之外，我们还应用了感知损失以及通过点云上的随机旋转来增强视图。在我们的环境中，所提出的方法显着优于以前的隐式方法，表明所提出的问题和方法的巨大潜力。此 https 网址提供了代码和数据。
  - [具有动态学习神经隐式表示的多对象导航](https://arxiv.org/abs/2210.05129) | [code]
    > 理解和映射新环境是任何自主导航代理的核心能力。虽然经典机器人通常使用 SLAM 变体以独立的方式估计地图，这些变体保持拓扑或度量表示，但导航的端到端学习在神经网络中保留了某种形式的记忆。网络通常充满归纳偏差，其范围从矢量表示到鸟瞰度量张量或拓扑结构。在这项工作中，我们建议构建具有两个神经隐式表示的神经网络，它们在每一集期间动态学习并映射场景的内容：（i）语义查找器预测先前看到的查询对象的位置； (ii) Occupancy and Exploration Implicit Representation 封装了有关探索区域和障碍物的信息，并使用一种新颖的全局读取机制进行查询，该机制直接从函数空间映射到可用的嵌入空间。这两种表示都由经过强化学习 (RL) 训练的代理利用，并在每一集期间在线学习。我们评估了多对象导航上的代理，并展示了使用神经隐式表示作为记忆源的巨大影响。
  - [SiNeRF：用于联合姿势估计和场景重建的正弦神经辐射场, BMVC2022](https://arxiv.org/abs/2210.04553) | [***``[code]``***](https://github.com/yitongx/sinerf)
    > NeRFmm 是处理联合优化任务的神经辐射场 (NeRF)，即同时重建真实场景和注册相机参数。尽管 NeRFmm 产生了精确的场景合成和姿势估计，但它仍然难以在具有挑战性的场景中超越全注释基线。在这项工作中，我们发现联合优化中存在系统的次优性，并进一步确定了它的多个潜在来源。为了减少潜在源的影响，我们提出了利用正弦激活进行辐射映射的正弦神经辐射场 (SiNeRF) 和用于有效选择射线批次的新型混合区域采样 (MRS)。定量和定性的结果表明，与NeRFmm相比，SiNeRF在图像合成质量和姿态估计精度方面实现了全面的显着提升。此 https 网址提供了代码。
  - [NeRF2Real：使用神经辐射场的视觉引导双足运动技能的 Sim2real 转移](https://arxiv.org/abs/2210.04932) | [code]
    > 我们提出了一个系统，用于将 sim2real 方法应用于具有逼真视觉效果的“野外”场景，以及依赖于使用 RGB 相机的主动感知的策略。给定一个使用通用电话收集的静态场景的短视频，我们学习场景的接触几何和使用神经辐射场 (NeRF) 进行新视图合成的功能。我们通过叠加其他动态对象（例如机器人自己的身体、球）的渲染来增强静态场景的 NeRF 渲染。然后使用物理模拟器中的渲染引擎创建模拟，该模拟从静态场景几何（根据 NeRF 体积密度估计）和动态对象的几何和物理属性（假设已知）计算接触动力学。我们证明我们可以使用这个模拟来学习基于视觉的全身导航和推球策略，用于具有驱动头戴式 RGB 摄像头的 20 自由度类人机器人，并且我们成功地将这些策略转移到真实机器人。此 https 网址提供项目视频
## Oct2 - Oct8, 2022
  - [一种基于神经表面重建的鲁棒对象抓取的 Real2Sim2Real 方法](https://arxiv.org/abs/2210.02685) | [code]
    > 最近基于 3D 的操作方法要么使用 3D 神经网络直接预测抓取姿势，要么使用从形状数据库中检索到的类似对象来解决抓取姿势。然而，前者在使用新的机器人手臂或看不见的物体进行测试时面临着普遍性挑战；后者假设数据库中存在类似的对象。我们假设最近的 3D 建模方法为构建评估场景的数字副本提供了途径，该评估场景提供物理模拟并支持稳健的操作算法学习。我们建议使用最先进的神经表面重建方法（Real2Sim 步骤）从现实世界的点云中重建高质量的网格。由于大多数模拟器采用网格进行快速模拟，因此重建的网格无需人工即可生成抓取姿势标签。生成的标签可以训练在真实评估场景中表现稳健的抓取网络（Sim2Real 步骤）。在合成和真实实验中，我们表明 Real2Sim2Real 管道的性能优于使用大型数据集训练的基线抓取网络和基于检索的重建的抓取采样方法。 Real2Sim2Real 管道的好处来自 1) 将场景建模和抓取采样解耦为子问题，以及 2) 可以使用最新的 3D 学习算法和基于网格的物理模拟技术以足够高的质量解决这两个子问题。
  - [用于实时、开放集场景理解的特征真实神经融合](https://arxiv.org/abs/2210.03043) | [code]
    > 机器人的一般场景理解需要灵活的语义表示，以便可以识别、分割和分组训练时可能不知道的新物体和结构。我们提出了一种算法，该算法在实时 SLAM 期间将来自标准预训练网络的一般学习特征融合到高效的 3D 几何神经场表示中。融合的 3D 特征图继承了神经域几何表示的连贯性。这意味着在运行时交互的少量人类标签使对象甚至对象的一部分能够以开放集的方式稳健而准确地分割。
  - [IR-MCL：基于隐式表示的在线全球本地化](https://arxiv.org/abs/2210.03113) | [***``[code]``***](https://github.com/PRBonn/ir-mcl)
    > 确定移动机器人的状态是机器人导航系统的重要组成部分。在本文中，我们解决了使用 2D LiDAR 数据估计机器人在室内环境中的姿势的问题，并研究了现代环境模型如何改进黄金标准 Monte-Carlo 定位 (MCL) 系统。我们提出了一个神经占用场（NOF）来使用神经网络隐式表示场景。借助预训练网络，我们可以通过体绘制合成 2D LiDAR 扫描以获取任意机器人姿势。基于隐式表示，我们可以获得合成扫描与实际扫描之间的相似度作为观察模型，并将其集成到 MCL 系统中以执行准确的定位。我们在五个自记录数据集和三个公开可用数据集的序列上评估我们的方法。我们表明，我们可以使用我们的方法准确有效地定位机器人，超过最先进方法的定位性能。实验表明，所呈现的隐式表示能够预测更准确的 2D LiDAR 扫描，从而为我们的基于粒子滤波器的定位提供改进的观察模型。我们方法的代码发布在：this https URL。
  - [NARF22：用于配置感知渲染的神经铰接辐射场, IROS2022](https://progress.eecs.umich.edu/projects/narf/) | [code]
    > 铰接物体对机器人的感知和操作提出了独特的挑战。它们增加的自由度数量使得定位等任务在计算上变得困难，同时也使得现实世界数据集收集的过程无法扩展。为了解决这些可扩展性问题，我们提出了神经铰接辐射场 (NARF22)，这是一个使用完全可微分、配置参数化神经辐射场 (NeRF) 作为提供铰接对象高质量渲染的方法的管道。 NARF22 在推理时不需要明确了解对象结构。我们提出了一种两阶段的基于部件的训练机制，即使底层训练数据只有一个配置表示，它也允许对象渲染模型在配置空间中很好地泛化。我们通过在通过 Fetch 移动操作机器人收集的真实关节工具数据集上训练可配置渲染器来展示 NARF22 的功效。我们通过配置估计和 6 自由度姿态细化任务展示了该模型对基于梯度的推理方法的适用性。项目网页位于：此 https URL。
  - [密集单目 SLAM 的概率体积融合](https://arxiv.org/abs/2210.01276) | [code]
    > 我们提出了一种利用深度密集单目 SLAM 和快速不确定性传播从图像中重建 3D 场景的新方法。所提出的方法能够密集、准确、实时地对场景进行 3D 重建，同时对来自密集单目 SLAM 的极其嘈杂的深度估计具有鲁棒性。与以前的方法不同，要么使用 ad-hoc 深度滤波器，要么从 RGB-D 相机的传感器模型估计深度不确定性，我们的概率深度不确定性直接来自 SLAM 中底层束调整问题的信息矩阵。我们表明，由此产生的深度不确定性提供了一个很好的信号来加权深度图以进行体积融合。如果没有我们的深度不确定性，生成的网格会很嘈杂并带有伪影，而我们的方法会生成准确的 3D 网格，并且伪影要少得多。我们提供了具有挑战性的 Euroc 数据集的结果，并表明我们的方法比直接融合来自单目 SLAM 的深度的准确度提高了 92%，与最佳竞争方法相比提高了 90%。
  - [NeRF：3D 视觉中的神经辐射场，综合评论](https://arxiv.org/abs/2210.00379) | [code]
    > 神经辐射场 (NeRF) 是一种具有隐式场景表示的新型视图合成，已经席卷了计算机视觉领域。作为一种新颖的视图合成和 3D 重建方法，NeRF 模型在机器人技术、城市测绘、自主导航、虚拟现实/增强现实等领域都有应用。自 Mildenhall 等人的原始论文以来，已发表了 250 多份预印本，其中 100 多份最终被一级计算机​​视觉会议接受。鉴于 NeRF 的受欢迎程度和当前对该研究领域的兴趣，我们认为有必要对过去两年的 NeRF 论文进行全面调查，我们将其组织成基于架构和基于应用程序的分类法。我们还介绍了基于 NeRF 的新颖视图合成理论，以及关键 NeRF 模型的性能和速度的基准比较。通过创建这项调查，我们希望向 NeRF 介绍新的研究人员，为该领域有影响力的工作提供有益的参考，并通过我们的讨论部分激发未来的研究方向。
## Sep25 - Oct1, 2022
  - [具有三层采样和全景表示的城市级增量神经映射](https://arxiv.org/abs/2209.14072) | [code]
    > 神经隐式表示最近引起了机器人界的广泛关注，因为它们具有表现力、连续性和紧凑性。然而，基于稀疏 LiDAR 输入的城市规模增量隐式密集映射仍然是一个未充分探索的挑战。为此，我们成功构建了第一个具有全景表示的城市规模增量神经映射系统，该系统由环境级和实例级建模组成。给定一个稀疏的 LiDAR 点云流，它维护一个动态生成模型，将 3D 坐标映射到有符号距离场 (SDF) 值。为了解决在城市尺度空间中表示不同层次几何信息的困难，我们提出了一种定制的三层采样策略来动态采样全局、局部和近地表域。同时，为了实现高保真映射，引入了特定类别的先验以更好地对几何细节进行建模，从而实现全景表示。我们评估了公共 SemanticKITTI 数据集，并使用定量和定性结果证明了新提出的三层采样策略和全景表示的重要性。代码和数据将公开。
  - [Orbeez-SLAM：具有 ORB 特征和 NeRF 实现映射的实时单目视觉 SLAM](https://arxiv.org/abs/2209.13274) | [code]
    > 一种可以通过视觉信号执行复杂任务并与人类合作的空间人工智能备受期待。为了实现这一点，我们需要一个无需预训练即可轻松适应新场景并实时为下游任务生成密集地图的视觉 SLAM。由于其组件的内在限制，以前的基于学习和非基于学习的视觉 SLAM 都不能满足所有需求。在这项工作中，我们开发了一个名为 Orbeez-SLAM 的视觉 SLAM，它成功地与隐式神经表示 (NeRF) 和视觉里程计合作来实现我们的目标。此外，Orbeez-SLAM 可以与单目相机配合使用，因为它只需要 RGB 输入，使其广泛适用于现实世界。我们在各种具有挑战性的基准上验证了它的有效性。结果表明，我们的 SLAM 比强基线快 800 倍，并具有出色的渲染结果。
  - [通过控制屏障功能和神经辐射场增强基于视觉的控制器的安全性](https://arxiv.org/abs/2209.12266) | [code]
    > 为了在复杂的环境中导航，机器人必须越来越多地使用高维视觉反馈（例如图像）进行控制。然而，依靠高维图像数据做出控制决策会引发重要问题；特别是，我们如何证明视觉反馈控制器的安全性？控制障碍函数 (CBF) 是在状态反馈设置中验证反馈控制器安全性的强大工具，但由于需要预测未来的观察结果以评估障碍函数，CBF 传统上不太适合视觉反馈控制.在这项工作中，我们利用神经辐射场 (NeRFs) 的最新进展来解决这个问题，神经辐射场 (NeRFs) 学习 3D 场景的隐式表示并可以从以前看不见的相机视角渲染图像，为基于 CBF 的单步视觉预测提供控制器。这种新颖的组合能够过滤掉不安全的行为并进行干预以保护安全。我们在实时模拟实验中展示了我们的控制器的效果，它成功地防止了机器人采取危险行动。
## Sep18 - Sep24, 2022
  - [Local_INN：使用可逆神经网络的隐式地图表示和定位](https://arxiv.org/abs/2209.11925) | [code]
    > 机器人定位是使用地图和传感器测量找到机器人姿势的逆问题。近年来，可逆神经网络（INNs）成功地解决了各个领域的模糊逆问题。本文提出了一个用 INN 解决本地化问题的框架。我们设计了一个 INN，它在正向路径中提供隐式地图表示并在反向路径中提供定位。通过在评估中对潜在空间进行采样，Local\_INN 输出具有协方差的机器人位姿，可用于估计不确定性。我们表明 Local\_INN 的本地化性能与当前的方法相当，但延迟要低得多。我们使用训练集外部的姿势从 Local\_INN 显示详细的 2D 和 3D 地图重建。我们还提供了一个使用 Local\_INN 的全局定位算法来解决绑架问题。
  - [NeRF-Loc：神经辐射场内基于变换器的对象定位](https://arxiv.org/abs/2209.12068) | [code]
    > 神经辐射场 (NeRFs) 已成功用于场景表示。最近的工作还开发了使用基于 NeRF 的环境表示的机器人导航和操纵系统。由于对象定位是许多机器人应用的基础，为了进一步释放 NeRF 在机器人系统中的潜力，我们研究了 NeRF 场景中的对象定位。我们提出了一个基于转换器的框架 NeRF-Loc 来提取 NeRF 场景中对象的 3D 边界框。 NeRF-Loc 将预先训练的 NeRF 模型和相机视图作为输入，并生成标记的 3D 对象边界框作为输出。具体来说，我们设计了一对并行的转换器编码器分支，即粗流和细流，对目标对象的上下文和细节进行编码。然后将编码特征与注意力层融合在一起，以减轻模糊性，从而实现准确的对象定位。我们将我们的方法与传统的基于变压器的方法进行了比较，我们的方法取得了更好的性能。此外，我们还展示了第一个基于 NeRF 样本的对象定位基准 NeRFLocBench。
  - [感觉怎么样？ 用于越野车辆可穿越性的自我监督成本图学习](https://arxiv.org/abs/2209.10788) | [code]
    > 估计越野环境中的地形可穿越性需要推理机器人与这些地形之间的复杂交互动力学。然而，对于这些交互，构建准确的物理模型或创建信息标签以有监督的方式学习模型具有挑战性。我们提出了一种方法，该方法通过以自我监督的方式将外部感知环境信息与本体感知地形交互反馈相结合来学习预测可遍历性成本图。此外，我们提出了一种将机器人速度纳入成本图预测管道的新方法。我们在具有挑战性的越野地形的大型自主全地形车 (ATV) 上的多个短距离和大规模导航任务中验证了我们的方法，并证明了在单独的大型地面机器人上易于集成。我们的短尺度导航结果表明，使用我们学习的成本图可以使导航整体更顺畅，并为机器人提供对机器人与不同地形类型（如草地和砾石）之间相互作用的更细粒度的理解。我们的大规模导航试验表明，在 400 米到 3150 米的具有挑战性的越野路线中，与基于占用的导航基线相比，我们可以将干预次数减少多达 57%。
  - [Loc-NeRF：使用神经辐射场进行蒙特卡罗定位](https://arxiv.org/abs/2209.09050) | [***``[code]``***](https://github.com/MIT-SPARK/Loc-NeRF)
    > 我们提出了 Loc-NeRF，这是一种基于实时视觉的机器人定位方法，它结合了蒙特卡洛定位和神经辐射场 (NeRF)。我们的系统使用预训练的 NeRF 模型作为环境地图，并且可以使用 RGB 相机作为机器人上唯一的外部感受器实时定位自身。虽然神经辐射场已经在计算机视觉和图形中看到了视觉渲染的重要应用，但它们在机器人技术中的用途有限。现有的基于 NeRF 的定位方法需要良好的初始姿势猜测和大量计算，这使得它们对于实时机器人应用不切实际。通过使用 Monte Carlo 定位作为使用 NeRF 地图模型估计姿态的主力，Loc-NeRF 能够比现有技术更快地执行定位，并且不依赖于初始姿态估计。除了对合成数据进行测试外，我们还使用 Clearpath Jackal UGV 收集的真实数据运行我们的系统，并首次展示了使用神经辐射场执行实时全局定位的能力。我们通过此 https 网址公开我们的代码。
  - [MeSLAM：基于神经域的内存高效 SLAM, SMC2022](https://arxiv.org/abs/2209.09357) | [code]
    > 由于长期机器人操作中地图大小的增加，现有的同时定位和映射 (SLAM) 方法的可扩展性有限。此外，为定位和规划任务处理此类地图会导致车载所需的计算资源增加。为了解决长期操作中的内存消耗问题，我们开发了一种新颖的实时 SLAM 算法 MeSLAM，它基于神经场隐式地图表示。它将提议的全局映射策略（包括神经网络分布和区域跟踪）与外部里程计系统相结合。因此，该算法能够有效地训练代表不同地图区域的多个网络，并在大规模环境中准确地跟踪姿势。实验结果表明，所提出的方法的准确性与最先进的方法相当（在 TUM RGB-D 序列上平均为 6.6 cm），并且优于基线 iMAP*。此外，所提出的 SLAM 方法在最先进的 SLAM 方法中提供了最紧凑的地图，没有细节失真（1.9 MB 可存储 57 m3）。
  - [LATITUDE：在城市规模的 NeRF 中使用截断动态低通滤波器进行机器人全局定位, ICRA2023](https://arxiv.org/abs/2209.08498) | [***``[code]``***](https://github.com/jike5/LATITUDE)
    > 神经辐射场 (NeRFs) 在表示具有高分辨率细节和高效内存的复杂 3D 场景方面取得了巨大成功。然而，当前基于 NeRF 的姿态估计器没有初始姿态预测，并且在优化过程中容易出现局部最优。在本文中，我们提出了 LATITUDE：使用截断动态低通滤波器进行全局定位，它在城市规模的 NeRF 中引入了两阶段定位机制。在位置识别阶段，我们通过训练后的 NeRF 生成的图像训练回归器，为全局定位提供初始值。在姿态优化阶段，我们通过直接优化切平面上的姿态来最小化观察图像和渲染图像之间的残差。为了避免收敛到局部最优，我们引入了截断动态低通滤波器 (TDLF) 用于从粗到细的姿态配准。我们在合成数据和真实世界数据上评估我们的方法，并展示其在大规模城市场景中高精度导航的潜在应用。代码和数据将在此 https 网址上公开提供。
  - [使用神经辐射场进行主动机器人 3D 重建的不确定性引导策略, RAL2022](https://arxiv.org/abs/2209.08409) | [code]
    > 在本文中，我们解决了物体的主动机器人 3D 重建问题。特别是，我们研究了带有手持摄像头的移动机器人如何选择有利数量的视图来有效地恢复对象的 3D 形状。与该问题的现有解决方案相反，我们利用流行的基于神经辐射场的对象表示，最近在各种计算机视觉任务中显示出令人印象深刻的结果。然而，使用这种表示直接推断对象的显式 3D 几何细节并不简单，这使得密集 3D 重建的次佳视图选择问题具有挑战性。本文介绍了一种基于光线的体积不确定性估计器，它计算颜色样本沿物体隐式神经表示的每条光线的权重分布的熵。我们表明，使用所提出的估计器给出一个新颖的视图，可以推断出底层 3D 几何的不确定性。然后，我们提出了一个下一个最佳视图选择策略，该策略由基于神经辐射场的表示中基于射线的体积不确定性指导。令人鼓舞的合成数据和真实世界数据的实验结果表明，本文提出的方法可以启用一个新的研究方向，即使用隐式 3D 对象表示来解决机器人视觉应用中的下一个最佳视图问题，将我们的方法与现有的方法区分开来依赖于显式 3D 几何建模的方法。
## Sep11 - Sep17, 2022
  - [iDF-SLAM：具有神经隐式映射和深度特征跟踪的端到端 RGB-D SLAM](https://arxiv.org/abs/2209.07919) | [code]
    > 我们提出了一种新颖的端到端 RGB-D SLAM iDF-SLAM，它采用基于特征的深度神经跟踪器作为前端，采用 NeRF 风格的神经隐式映射器作为后端。神经隐式映射器是即时训练的，虽然神经跟踪器是在 ScanNet 数据集上进行预训练的，但它也会随着神经隐式映射器的训练进行微调。在这样的设计下，我们的 iDF-SLAM 能够学习使用特定场景的特征进行相机跟踪，从而实现 SLAM 系统的终身学习。跟踪器和映射器的训练都是自我监督的，没有引入地面真实姿势。我们在 Replica 和 ScanNet 数据集上测试了 iDF-SLAM 的性能，并将结果与​​最近的两个基于 NeRF 的神经 SLAM 系统进行了比较。所提出的 iDF-SLAM 在场景重建和相机跟踪的竞争性能方面展示了最先进的结果。
## Sep4 - Sep10, 2022
  - [PixTrack：使用 NeRF 模板和特征度量对齐的精确 6DoF 对象姿势跟踪](https://arxiv.org/abs/2209.03910) | [code]
    > 我们提出了 PixTrack，这是一个基于视觉的对象姿态跟踪框架，使用新颖的视图合成和深度特征度量对齐。我们的评估表明，我们的方法可以对 RGB 图像中的对象进行高度准确、稳健且无抖动的 6DoF 姿态估计，而无需任何数据注释或轨迹平滑。我们的方法在计算上也很高效，可以轻松进行多对象跟踪，而无需更改我们的方法，并且只使用 CPU 多处理。
## Aug28 - Sep3, 2022
## Aug21 - Aug27, 2022
  - [SCONE：通过体积积分优化未知环境中的表面覆盖率](https://arxiv.org/abs/2208.10449) | [code]
    > 下一个最佳视图计算 (NBV) 是机器人技术中长期存在的问题，包括识别下一个信息量最大的传感器位置，以有效且准确地重建 3D 对象或场景。像大多数当前方法一样，我们考虑来自深度传感器的 NBV 预测。依赖于场景体积表示的基于学习的方法适用于路径规划，但不能很好地适应场景的大小，并且精度低于使用基于表面的表示的方法。然而，后者将相机限制在少数姿势。为了获得这两种表示的优点，我们表明我们可以通过蒙特卡罗积分在体积表示上最大化表面度量。我们的方法可扩展到大型场景并处理自由相机运动：它将由深度传感器（如激光雷达系统）收集的任意大点云以及相机姿势作为输入来预测 NBV。我们在由大型复杂 3D 场景组成的新数据集上展示了我们的方法。
## Aug14 - Aug20, 2022
  - [8 点算法作为 ViTs 相对姿势预测的归纳偏差, 3DV2022](https://arxiv.org/abs/2208.08988) | [***``[code]``***](https://github.com/crockwell/rel_pose)
    > 我们提出了一个简单的基线，用于直接估计两个图像之间的相对姿势（旋转和平移，包括比例）。深度方法最近显示出强劲的进展，但通常需要复杂或多阶段的架构。我们展示了一些修改可以应用于视觉转换器 (ViT)，以使其计算接近八点算法。这种归纳偏差使一种简单的方法在多种环境中具有竞争力，通常在有限的数据机制中显着提高现有技术水平，并具有强大的性能提升。
## Aug7 - Aug13, 2022
  - [RelPose：预测野外单个物体的概率相对旋转, ECCV2022](https://jasonyzhang.com/relpose/) | [***``[code]``***](https://github.com/jasonyzhang/relpose)
    > 我们描述了一种数据驱动的方法，用于在给定任意对象的多个图像的情况下推断相机视点。该任务是经典几何流水线（如 SfM 和 SLAM）的核心组成部分，也是当代神经方法（例如 NeRF）对对象重建和视图合成的重要预处理要求。与现有的在稀疏视图中表现不佳的对应驱动方法相比，我们提出了一种基于自上而下预测的方法来估计相机视点。我们的关键技术见解是使用基于能量的公式来表示相对相机旋转的分布，从而使我们能够明确表示由对象对称性或视图产生的多个相机模式。利用这些相对预测，我们从多张图像中共同估计一组一致的相机旋转。我们表明，在给定可见和不可见类别的稀疏图像的情况下，我们的方法优于最先进的 SfM 和 SLAM 方法。此外，我们的概率方法明显优于直接回归相对姿势，这表明建模多模态对于连贯的关节重建很重要。我们证明我们的系统可以成为从多视图数据集进行野外重建的垫脚石。包含代码和视频的项目页面可以在这个 https URL 找到。
## Jul31 - Aug6, 2022
  - [PRIF: Primary Ray-based Implicit Function](https://research.google/pubs/pub51556/) | [code]
    > 我们引入了一种新的隐式形状表示，称为基于初级光线的隐式函数 (PRIF)。与大多数基于符号距离函数 (SDF) 处理空间位置的现有方法相比，我们的表示在定向射线上运行。具体来说，PRIF 被制定为直接生成给定输入射线的表面命中点，而无需昂贵的球体跟踪操作，从而实现高效的形状提取和可微渲染。我们证明了经过训练以编码 PRIF 的神经网络在各种任务中取得了成功，包括单一形状表示、类别形状生成、稀疏或嘈杂观察的形状补全、相机姿态估计的逆渲染以及颜色的神经渲染。
## Jul24 - Jul30, 2022
  - [ObjectFusion：具有神经对象先验的准确对象级 SLAM, Graphical Models, Volume 123, September 2022](https://www.sciencedirect.com/science/article/pii/S1524070322000418) | [code]
    > 以前的对象级同步定位和映射 (SLAM) 方法仍然无法以有效的方式创建高质量的面向对象的 3D 地图。主要挑战来自如何有效地表示对象形状以及如何将这种对象表示有效地应用于准确的在线相机跟踪。在本文中，我们提供 ObjectFusion 作为静态场景中的一种新颖的对象级 SLAM，它通过利用神经对象先验，有效地创建具有高质量对象重建的面向对象的 3D 地图。我们提出了一种仅具有单个编码器-解码器网络的神经对象表示，以有效地表达各种类别的对象形状，这有利于对象实例的高质量重建。更重要的是，我们建议将这种神经对象表示转换为精确测量，以共同优化对象形状、对象姿态和相机姿态，以实现最终准确的 3D 对象重建。通过对合成和真实世界 RGB-D 数据集的广泛评估，我们表明我们的 ObjectFusion 优于以前的方法，具有更好的对象重建质量，使用更少的内存占用，并且以更有效的方式，尤其是在对象级别。
  - [神经密度-距离场, ECCV2022](https://arxiv.org/abs/2207.14455) | [***``[code]``***](https://ueda0319.github.io/neddf/)
    > 神经领域在 3D 视觉任务中的成功现在是无可争辩的。遵循这一趋势，已经提出了几种针对视觉定位的方法（例如，SLAM）来使用神经场估计距离或密度场。然而，仅通过基于密度场的方法（例如神经辐射场 (NeRF)）很难实现高定位性能，因为它们在大多数空白区域中不提供密度梯度。另一方面，基于距离场的方法，例如神经隐式表面 (NeuS)，在对象的表面形状方面存在局限性。本文提出了神经密度-距离场 (NeDDF)，这是一种新的 3D 表示，它相互约束距离和密度场。我们将距离场公式扩展到没有明确边界表面的形状，例如毛皮或烟雾，这使得从距离场到密度场的显式转换成为可能。通过显式转换实现的一致距离和密度场既能保证初始值的鲁棒性，又能实现高质量的配准。此外，场之间的一致性允许从稀疏点云快速收敛。实验表明，NeDDF 可以实现高定位性能，同时在新颖的视图合成上提供与 NeRF 相当的结果。该代码可在此 https URL 获得。
  - [ShAPO：多对象形状、外观和姿势优化的隐式表示, ECCV2022](https://arxiv.org/abs/2207.13691) | [***``[code]``***](https://zubair-irshad.github.io/projects/ShAPO.html)
    > 我们的方法从单个 RGB-D 观察中研究以对象为中心的 3D 理解的复杂任务。由于这是一个不适定问题，现有方法在具有遮挡的复杂多对象场景中的 3D 形状和 6D 姿势和尺寸估计性能低下。我们提出了 ShaAPO，一种用于联合多对象检测、3D 纹理重建、6D 对象姿态和大小估计的方法。 ShAPO 的关键是一个单次管道，用于回归形状、外观和姿势潜在代码以及每个对象实例的掩码，然后以稀疏到密集的方式进一步细化。首先学习了一种新的解开的先验形状和外观数据库，以将对象嵌入到它们各自的形状和外观空间中。我们还提出了一种新颖的、基于八叉树的可微优化步骤，使我们能够以综合分析的方式在学习的潜在空间下同时进一步改进对象形状、姿势和外观。我们新颖的联合隐式纹理对象表示使我们能够准确地识别和重建新的看不见的对象，而无需访问它们的 3D 网格。通过广泛的实验，我们证明了我们的方法在模拟室内场景上进行训练，能够以最少的微调准确地回归现实世界中新物体的形状、外观和姿势。我们的方法显着优于 NOCS 数据集上的所有基线，6D 姿态估计的 mAP 绝对提高了 8%。
  - [GAUDI：沉浸式 3D 场景生成的神经架构师](https://arxiv.org/abs/2207.13751) | [***``[code]``***](https://github.com/apple/ml-gaudi)
    > 我们介绍了 GAUDI，这是一种生成模型，能够捕捉复杂而逼真的 3D 场景的分布，可以从移动的相机中沉浸式地渲染。我们用一种可扩展但功能强大的方法来解决这个具有挑战性的问题，我们首先优化一个潜在的表示，以解开辐射场和相机姿势。然后使用这种潜在表示来学习生成模型，该模型可以无条件和有条件地生成 3D 场景.我们的模型通过消除相机姿态分布可以跨样本共享的假设来概括以前专注于单个对象的工作。我们展示了 GAUDI 在跨多个数据集的无条件生成设置中获得了最先进的性能，并允许在给定条件变量（如稀疏图像观察或描述场景的文本）的情况下有条件地生成 3D 场景。
  - [AlignSDF：用于手对象重建的姿势对齐有符号距离场, ECCV2022](https://arxiv.org/abs/2207.12909) | [***``[code]``***](https://zerchen.github.io/projects/alignsdf.html)
    > 最近的工作在从单目彩色图像联合重建手和操纵对象方面取得了令人瞩目的进展。现有方法侧重于参数网格或符号距离场 (SDF) 方面的两种替代表示。一方面，参数模型可以从先验知识中受益，但代价是有限的形状变形和网格分辨率。因此，网格模型可能无法精确重建细节，例如手和物体的接触面。另一方面，基于 SDF 的方法可以表示任意细节，但缺乏明确的先验。在这项工作中，我们的目标是使用参数表示提供的先验改进 SDF 模型。特别是，我们提出了一个联合学习框架，可以解开姿势和形状。我们从参数模型中获取手和物体的姿势，并使用它们在 3D 空间中对齐 SDF。我们表明，这种对齐的 SDF 更好地专注于重建形状细节并提高手和物体的重建精度。我们评估了我们的方法，并在具有挑战性的 ObMan 和 DexYCB 基准上展示了对现有技术的显着改进。
## Previous weeks
  - [野外的 NeRF：无约束照片集的神经辐射场, CVPR2021](https://arxiv.org/abs/2008.02268) | [code]
    > 我们提出了一种基于学习的方法，用于仅使用野外照片的非结构化集合来合成复杂场景的新视图。我们建立在神经辐射场 (NeRF) 的基础上，它使用多层感知器的权重将场景的密度和颜色建模为 3D 坐标的函数。虽然 NeRF 在受控设置下捕获的静态对象的图像上效果很好，但它无法在不受控的图像中模拟许多普遍存在的真实世界现象，例如可变照明或瞬态遮挡物。我们为 NeRF 引入了一系列扩展来解决这些问题，从而能够从互联网上获取的非结构化图像集合中进行准确的重建。我们将我们的系统（称为 NeRF-W）应用于著名地标的互联网照片集，并展示时间一致的新颖视图渲染，这些渲染比现有技术更接近真实感。
  - [Ha-NeRF：野外的幻觉神经辐射场, CVPR2022](https://rover-xingyu.github.io/Ha-NeRF/) | [***``[code]``***](https://github.com/rover-xingyu/Ha-NeRF)
    > 神经辐射场 (NeRF) 最近因其令人印象深刻的新颖视图合成能力而广受欢迎。本文研究了幻觉 NeRF 的问题：即在一天中的不同时间从一组旅游图像中恢复一个真实的 NeRF。现有的解决方案采用具有可控外观嵌入的 NeRF 在各种条件下渲染新颖的视图，但它们无法渲染具有看不见的外观的视图一致图像。为了解决这个问题，我们提出了一个用于构建幻觉 NeRF 的端到端框架，称为 Ha-NeRF。具体来说，我们提出了一个外观幻觉模块来处理随时间变化的外观并将它们转移到新的视图中。考虑到旅游图像的复杂遮挡，我们引入了一个反遮挡模块来准确地分解静态主体以获得可见性。合成数据和真实旅游照片集的实验结果表明，我们的方法可以产生幻觉，并从不同的视图呈现无遮挡的图像。
  - [Nerfies：可变形的神经辐射场, ICCV2021](https://arxiv.org/abs/2011.12948) | [code]
    > 我们提出了第一种能够使用从手机随便捕获的照片/视频来逼真地重建可变形场景的方法。我们的方法通过优化一个额外的连续体积变形场来增强神经辐射场 (NeRF)，该场将每个观察点扭曲成一个规范的 5D NeRF。我们观察到这些类似 NeRF 的变形场容易出现局部最小值，并为基于坐标的模型提出了一种从粗到细的优化方法，可以实现更稳健的优化。通过将几何处理和物理模拟的原理应用于类似 NeRF 的模型，我们提出了变形场的弹性正则化，进一步提高了鲁棒性。我们表明，我们的方法可以将随意捕获的自拍照片/视频转换为可变形的 NeRF 模型，允许从任意视角对主体进行逼真的渲染，我们称之为“nerfies”。我们通过使用带有两部手机的装备收集时间同步数据来评估我们的方法，从而在不同视点产生相同姿势的训练/验证图像。我们表明，我们的方法忠实地重建了非刚性变形的场景，并以高保真度再现了看不见的视图。
  - [用于单目 4D 面部头像重建的动态神经辐射场, CVPR2021](https://gafniguy.github.io/4D-Facial-Avatars/) | [***``[code]``***](https://github.com/gafniguy/4D-Facial-Avatars)
    > 我们提出了用于模拟人脸外观和动态的动态神经辐射场。对说话的人进行数字建模和重建是各种应用程序的关键组成部分。特别是对于 AR 或 VR 中的远程呈现应用，需要忠实再现外观，包括新颖的视点或头部姿势。与显式建模几何和材料属性或纯粹基于图像的最先进方法相比，我们引入了基于场景表示网络的头部隐式表示。为了处理面部的动态，我们将场景表示网络与低维可变形模型相结合，该模型提供对姿势和表情的显式控制。我们使用体积渲染从这种混合表示中生成图像，并证明这种动态神经场景表示只能从单目输入数据中学习，而不需要专门的捕获设置。在我们的实验中，我们表明这种学习的体积表示允许生成照片般逼真的图像，其质量超过了基于视频的最先进的重演方法的质量。
  - [神经关节辐射场, ICCV2021](https://arxiv.org/abs/2104.03110) | [***``[code]``***](https://github.com/nogu-atsu/NARF#code)
    > 我们提出了神经关节辐射场 (NARF)，这是一种新颖的可变形 3D 表示，用于从图像中学习到的关节对象。虽然 3D 隐式表示的最新进展使得学习复杂对象的模型成为可能，但学习关节对象的姿势可控表示仍然是一个挑战，因为当前的方法需要 3D 形状监督并且无法呈现外观。在制定 3D 关节对象的隐式表示时，我们的方法在求解每个 3D 位置的辐射场时仅考虑最相关对象部分的刚性变换。通过这种方式，所提出的方法可以表示与姿势相关的变化，而不会显着增加计算复杂度。 NARF 是完全可微的，可以从带有姿势注释的图像中训练出来。此外，通过使用自动编码器，它可以学习对象类的多个实例的外观变化。实验表明，所提出的方法是有效的，并且可以很好地推广到新的姿势。
  - [神经演员：具有姿势控制的人类演员的神经自由视图合成, SIGSIGGRAPH Asia 2021](https://vcai.mpi-inf.mpg.de/projects/NeuralActor/) | [***``[code]``***](https://people.mpi-inf.mpg.de/~lliu/projects/NeuralActor/)
    > 我们提出了神经演员 (NA)，这是一种从任意视角和任意可控姿势下高质量合成人类的新方法。我们的方法建立在最近的神经场景表示和渲染工作之上，这些工作仅从 2D 图像中学习几何和外观的表示。虽然现有作品展示了令人信服的静态场景渲染和动态场景回放，但使用神经隐式方法对人类进行逼真的重建和渲染，特别是在用户控制的新姿势下，仍然很困难。为了解决这个问题，我们利用粗体模型作为代理将周围的 3D 空间展开为规范姿势。神经辐射场从多视图视频输入中学习规范空间中与姿势相关的几何变形以及与姿势和视图相关的外观效果。为了合成高保真动态几何和外观的新视图，我们利用在身体模型上定义的 2D 纹理图作为潜在变量来预测残余变形和动态外观。实验表明，我们的方法在回放和新颖的姿势合成方面取得了比现有技术更好的质量，甚至可以很好地推广到与训练姿势截然不同的新姿势。此外，我们的方法还支持合成结果的体形控制。
  - [iNeRF：用于姿势估计的反转神经辐射场, IROS2021](http://yenchenlin.me/inerf/) | [***``[code]``***](https://github.com/yenchenlin/iNeRF-public)
    > 我们提出了 iNeRF，这是一个通过“反转”经过训练的神经辐射场 (NeRF) 来执行姿态估计的框架。 NeRF 已被证明对视图合成任务非常有效——合成真实世界场景或对象的逼真的新视图。在这项工作中，我们研究是否可以使用 NeRF 进行综合分析来进行 6DoF 姿势估计——给定图像，找到相机相对于 3D 模型的平移和旋转。从初始姿态估计开始，我们使用梯度下降来最小化从已经训练的 NeRF 渲染的像素和观察图像中的像素之间的残差。在我们的实验中，我们首先研究 1）如何在 iNeRF 的姿势细化过程中对光线进行采样以收集信息梯度，以及 2）不同批次大小的光线如何影响合成数据集上的 iNeRF。然后，我们展示了对于来自 LLFF 数据集的复杂现实世界场景，iNeRF 可以通过估计新图像的相机位姿并将这些图像用作 NeRF 的额外训练数据来改进 NeRF。最后，我们展示了 iNeRF 可以与基于特征的姿势初始化相结合。该方法优于所有其他依赖 LineMOD 上的合成数据的基于 RGB 的方法。
  - [A-NeRF：通过神经渲染进行无表面人体 3D 姿势细化, NeurIPS2021](https://arxiv.org/abs/2102.06199) | [***``[code]``***](https://github.com/LemonATsu/A-NeRF)
    > 虽然深度学习使用前馈网络重塑了经典的运动捕捉管道，但需要生成模型通过迭代细化来恢复精细对齐。不幸的是，现有模型通常是在受控条件下手工制作或学习的，仅适用于有限的领域。我们提出了一种通过扩展神经辐射场 (NeRFs) 从未标记的单目视频中学习生成神经体模型的方法。我们为它们配备了骨架，以适用于时变和关节运动。一个关键的见解是，隐式模型需要与显式曲面模型中使用的正向运动学相反。我们的重新参数化定义了相对于身体部位姿势的空间潜在变量，从而克服了过度参数化的不适定逆运算。这使得从头开始学习体积身体形状和外观，同时共同改进关节姿势；输入视频上的所有外观、姿势或 3D 形状都没有地面实况标签。当用于新视图合成和动作捕捉时，我们的神经模型提高了不同数据集的准确性。项目网站：此 https 网址。
  - [NeRF--：没有已知相机参数的神经辐射场](https://nerfmm.active.vision/) | [***``[code]``***](https://github.com/ActiveVisionLab/nerfmm)
    > 考虑到仅来自一组 2D 图像的新视图合成 (NVS) 问题，我们通过消除已知或预先计算的相机参数的要求，简化了前向场景中神经辐射场 (NeRF) 的训练过程，包括内在函数和 6DoF 姿势。为此，我们提出了 NeRF−−，具有三个贡献：首先，我们表明相机参数可以通过光度重建作为可学习参数与 NeRF 训练联合优化；其次，为了对相机参数估计和新颖视图渲染的质量进行基准测试，我们引入了一个新的路径跟踪合成场景数据集，称为 Blender Forward-Facing Dataset (BLEFF)；第三，我们进行了广泛的分析以了解各种相机运动下的训练行为，并表明在大多数情况下，联合优化管道可以恢复准确的相机参数并实现与使用 COLMAP 预计算相机参数训练的方法相当的新视图合成质量。
  - [实时隐式映射和定位, ICCV2021](https://arxiv.org/abs/2103.12352) | [code]
    > 我们首次展示了多层感知器 (MLP) 可以作为手持 RGB-D 相机的实时 SLAM 系统中唯一的场景表示。我们的网络在没有先验数据的情况下进行实时操作训练，构建了一个密集的、特定于场景的隐式 3D 占用率和颜色模型，该模型也可立即用于跟踪。
  - [用于 SLAM 的 NICE-SLAM 神经隐​​式可扩展编码, CVPR2022](https://arxiv.org/abs/2112.12130) | [***``[code]``***](https://github.com/cvg/nice-slam)
    > 神经隐式表示最近在各个领域都显示出令人鼓舞的结果，包括在同时定位和映射 (SLAM) 方面取得的可喜进展。然而，现有方法会产生过度平滑的场景重建，并且难以扩展到大场景。这些限制主要是由于它们简单的全连接网络架构没有在观察中包含本地信息。在本文中，我们提出了 NICE-SLAM，这是一种密集的 SLAM 系统，它通过引入分层场景表示来结合多级局部信息。使用预先训练的几何先验优化这种表示可以在大型室内场景中进行详细的重建。与最近的神经隐式 SLAM 系统相比，我们的方法更具可扩展性、高效性和鲁棒性。在五个具有挑战性的数据集上的实验证明了 NICE-SLAM 在映射和跟踪质量方面的竞争结果。
  - [GNeRF：基于 GAN 的无姿势相机的神经辐射场, ICCV2021(oral)](https://arxiv.org/abs/2103.15606) | [code]
    > 我们介绍了 GNeRF，这是一个将生成对抗网络 (GAN) 与神经辐射场 (NeRF) 重建相结合的框架，用于具有未知甚至随机初始化相机姿势的复杂场景。最近基于 NeRF 的进展因显着的逼真的新视图合成而受到欢迎。然而，它们中的大多数严重依赖于准确的相机位姿估计，而最近的一些方法只能在相机轨迹相对较短的大致前向场景中优化未知相机位姿，并且需要粗略的相机位姿初始化。不同的是，我们的 GNeRF 仅将随机初始化的姿势用于复杂的由外而内的场景。我们提出了一种新颖的两阶段端到端框架。第一阶段将 GAN 的使用带入新领域，以联合优化粗略的相机姿势和辐射场，而第二阶段通过额外的光度损失对它们进行细化。我们使用混合迭代优化方案克服了局部最小值。对各种合成和自然场景的广泛实验证明了 GNeRF 的有效性。更令人印象深刻的是，我们的方法在那些以前被认为极具挑战性的重复模式甚至低纹理的场景中优于基线。
  - [BARF：捆绑调整神经辐射场, ICCV2021(oral)](https://chenhsuanlin.bitbucket.io/bundle-adjusting-NeRF/) | [***``[code]``***](https://github.com/chenhsuanlin/bundle-adjusting-NeRF)
    > 神经辐射场 (NeRF) 最近在计算机视觉界引起了极大的兴趣，因为它具有合成真实世界场景的逼真的新颖视图的能力。然而，NeRF 的一个限制是它需要准确的相机姿势来学习场景表示。在本文中，我们提出了 Bundle-Adjusting Neural Radiance Fields (BARF)，用于从不完美（甚至未知）的相机姿势训练 NeRF——学习神经 3D 表示和注册相机帧的联合问题。我们建立了与经典图像对齐的理论联系，并表明从粗到细的配准也适用于 NeRF。此外，我们表明，在 NeRF 中天真地应用位置编码会对基于合成的目标的注册产生负面影响。合成数据和真实世界数据的实验表明，BARF 可以有效地优化神经场景表示并同时解决大的相机位姿错位问题。这使得来自未知相机位姿的视频序列的视图合成和定位成为可能，为视觉定位系统（例如 SLAM）和密集 3D 映射和重建的潜在应用开辟了新途径。
  - [自校准神经辐射场, ICCV2021](https://postech-cvlab.github.io/SCNeRF/) | [***``[code]``***](https://github.com/POSTECH-CVLab/SCNeRF)
    > 在这项工作中，我们提出了一种用于具有任意非线性失真的通用相机的相机自校准算法。我们共同学习场景的几何形状和准确的相机参数，无需任何校准对象。我们的相机模型包括针孔模型、径向失真和可以学习任意非线性相机失真的通用噪声模型。虽然传统的自校准算法主要依赖于几何约束，但我们还结合了光度一致性。这需要学习场景的几何形状，我们使用神经辐射场 (NeRF)。我们还提出了一种新的几何损失函数，即投影射线距离损失，以结合复杂非线性相机模型的几何一致性。我们在标准真实图像数据集上验证了我们的方法，并证明我们的模型可以从头开始学习相机的内在和外在（姿势），而无需 COLMAP 初始化。此外，我们表明，以可微分的方式学习准确的相机模型可以让我们在 NeRF 上提高 PSNR。我们通过实验证明我们提出的方法适用于 NeRF 的变体。此外，我们使用一组用鱼眼镜头拍摄的图像来证明学习相机模型与 COLMAP 初始化相比，共同提高了性能。
  - [动态场景的神经场景图, CVPR2021(oral)](https://arxiv.org/abs/2011.10379) | [***``[code]``***](https://github.com/princeton-computational-imaging/neural-scene-graphs)
    > 最近的隐式神经渲染方法表明，可以通过仅由一组 RGB 图像监督的预测其体积密度和颜色来学习复杂场景的准确视图合成。然而，现有方法仅限于学习将所有场景对象编码为单个神经网络的静态场景的有效表示，并且缺乏将动态场景表示和分解为单个场景对象的能力。在这项工作中，我们提出了第一个将动态场景分解为场景图的神经渲染方法。我们提出了一种学习的场景图表示，它对对象变换和辐射进行编码，以有效地渲染场景的新颖排列和视图。为此，我们学习隐式编码的场景，并结合联合学习的潜在表示来描述具有单个隐式函数的对象。我们在合成和真实汽车数据上评估所提出的方法，验证我们的方法学习动态场景 - 仅通过观察该场景的视频 - 并允许渲染具有看不见的对象集的新颖场景组合的新颖照片般逼真的视图看不见的姿势。
