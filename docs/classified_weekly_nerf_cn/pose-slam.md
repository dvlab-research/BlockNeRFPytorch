
每周分类神经辐射场 - pose-slam ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
======================================================================================================================================
## 按类别筛选: [全部](../weekly_nerf_cn.md) | [动态](./dynamic.md) | [编辑](./editing.md) | [快速](./fast.md) | [泛化](./generalization.md) 
## [光照](./lighting.md) | [重建](./reconstruction.md) | [纹理](./texture.md) | [语义](./semantic.md) | [姿态-SLAM](./pose-slam.md) | [其他](./others.md) 
## 大部分为机器翻译，少数论文手动翻译，有翻译错误可以PR修复。
## Jul31 - Aug6, 2022
  - [PRIF: Primary Ray-based Implicit Function](https://research.google/pubs/pub51556/) | [code]
    > 我们引入了一种新的隐式形状表示，称为基于初级光线的隐式函数 (PRIF)。与大多数基于符号距离函数 (SDF) 处理空间位置的现有方法相比，我们的表示在定向射线上运行。具体来说，PRIF 被制定为直接生成给定输入射线的表面命中点，而无需昂贵的球体跟踪操作，从而实现高效的形状提取和可微渲染。我们证明了经过训练以编码 PRIF 的神经网络在各种任务中取得了成功，包括单一形状表示、类别形状生成、稀疏或嘈杂观察的形状补全、相机姿态估计的逆渲染以及颜色的神经渲染。
## Jul24 - Jul30, 2022
  - [ObjectFusion：具有神经对象先验的准确对象级 SLAM, Graphical Models, Volume 123, September 2022](https://www.sciencedirect.com/science/article/pii/S1524070322000418) | [code]
    > 以前的对象级同步定位和映射 (SLAM) 方法仍然无法以有效的方式创建高质量的面向对象的 3D 地图。主要挑战来自如何有效地表示对象形状以及如何将这种对象表示有效地应用于准确的在线相机跟踪。在本文中，我们提供 ObjectFusion 作为静态场景中的一种新颖的对象级 SLAM，它通过利用神经对象先验，有效地创建具有高质量对象重建的面向对象的 3D 地图。我们提出了一种仅具有单个编码器-解码器网络的神经对象表示，以有效地表达各种类别的对象形状，这有利于对象实例的高质量重建。更重要的是，我们建议将这种神经对象表示转换为精确测量，以共同优化对象形状、对象姿态和相机姿态，以实现最终准确的 3D 对象重建。通过对合成和真实世界 RGB-D 数据集的广泛评估，我们表明我们的 ObjectFusion 优于以前的方法，具有更好的对象重建质量，使用更少的内存占用，并且以更有效的方式，尤其是在对象级别。
  - [神经密度-距离场, ECCV2022](https://arxiv.org/abs/2207.14455) | [***``[code]``***](https://ueda0319.github.io/neddf/)
    > 神经领域在 3D 视觉任务中的成功现在是无可争辩的。遵循这一趋势，已经提出了几种针对视觉定位的方法（例如，SLAM）来使用神经场估计距离或密度场。然而，仅通过基于密度场的方法（例如神经辐射场 (NeRF)）很难实现高定位性能，因为它们在大多数空白区域中不提供密度梯度。另一方面，基于距离场的方法，例如神经隐式表面 (NeuS)，在对象的表面形状方面存在局限性。本文提出了神经密度-距离场 (NeDDF)，这是一种新的 3D 表示，它相互约束距离和密度场。我们将距离场公式扩展到没有明确边界表面的形状，例如毛皮或烟雾，这使得从距离场到密度场的显式转换成为可能。通过显式转换实现的一致距离和密度场既能保证初始值的鲁棒性，又能实现高质量的配准。此外，场之间的一致性允许从稀疏点云快速收敛。实验表明，NeDDF 可以实现高定位性能，同时在新颖的视图合成上提供与 NeRF 相当的结果。该代码可在此 https URL 获得。
  - [ShAPO：多对象形状、外观和姿势优化的隐式表示, ECCV2022](https://arxiv.org/abs/2207.13691) | [***``[code]``***](https://zubair-irshad.github.io/projects/ShAPO.html)
    > 我们的方法从单个 RGB-D 观察中研究以对象为中心的 3D 理解的复杂任务。由于这是一个不适定问题，现有方法在具有遮挡的复杂多对象场景中的 3D 形状和 6D 姿势和尺寸估计性能低下。我们提出了 ShaAPO，一种用于联合多对象检测、3D 纹理重建、6D 对象姿态和大小估计的方法。 ShAPO 的关键是一个单次管道，用于回归形状、外观和姿势潜在代码以及每个对象实例的掩码，然后以稀疏到密集的方式进一步细化。首先学习了一种新的解开的先验形状和外观数据库，以将对象嵌入到它们各自的形状和外观空间中。我们还提出了一种新颖的、基于八叉树的可微优化步骤，使我们能够以综合分析的方式在学习的潜在空间下同时进一步改进对象形状、姿势和外观。我们新颖的联合隐式纹理对象表示使我们能够准确地识别和重建新的看不见的对象，而无需访问它们的 3D 网格。通过广泛的实验，我们证明了我们的方法在模拟室内场景上进行训练，能够以最少的微调准确地回归现实世界中新物体的形状、外观和姿势。我们的方法显着优于 NOCS 数据集上的所有基线，6D 姿态估计的 mAP 绝对提高了 8%。
  - [GAUDI：沉浸式 3D 场景生成的神经架构师](https://arxiv.org/abs/2207.13751) | [***``[code]``***](https://github.com/apple/ml-gaudi)
    > 我们介绍了 GAUDI，这是一种生成模型，能够捕捉复杂而逼真的 3D 场景的分布，可以从移动的相机中沉浸式地渲染。我们用一种可扩展但功能强大的方法来解决这个具有挑战性的问题，我们首先优化一个潜在的表示，以解开辐射场和相机姿势。然后使用这种潜在表示来学习生成模型，该模型可以无条件和有条件地生成 3D 场景.我们的模型通过消除相机姿态分布可以跨样本共享的假设来概括以前专注于单个对象的工作。我们展示了 GAUDI 在跨多个数据集的无条件生成设置中获得了最先进的性能，并允许在给定条件变量（如稀疏图像观察或描述场景的文本）的情况下有条件地生成 3D 场景。
  - [AlignSDF：用于手对象重建的姿势对齐有符号距离场, ECCV2022](https://arxiv.org/abs/2207.12909) | [***``[code]``***](https://zerchen.github.io/projects/alignsdf.html)
    > 最近的工作在从单目彩色图像联合重建手和操纵对象方面取得了令人瞩目的进展。现有方法侧重于参数网格或符号距离场 (SDF) 方面的两种替代表示。一方面，参数模型可以从先验知识中受益，但代价是有限的形状变形和网格分辨率。因此，网格模型可能无法精确重建细节，例如手和物体的接触面。另一方面，基于 SDF 的方法可以表示任意细节，但缺乏明确的先验。在这项工作中，我们的目标是使用参数表示提供的先验改进 SDF 模型。特别是，我们提出了一个联合学习框架，可以解开姿势和形状。我们从参数模型中获取手和物体的姿势，并使用它们在 3D 空间中对齐 SDF。我们表明，这种对齐的 SDF 更好地专注于重建形状细节并提高手和物体的重建精度。我们评估了我们的方法，并在具有挑战性的 ObMan 和 DexYCB 基准上展示了对现有技术的显着改进。
