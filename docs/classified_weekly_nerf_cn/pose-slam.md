
每周分类神经辐射场 - pose-slam ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
======================================================================================================================================
## 按类别筛选: 
 [全部](../weekly_nerf_cn.md) | [动态](./dynamic.md) | [编辑](./editing.md) | [快速](./fast.md) | [泛化](./generalization.md) | [人体](./human.md) | [视频](./video.md) | [光照](./lighting.md) | [重建](./reconstruction.md) | [纹理](./texture.md) | [语义](./semantic.md) | [姿态-SLAM](./pose-slam.md) | [其他](./others.md) 
## Oct2- Oct8, 2022
  - [一种基于神经表面重建的鲁棒对象抓取的 Real2Sim2Real 方法](https://arxiv.org/abs/2210.02685) | [code]
    > 最近基于 3D 的操作方法要么使用 3D 神经网络直接预测抓取姿势，要么使用从形状数据库中检索到的类似对象来解决抓取姿势。然而，前者在使用新的机器人手臂或看不见的物体进行测试时面临着普遍性挑战；后者假设数据库中存在类似的对象。我们假设最近的 3D 建模方法为构建评估场景的数字副本提供了途径，该评估场景提供物理模拟并支持稳健的操作算法学习。我们建议使用最先进的神经表面重建方法（Real2Sim 步骤）从现实世界的点云中重建高质量的网格。由于大多数模拟器采用网格进行快速模拟，因此重建的网格无需人工即可生成抓取姿势标签。生成的标签可以训练在真实评估场景中表现稳健的抓取网络（Sim2Real 步骤）。在合成和真实实验中，我们表明 Real2Sim2Real 管道的性能优于使用大型数据集训练的基线抓取网络和基于检索的重建的抓取采样方法。 Real2Sim2Real 管道的好处来自 1) 将场景建模和抓取采样解耦为子问题，以及 2) 可以使用最新的 3D 学习算法和基于网格的物理模拟技术以足够高的质量解决这两个子问题。
  - [用于实时、开放集场景理解的特征真实神经融合](https://arxiv.org/abs/2210.03043) | [code]
    > 机器人的一般场景理解需要灵活的语义表示，以便可以识别、分割和分组训练时可能不知道的新物体和结构。我们提出了一种算法，该算法在实时 SLAM 期间将来自标准预训练网络的一般学习特征融合到高效的 3D 几何神经场表示中。融合的 3D 特征图继承了神经域几何表示的连贯性。这意味着在运行时交互的少量人类标签使对象甚至对象的一部分能够以开放集的方式稳健而准确地分割。
  - [IR-MCL：基于隐式表示的在线全球本地化](https://arxiv.org/abs/2210.03113) | [***``[code]``***](https://github.com/PRBonn/ir-mcl)
    > 确定移动机器人的状态是机器人导航系统的重要组成部分。在本文中，我们解决了使用 2D LiDAR 数据估计机器人在室内环境中的姿势的问题，并研究了现代环境模型如何改进黄金标准 Monte-Carlo 定位 (MCL) 系统。我们提出了一个神经占用场（NOF）来使用神经网络隐式表示场景。借助预训练网络，我们可以通过体绘制合成 2D LiDAR 扫描以获取任意机器人姿势。基于隐式表示，我们可以获得合成扫描与实际扫描之间的相似度作为观察模型，并将其集成到 MCL 系统中以执行准确的定位。我们在五个自记录数据集和三个公开可用数据集的序列上评估我们的方法。我们表明，我们可以使用我们的方法准确有效地定位机器人，超过最先进方法的定位性能。实验表明，所呈现的隐式表示能够预测更准确的 2D LiDAR 扫描，从而为我们的基于粒子滤波器的定位提供改进的观察模型。我们方法的代码发布在：this https URL。
  - [NARF22：用于配置感知渲染的神经铰接辐射场, IROS2022](https://progress.eecs.umich.edu/projects/narf/) | [code]
    > 铰接物体对机器人的感知和操作提出了独特的挑战。它们增加的自由度数量使得定位等任务在计算上变得困难，同时也使得现实世界数据集收集的过程无法扩展。为了解决这些可扩展性问题，我们提出了神经铰接辐射场 (NARF22)，这是一个使用完全可微分、配置参数化神经辐射场 (NeRF) 作为提供铰接对象高质量渲染的方法的管道。 NARF22 在推理时不需要明确了解对象结构。我们提出了一种两阶段的基于部件的训练机制，即使底层训练数据只有一个配置表示，它也允许对象渲染模型在配置空间中很好地泛化。我们通过在通过 Fetch 移动操作机器人收集的真实关节工具数据集上训练可配置渲染器来展示 NARF22 的功效。我们通过配置估计和 6 自由度姿态细化任务展示了该模型对基于梯度的推理方法的适用性。项目网页位于：此 https URL。
  - [密集单目 SLAM 的概率体积融合](https://arxiv.org/abs/2210.01276) | [code]
    > 我们提出了一种利用深度密集单目 SLAM 和快速不确定性传播从图像中重建 3D 场景的新方法。所提出的方法能够密集、准确、实时地对场景进行 3D 重建，同时对来自密集单目 SLAM 的极其嘈杂的深度估计具有鲁棒性。与以前的方法不同，要么使用 ad-hoc 深度滤波器，要么从 RGB-D 相机的传感器模型估计深度不确定性，我们的概率深度不确定性直接来自 SLAM 中底层束调整问题的信息矩阵。我们表明，由此产生的深度不确定性提供了一个很好的信号来加权深度图以进行体积融合。如果没有我们的深度不确定性，生成的网格会很嘈杂并带有伪影，而我们的方法会生成准确的 3D 网格，并且伪影要少得多。我们提供了具有挑战性的 Euroc 数据集的结果，并表明我们的方法比直接融合来自单目 SLAM 的深度的准确度提高了 92%，与最佳竞争方法相比提高了 90%。
  - [NeRF：3D 视觉中的神经辐射场，综合评论](https://arxiv.org/abs/2210.00379) | [code]
    > 神经辐射场 (NeRF) 是一种具有隐式场景表示的新型视图合成，已经席卷了计算机视觉领域。作为一种新颖的视图合成和 3D 重建方法，NeRF 模型在机器人技术、城市测绘、自主导航、虚拟现实/增强现实等领域都有应用。自 Mildenhall 等人的原始论文以来，已发表了 250 多份预印本，其中 100 多份最终被一级计算机​​视觉会议接受。鉴于 NeRF 的受欢迎程度和当前对该研究领域的兴趣，我们认为有必要对过去两年的 NeRF 论文进行全面调查，我们将其组织成基于架构和基于应用程序的分类法。我们还介绍了基于 NeRF 的新颖视图合成理论，以及关键 NeRF 模型的性能和速度的基准比较。通过创建这项调查，我们希望向 NeRF 介绍新的研究人员，为该领域有影响力的工作提供有益的参考，并通过我们的讨论部分激发未来的研究方向。
## Sep25 - Oct1, 2022
  - [具有三层采样和全景表示的城市级增量神经映射](https://arxiv.org/abs/2209.14072) | [code]
    > 神经隐式表示最近引起了机器人界的广泛关注，因为它们具有表现力、连续性和紧凑性。然而，基于稀疏 LiDAR 输入的城市规模增量隐式密集映射仍然是一个未充分探索的挑战。为此，我们成功构建了第一个具有全景表示的城市规模增量神经映射系统，该系统由环境级和实例级建模组成。给定一个稀疏的 LiDAR 点云流，它维护一个动态生成模型，将 3D 坐标映射到有符号距离场 (SDF) 值。为了解决在城市尺度空间中表示不同层次几何信息的困难，我们提出了一种定制的三层采样策略来动态采样全局、局部和近地表域。同时，为了实现高保真映射，引入了特定类别的先验以更好地对几何细节进行建模，从而实现全景表示。我们评估了公共 SemanticKITTI 数据集，并使用定量和定性结果证明了新提出的三层采样策略和全景表示的重要性。代码和数据将公开。
  - [Orbeez-SLAM：具有 ORB 特征和 NeRF 实现映射的实时单目视觉 SLAM](https://arxiv.org/abs/2209.13274) | [code]
    > 一种可以通过视觉信号执行复杂任务并与人类合作的空间人工智能备受期待。为了实现这一点，我们需要一个无需预训练即可轻松适应新场景并实时为下游任务生成密集地图的视觉 SLAM。由于其组件的内在限制，以前的基于学习和非基于学习的视觉 SLAM 都不能满足所有需求。在这项工作中，我们开发了一个名为 Orbeez-SLAM 的视觉 SLAM，它成功地与隐式神经表示 (NeRF) 和视觉里程计合作来实现我们的目标。此外，Orbeez-SLAM 可以与单目相机配合使用，因为它只需要 RGB 输入，使其广泛适用于现实世界。我们在各种具有挑战性的基准上验证了它的有效性。结果表明，我们的 SLAM 比强基线快 800 倍，并具有出色的渲染结果。
  - [通过控制屏障功能和神经辐射场增强基于视觉的控制器的安全性](https://arxiv.org/abs/2209.12266) | [code]
    > 为了在复杂的环境中导航，机器人必须越来越多地使用高维视觉反馈（例如图像）进行控制。然而，依靠高维图像数据做出控制决策会引发重要问题；特别是，我们如何证明视觉反馈控制器的安全性？控制障碍函数 (CBF) 是在状态反馈设置中验证反馈控制器安全性的强大工具，但由于需要预测未来的观察结果以评估障碍函数，CBF 传统上不太适合视觉反馈控制.在这项工作中，我们利用神经辐射场 (NeRFs) 的最新进展来解决这个问题，神经辐射场 (NeRFs) 学习 3D 场景的隐式表示并可以从以前看不见的相机视角渲染图像，为基于 CBF 的单步视觉预测提供控制器。这种新颖的组合能够过滤掉不安全的行为并进行干预以保护安全。我们在实时模拟实验中展示了我们的控制器的效果，它成功地防止了机器人采取危险行动。
## Sep18 - Sep24, 2022
  - [Local_INN：使用可逆神经网络的隐式地图表示和定位](https://arxiv.org/abs/2209.11925) | [code]
    > 机器人定位是使用地图和传感器测量找到机器人姿势的逆问题。近年来，可逆神经网络（INNs）成功地解决了各个领域的模糊逆问题。本文提出了一个用 INN 解决本地化问题的框架。我们设计了一个 INN，它在正向路径中提供隐式地图表示并在反向路径中提供定位。通过在评估中对潜在空间进行采样，Local\_INN 输出具有协方差的机器人位姿，可用于估计不确定性。我们表明 Local\_INN 的本地化性能与当前的方法相当，但延迟要低得多。我们使用训练集外部的姿势从 Local\_INN 显示详细的 2D 和 3D 地图重建。我们还提供了一个使用 Local\_INN 的全局定位算法来解决绑架问题。
  - [NeRF-Loc：神经辐射场内基于变换器的对象定位](https://arxiv.org/abs/2209.12068) | [code]
    > 神经辐射场 (NeRFs) 已成功用于场景表示。最近的工作还开发了使用基于 NeRF 的环境表示的机器人导航和操纵系统。由于对象定位是许多机器人应用的基础，为了进一步释放 NeRF 在机器人系统中的潜力，我们研究了 NeRF 场景中的对象定位。我们提出了一个基于转换器的框架 NeRF-Loc 来提取 NeRF 场景中对象的 3D 边界框。 NeRF-Loc 将预先训练的 NeRF 模型和相机视图作为输入，并生成标记的 3D 对象边界框作为输出。具体来说，我们设计了一对并行的转换器编码器分支，即粗流和细流，对目标对象的上下文和细节进行编码。然后将编码特征与注意力层融合在一起，以减轻模糊性，从而实现准确的对象定位。我们将我们的方法与传统的基于变压器的方法进行了比较，我们的方法取得了更好的性能。此外，我们还展示了第一个基于 NeRF 样本的对象定位基准 NeRFLocBench。
  - [感觉怎么样？ 用于越野车辆可穿越性的自我监督成本图学习](https://arxiv.org/abs/2209.10788) | [code]
    > 估计越野环境中的地形可穿越性需要推理机器人与这些地形之间的复杂交互动力学。然而，对于这些交互，构建准确的物理模型或创建信息标签以有监督的方式学习模型具有挑战性。我们提出了一种方法，该方法通过以自我监督的方式将外部感知环境信息与本体感知地形交互反馈相结合来学习预测可遍历性成本图。此外，我们提出了一种将机器人速度纳入成本图预测管道的新方法。我们在具有挑战性的越野地形的大型自主全地形车 (ATV) 上的多个短距离和大规模导航任务中验证了我们的方法，并证明了在单独的大型地面机器人上易于集成。我们的短尺度导航结果表明，使用我们学习的成本图可以使导航整体更顺畅，并为机器人提供对机器人与不同地形类型（如草地和砾石）之间相互作用的更细粒度的理解。我们的大规模导航试验表明，在 400 米到 3150 米的具有挑战性的越野路线中，与基于占用的导航基线相比，我们可以将干预次数减少多达 57%。
  - [Loc-NeRF：使用神经辐射场进行蒙特卡罗定位](https://arxiv.org/abs/2209.09050) | [***``[code]``***](https://github.com/MIT-SPARK/Loc-NeRF)
    > 我们提出了 Loc-NeRF，这是一种基于实时视觉的机器人定位方法，它结合了蒙特卡洛定位和神经辐射场 (NeRF)。我们的系统使用预训练的 NeRF 模型作为环境地图，并且可以使用 RGB 相机作为机器人上唯一的外部感受器实时定位自身。虽然神经辐射场已经在计算机视觉和图形中看到了视觉渲染的重要应用，但它们在机器人技术中的用途有限。现有的基于 NeRF 的定位方法需要良好的初始姿势猜测和大量计算，这使得它们对于实时机器人应用不切实际。通过使用 Monte Carlo 定位作为使用 NeRF 地图模型估计姿态的主力，Loc-NeRF 能够比现有技术更快地执行定位，并且不依赖于初始姿态估计。除了对合成数据进行测试外，我们还使用 Clearpath Jackal UGV 收集的真实数据运行我们的系统，并首次展示了使用神经辐射场执行实时全局定位的能力。我们通过此 https 网址公开我们的代码。
  - [MeSLAM：基于神经域的内存高效 SLAM, SMC2022](https://arxiv.org/abs/2209.09357) | [code]
    > 由于长期机器人操作中地图大小的增加，现有的同时定位和映射 (SLAM) 方法的可扩展性有限。此外，为定位和规划任务处理此类地图会导致车载所需的计算资源增加。为了解决长期操作中的内存消耗问题，我们开发了一种新颖的实时 SLAM 算法 MeSLAM，它基于神经场隐式地图表示。它将提议的全局映射策略（包括神经网络分布和区域跟踪）与外部里程计系统相结合。因此，该算法能够有效地训练代表不同地图区域的多个网络，并在大规模环境中准确地跟踪姿势。实验结果表明，所提出的方法的准确性与最先进的方法相当（在 TUM RGB-D 序列上平均为 6.6 cm），并且优于基线 iMAP*。此外，所提出的 SLAM 方法在最先进的 SLAM 方法中提供了最紧凑的地图，没有细节失真（1.9 MB 可存储 57 m3）。
  - [LATITUDE：在城市规模的 NeRF 中使用截断动态低通滤波器进行机器人全局定位, ICRA2023](https://arxiv.org/abs/2209.08498) | [***``[code]``***](https://github.com/jike5/LATITUDE)
    > 神经辐射场 (NeRFs) 在表示具有高分辨率细节和高效内存的复杂 3D 场景方面取得了巨大成功。然而，当前基于 NeRF 的姿态估计器没有初始姿态预测，并且在优化过程中容易出现局部最优。在本文中，我们提出了 LATITUDE：使用截断动态低通滤波器进行全局定位，它在城市规模的 NeRF 中引入了两阶段定位机制。在位置识别阶段，我们通过训练后的 NeRF 生成的图像训练回归器，为全局定位提供初始值。在姿态优化阶段，我们通过直接优化切平面上的姿态来最小化观察图像和渲染图像之间的残差。为了避免收敛到局部最优，我们引入了截断动态低通滤波器 (TDLF) 用于从粗到细的姿态配准。我们在合成数据和真实世界数据上评估我们的方法，并展示其在大规模城市场景中高精度导航的潜在应用。代码和数据将在此 https 网址上公开提供。
  - [使用神经辐射场进行主动机器人 3D 重建的不确定性引导策略, RA-L2022](https://arxiv.org/abs/2209.08409) | [code]
    > 在本文中，我们解决了物体的主动机器人 3D 重建问题。特别是，我们研究了带有手持摄像头的移动机器人如何选择有利数量的视图来有效地恢复对象的 3D 形状。与该问题的现有解决方案相反，我们利用流行的基于神经辐射场的对象表示，最近在各种计算机视觉任务中显示出令人印象深刻的结果。然而，使用这种表示直接推断对象的显式 3D 几何细节并不简单，这使得密集 3D 重建的次佳视图选择问题具有挑战性。本文介绍了一种基于光线的体积不确定性估计器，它计算颜色样本沿物体隐式神经表示的每条光线的权重分布的熵。我们表明，使用所提出的估计器给出一个新颖的视图，可以推断出底层 3D 几何的不确定性。然后，我们提出了一个下一个最佳视图选择策略，该策略由基于神经辐射场的表示中基于射线的体积不确定性指导。令人鼓舞的合成数据和真实世界数据的实验结果表明，本文提出的方法可以启用一个新的研究方向，即使用隐式 3D 对象表示来解决机器人视觉应用中的下一个最佳视图问题，将我们的方法与现有的方法区分开来依赖于显式 3D 几何建模的方法。
## Sep11 - Sep17, 2022
  - [iDF-SLAM：具有神经隐式映射和深度特征跟踪的端到端 RGB-D SLAM](https://arxiv.org/abs/2209.07919) | [code]
    > 我们提出了一种新颖的端到端 RGB-D SLAM iDF-SLAM，它采用基于特征的深度神经跟踪器作为前端，采用 NeRF 风格的神经隐式映射器作为后端。神经隐式映射器是即时训练的，虽然神经跟踪器是在 ScanNet 数据集上进行预训练的，但它也会随着神经隐式映射器的训练进行微调。在这样的设计下，我们的 iDF-SLAM 能够学习使用特定场景的特征进行相机跟踪，从而实现 SLAM 系统的终身学习。跟踪器和映射器的训练都是自我监督的，没有引入地面真实姿势。我们在 Replica 和 ScanNet 数据集上测试了 iDF-SLAM 的性能，并将结果与​​最近的两个基于 NeRF 的神经 SLAM 系统进行了比较。所提出的 iDF-SLAM 在场景重建和相机跟踪的竞争性能方面展示了最先进的结果。
## Previous weeks
## Sep4 - Sep10, 2022
  - [PixTrack：使用 NeRF 模板和特征度量对齐的精确 6DoF 对象姿势跟踪](https://arxiv.org/abs/2209.03910) | [code]
    > 我们提出了 PixTrack，这是一个基于视觉的对象姿态跟踪框架，使用新颖的视图合成和深度特征度量对齐。我们的评估表明，我们的方法可以对 RGB 图像中的对象进行高度准确、稳健且无抖动的 6DoF 姿态估计，而无需任何数据注释或轨迹平滑。我们的方法在计算上也很高效，可以轻松进行多对象跟踪，而无需更改我们的方法，并且只使用 CPU 多处理。
## Aug28 - Sep3, 2022
## Aug21 - Aug27, 2022
## Previous weeks
## Aug21 - Aug27, 2022
  - [SCONE：通过体积积分优化未知环境中的表面覆盖率](https://arxiv.org/abs/2208.10449) | [code]
    > 下一个最佳视图计算 (NBV) 是机器人技术中长期存在的问题，包括识别下一个信息量最大的传感器位置，以有效且准确地重建 3D 对象或场景。像大多数当前方法一样，我们考虑来自深度传感器的 NBV 预测。依赖于场景体积表示的基于学习的方法适用于路径规划，但不能很好地适应场景的大小，并且精度低于使用基于表面的表示的方法。然而，后者将相机限制在少数姿势。为了获得这两种表示的优点，我们表明我们可以通过蒙特卡罗积分在体积表示上最大化表面度量。我们的方法可扩展到大型场景并处理自由相机运动：它将由深度传感器（如激光雷达系统）收集的任意大点云以及相机姿势作为输入来预测 NBV。我们在由大型复杂 3D 场景组成的新数据集上展示了我们的方法。
## Aug14 - Aug20, 2022
  - [8 点算法作为 ViTs 相对姿势预测的归纳偏差, 3DV2022](https://arxiv.org/abs/2208.08988) | [***``[code]``***](https://github.com/crockwell/rel_pose)
    > 我们提出了一个简单的基线，用于直接估计两个图像之间的相对姿势（旋转和平移，包括比例）。深度方法最近显示出强劲的进展，但通常需要复杂或多阶段的架构。我们展示了一些修改可以应用于视觉转换器 (ViT)，以使其计算接近八点算法。这种归纳偏差使一种简单的方法在多种环境中具有竞争力，通常在有限的数据机制中显着提高现有技术水平，并具有强大的性能提升。
## Aug7 - Aug13, 2022
  - [RelPose：预测野外单个物体的概率相对旋转, ECCV2022](https://jasonyzhang.com/relpose/) | [***``[code]``***](https://github.com/jasonyzhang/relpose)
    > 我们描述了一种数据驱动的方法，用于在给定任意对象的多个图像的情况下推断相机视点。该任务是经典几何流水线（如 SfM 和 SLAM）的核心组成部分，也是当代神经方法（例如 NeRF）对对象重建和视图合成的重要预处理要求。与现有的在稀疏视图中表现不佳的对应驱动方法相比，我们提出了一种基于自上而下预测的方法来估计相机视点。我们的关键技术见解是使用基于能量的公式来表示相对相机旋转的分布，从而使我们能够明确表示由对象对称性或视图产生的多个相机模式。利用这些相对预测，我们从多张图像中共同估计一组一致的相机旋转。我们表明，在给定可见和不可见类别的稀疏图像的情况下，我们的方法优于最先进的 SfM 和 SLAM 方法。此外，我们的概率方法明显优于直接回归相对姿势，这表明建模多模态对于连贯的关节重建很重要。我们证明我们的系统可以成为从多视图数据集进行野外重建的垫脚石。包含代码和视频的项目页面可以在这个 https URL 找到。
## Jul31 - Aug6, 2022
  - [PRIF: Primary Ray-based Implicit Function](https://research.google/pubs/pub51556/) | [code]
    > 我们引入了一种新的隐式形状表示，称为基于初级光线的隐式函数 (PRIF)。与大多数基于符号距离函数 (SDF) 处理空间位置的现有方法相比，我们的表示在定向射线上运行。具体来说，PRIF 被制定为直接生成给定输入射线的表面命中点，而无需昂贵的球体跟踪操作，从而实现高效的形状提取和可微渲染。我们证明了经过训练以编码 PRIF 的神经网络在各种任务中取得了成功，包括单一形状表示、类别形状生成、稀疏或嘈杂观察的形状补全、相机姿态估计的逆渲染以及颜色的神经渲染。
## Jul24 - Jul30, 2022
  - [ObjectFusion：具有神经对象先验的准确对象级 SLAM, Graphical Models, Volume 123, September 2022](https://www.sciencedirect.com/science/article/pii/S1524070322000418) | [code]
    > 以前的对象级同步定位和映射 (SLAM) 方法仍然无法以有效的方式创建高质量的面向对象的 3D 地图。主要挑战来自如何有效地表示对象形状以及如何将这种对象表示有效地应用于准确的在线相机跟踪。在本文中，我们提供 ObjectFusion 作为静态场景中的一种新颖的对象级 SLAM，它通过利用神经对象先验，有效地创建具有高质量对象重建的面向对象的 3D 地图。我们提出了一种仅具有单个编码器-解码器网络的神经对象表示，以有效地表达各种类别的对象形状，这有利于对象实例的高质量重建。更重要的是，我们建议将这种神经对象表示转换为精确测量，以共同优化对象形状、对象姿态和相机姿态，以实现最终准确的 3D 对象重建。通过对合成和真实世界 RGB-D 数据集的广泛评估，我们表明我们的 ObjectFusion 优于以前的方法，具有更好的对象重建质量，使用更少的内存占用，并且以更有效的方式，尤其是在对象级别。
  - [神经密度-距离场, ECCV2022](https://arxiv.org/abs/2207.14455) | [***``[code]``***](https://ueda0319.github.io/neddf/)
    > 神经领域在 3D 视觉任务中的成功现在是无可争辩的。遵循这一趋势，已经提出了几种针对视觉定位的方法（例如，SLAM）来使用神经场估计距离或密度场。然而，仅通过基于密度场的方法（例如神经辐射场 (NeRF)）很难实现高定位性能，因为它们在大多数空白区域中不提供密度梯度。另一方面，基于距离场的方法，例如神经隐式表面 (NeuS)，在对象的表面形状方面存在局限性。本文提出了神经密度-距离场 (NeDDF)，这是一种新的 3D 表示，它相互约束距离和密度场。我们将距离场公式扩展到没有明确边界表面的形状，例如毛皮或烟雾，这使得从距离场到密度场的显式转换成为可能。通过显式转换实现的一致距离和密度场既能保证初始值的鲁棒性，又能实现高质量的配准。此外，场之间的一致性允许从稀疏点云快速收敛。实验表明，NeDDF 可以实现高定位性能，同时在新颖的视图合成上提供与 NeRF 相当的结果。该代码可在此 https URL 获得。
  - [ShAPO：多对象形状、外观和姿势优化的隐式表示, ECCV2022](https://arxiv.org/abs/2207.13691) | [***``[code]``***](https://zubair-irshad.github.io/projects/ShAPO.html)
    > 我们的方法从单个 RGB-D 观察中研究以对象为中心的 3D 理解的复杂任务。由于这是一个不适定问题，现有方法在具有遮挡的复杂多对象场景中的 3D 形状和 6D 姿势和尺寸估计性能低下。我们提出了 ShaAPO，一种用于联合多对象检测、3D 纹理重建、6D 对象姿态和大小估计的方法。 ShAPO 的关键是一个单次管道，用于回归形状、外观和姿势潜在代码以及每个对象实例的掩码，然后以稀疏到密集的方式进一步细化。首先学习了一种新的解开的先验形状和外观数据库，以将对象嵌入到它们各自的形状和外观空间中。我们还提出了一种新颖的、基于八叉树的可微优化步骤，使我们能够以综合分析的方式在学习的潜在空间下同时进一步改进对象形状、姿势和外观。我们新颖的联合隐式纹理对象表示使我们能够准确地识别和重建新的看不见的对象，而无需访问它们的 3D 网格。通过广泛的实验，我们证明了我们的方法在模拟室内场景上进行训练，能够以最少的微调准确地回归现实世界中新物体的形状、外观和姿势。我们的方法显着优于 NOCS 数据集上的所有基线，6D 姿态估计的 mAP 绝对提高了 8%。
  - [GAUDI：沉浸式 3D 场景生成的神经架构师](https://arxiv.org/abs/2207.13751) | [***``[code]``***](https://github.com/apple/ml-gaudi)
    > 我们介绍了 GAUDI，这是一种生成模型，能够捕捉复杂而逼真的 3D 场景的分布，可以从移动的相机中沉浸式地渲染。我们用一种可扩展但功能强大的方法来解决这个具有挑战性的问题，我们首先优化一个潜在的表示，以解开辐射场和相机姿势。然后使用这种潜在表示来学习生成模型，该模型可以无条件和有条件地生成 3D 场景.我们的模型通过消除相机姿态分布可以跨样本共享的假设来概括以前专注于单个对象的工作。我们展示了 GAUDI 在跨多个数据集的无条件生成设置中获得了最先进的性能，并允许在给定条件变量（如稀疏图像观察或描述场景的文本）的情况下有条件地生成 3D 场景。
  - [AlignSDF：用于手对象重建的姿势对齐有符号距离场, ECCV2022](https://arxiv.org/abs/2207.12909) | [***``[code]``***](https://zerchen.github.io/projects/alignsdf.html)
    > 最近的工作在从单目彩色图像联合重建手和操纵对象方面取得了令人瞩目的进展。现有方法侧重于参数网格或符号距离场 (SDF) 方面的两种替代表示。一方面，参数模型可以从先验知识中受益，但代价是有限的形状变形和网格分辨率。因此，网格模型可能无法精确重建细节，例如手和物体的接触面。另一方面，基于 SDF 的方法可以表示任意细节，但缺乏明确的先验。在这项工作中，我们的目标是使用参数表示提供的先验改进 SDF 模型。特别是，我们提出了一个联合学习框架，可以解开姿势和形状。我们从参数模型中获取手和物体的姿势，并使用它们在 3D 空间中对齐 SDF。我们表明，这种对齐的 SDF 更好地专注于重建形状细节并提高手和物体的重建精度。我们评估了我们的方法，并在具有挑战性的 ObMan 和 DexYCB 基准上展示了对现有技术的显着改进。
## Previous weeks
  - [野外的 NeRF：无约束照片集的神经辐射场, CVPR2021](https://arxiv.org/abs/2008.02268) | [code]
    > 我们提出了一种基于学习的方法，用于仅使用野外照片的非结构化集合来合成复杂场景的新视图。我们建立在神经辐射场 (NeRF) 的基础上，它使用多层感知器的权重将场景的密度和颜色建模为 3D 坐标的函数。虽然 NeRF 在受控设置下捕获的静态对象的图像上效果很好，但它无法在不受控的图像中模拟许多普遍存在的真实世界现象，例如可变照明或瞬态遮挡物。我们为 NeRF 引入了一系列扩展来解决这些问题，从而能够从互联网上获取的非结构化图像集合中进行准确的重建。我们将我们的系统（称为 NeRF-W）应用于著名地标的互联网照片集，并展示时间一致的新颖视图渲染，这些渲染比现有技术更接近真实感。
  - [Ha-NeRF：野外的幻觉神经辐射场, CVPR2022](https://rover-xingyu.github.io/Ha-NeRF/) | [***``[code]``***](https://github.com/rover-xingyu/Ha-NeRF)
    > 神经辐射场 (NeRF) 最近因其令人印象深刻的新颖视图合成能力而广受欢迎。本文研究了幻觉 NeRF 的问题：即在一天中的不同时间从一组旅游图像中恢复一个真实的 NeRF。现有的解决方案采用具有可控外观嵌入的 NeRF 在各种条件下渲染新颖的视图，但它们无法渲染具有看不见的外观的视图一致图像。为了解决这个问题，我们提出了一个用于构建幻觉 NeRF 的端到端框架，称为 Ha-NeRF。具体来说，我们提出了一个外观幻觉模块来处理随时间变化的外观并将它们转移到新的视图中。考虑到旅游图像的复杂遮挡，我们引入了一个反遮挡模块来准确地分解静态主体以获得可见性。合成数据和真实旅游照片集的实验结果表明，我们的方法可以产生幻觉，并从不同的视图呈现无遮挡的图像。
  - [Nerfies：可变形的神经辐射场, ICCV2021](https://arxiv.org/abs/2011.12948) | [code]
    > 我们提出了第一种能够使用从手机随便捕获的照片/视频来逼真地重建可变形场景的方法。我们的方法通过优化一个额外的连续体积变形场来增强神经辐射场 (NeRF)，该场将每个观察点扭曲成一个规范的 5D NeRF。我们观察到这些类似 NeRF 的变形场容易出现局部最小值，并为基于坐标的模型提出了一种从粗到细的优化方法，可以实现更稳健的优化。通过将几何处理和物理模拟的原理应用于类似 NeRF 的模型，我们提出了变形场的弹性正则化，进一步提高了鲁棒性。我们表明，我们的方法可以将随意捕获的自拍照片/视频转换为可变形的 NeRF 模型，允许从任意视角对主体进行逼真的渲染，我们称之为“nerfies”。我们通过使用带有两部手机的装备收集时间同步数据来评估我们的方法，从而在不同视点产生相同姿势的训练/验证图像。我们表明，我们的方法忠实地重建了非刚性变形的场景，并以高保真度再现了看不见的视图。
  - [用于单目 4D 面部头像重建的动态神经辐射场, CVPR2021](https://gafniguy.github.io/4D-Facial-Avatars/) | [***``[code]``***](https://github.com/gafniguy/4D-Facial-Avatars)
    > 我们提出了用于模拟人脸外观和动态的动态神经辐射场。对说话的人进行数字建模和重建是各种应用程序的关键组成部分。特别是对于 AR 或 VR 中的远程呈现应用，需要忠实再现外观，包括新颖的视点或头部姿势。与显式建模几何和材料属性或纯粹基于图像的最先进方法相比，我们引入了基于场景表示网络的头部隐式表示。为了处理面部的动态，我们将场景表示网络与低维可变形模型相结合，该模型提供对姿势和表情的显式控制。我们使用体积渲染从这种混合表示中生成图像，并证明这种动态神经场景表示只能从单目输入数据中学习，而不需要专门的捕获设置。在我们的实验中，我们表明这种学习的体积表示允许生成照片般逼真的图像，其质量超过了基于视频的最先进的重演方法的质量。
  - [神经关节辐射场, ICCV2021](https://arxiv.org/abs/2104.03110) | [***``[code]``***](https://github.com/nogu-atsu/NARF#code)
    > 我们提出了神经关节辐射场 (NARF)，这是一种新颖的可变形 3D 表示，用于从图像中学习到的关节对象。虽然 3D 隐式表示的最新进展使得学习复杂对象的模型成为可能，但学习关节对象的姿势可控表示仍然是一个挑战，因为当前的方法需要 3D 形状监督并且无法呈现外观。在制定 3D 关节对象的隐式表示时，我们的方法在求解每个 3D 位置的辐射场时仅考虑最相关对象部分的刚性变换。通过这种方式，所提出的方法可以表示与姿势相关的变化，而不会显着增加计算复杂度。 NARF 是完全可微的，可以从带有姿势注释的图像中训练出来。此外，通过使用自动编码器，它可以学习对象类的多个实例的外观变化。实验表明，所提出的方法是有效的，并且可以很好地推广到新的姿势。
  - [神经演员：具有姿势控制的人类演员的神经自由视图合成, SIGSIGGRAPH Asia 2021](https://vcai.mpi-inf.mpg.de/projects/NeuralActor/) | [***``[code]``***](https://people.mpi-inf.mpg.de/~lliu/projects/NeuralActor/)
    > 我们提出了神经演员 (NA)，这是一种从任意视角和任意可控姿势下高质量合成人类的新方法。我们的方法建立在最近的神经场景表示和渲染工作之上，这些工作仅从 2D 图像中学习几何和外观的表示。虽然现有作品展示了令人信服的静态场景渲染和动态场景回放，但使用神经隐式方法对人类进行逼真的重建和渲染，特别是在用户控制的新姿势下，仍然很困难。为了解决这个问题，我们利用粗体模型作为代理将周围的 3D 空间展开为规范姿势。神经辐射场从多视图视频输入中学习规范空间中与姿势相关的几何变形以及与姿势和视图相关的外观效果。为了合成高保真动态几何和外观的新视图，我们利用在身体模型上定义的 2D 纹理图作为潜在变量来预测残余变形和动态外观。实验表明，我们的方法在回放和新颖的姿势合成方面取得了比现有技术更好的质量，甚至可以很好地推广到与训练姿势截然不同的新姿势。此外，我们的方法还支持合成结果的体形控制。
  - [iNeRF：用于姿势估计的反转神经辐射场, IROS2021](http://yenchenlin.me/inerf/) | [***``[code]``***](https://github.com/yenchenlin/iNeRF-public)
    > 我们提出了 iNeRF，这是一个通过“反转”经过训练的神经辐射场 (NeRF) 来执行姿态估计的框架。 NeRF 已被证明对视图合成任务非常有效——合成真实世界场景或对象的逼真的新视图。在这项工作中，我们研究是否可以使用 NeRF 进行综合分析来进行 6DoF 姿势估计——给定图像，找到相机相对于 3D 模型的平移和旋转。从初始姿态估计开始，我们使用梯度下降来最小化从已经训练的 NeRF 渲染的像素和观察图像中的像素之间的残差。在我们的实验中，我们首先研究 1）如何在 iNeRF 的姿势细化过程中对光线进行采样以收集信息梯度，以及 2）不同批次大小的光线如何影响合成数据集上的 iNeRF。然后，我们展示了对于来自 LLFF 数据集的复杂现实世界场景，iNeRF 可以通过估计新图像的相机位姿并将这些图像用作 NeRF 的额外训练数据来改进 NeRF。最后，我们展示了 iNeRF 可以与基于特征的姿势初始化相结合。该方法优于所有其他依赖 LineMOD 上的合成数据的基于 RGB 的方法。
  - [A-NeRF：通过神经渲染进行无表面人体 3D 姿势细化, NeurIPS2021](https://arxiv.org/abs/2102.06199) | [***``[code]``***](https://github.com/LemonATsu/A-NeRF)
    > 虽然深度学习使用前馈网络重塑了经典的运动捕捉管道，但需要生成模型通过迭代细化来恢复精细对齐。不幸的是，现有模型通常是在受控条件下手工制作或学习的，仅适用于有限的领域。我们提出了一种通过扩展神经辐射场 (NeRFs) 从未标记的单目视频中学习生成神经体模型的方法。我们为它们配备了骨架，以适用于时变和关节运动。一个关键的见解是，隐式模型需要与显式曲面模型中使用的正向运动学相反。我们的重新参数化定义了相对于身体部位姿势的空间潜在变量，从而克服了过度参数化的不适定逆运算。这使得从头开始学习体积身体形状和外观，同时共同改进关节姿势；输入视频上的所有外观、姿势或 3D 形状都没有地面实况标签。当用于新视图合成和动作捕捉时，我们的神经模型提高了不同数据集的准确性。项目网站：此 https 网址。
  - [NeRF--：没有已知相机参数的神经辐射场](https://nerfmm.active.vision/) | [***``[code]``***](https://github.com/ActiveVisionLab/nerfmm)
    > 考虑到仅来自一组 2D 图像的新视图合成 (NVS) 问题，我们通过消除已知或预先计算的相机参数的要求，简化了前向场景中神经辐射场 (NeRF) 的训练过程，包括内在函数和 6DoF 姿势。为此，我们提出了 NeRF−−，具有三个贡献：首先，我们表明相机参数可以通过光度重建作为可学习参数与 NeRF 训练联合优化；其次，为了对相机参数估计和新颖视图渲染的质量进行基准测试，我们引入了一个新的路径跟踪合成场景数据集，称为 Blender Forward-Facing Dataset (BLEFF)；第三，我们进行了广泛的分析以了解各种相机运动下的训练行为，并表明在大多数情况下，联合优化管道可以恢复准确的相机参数并实现与使用 COLMAP 预计算相机参数训练的方法相当的新视图合成质量。
  - [实时隐式映射和定位, ICCV2021](https://arxiv.org/abs/2103.12352) | [code]
    > 我们首次展示了多层感知器 (MLP) 可以作为手持 RGB-D 相机的实时 SLAM 系统中唯一的场景表示。我们的网络在没有先验数据的情况下进行实时操作训练，构建了一个密集的、特定于场景的隐式 3D 占用率和颜色模型，该模型也可立即用于跟踪。
  - [用于 SLAM 的 NICE-SLAM 神经隐​​式可扩展编码, CVPR2022](https://arxiv.org/abs/2112.12130) | [***``[code]``***](https://github.com/cvg/nice-slam)
    > 神经隐式表示最近在各个领域都显示出令人鼓舞的结果，包括在同时定位和映射 (SLAM) 方面取得的可喜进展。然而，现有方法会产生过度平滑的场景重建，并且难以扩展到大场景。这些限制主要是由于它们简单的全连接网络架构没有在观察中包含本地信息。在本文中，我们提出了 NICE-SLAM，这是一种密集的 SLAM 系统，它通过引入分层场景表示来结合多级局部信息。使用预先训练的几何先验优化这种表示可以在大型室内场景中进行详细的重建。与最近的神经隐式 SLAM 系统相比，我们的方法更具可扩展性、高效性和鲁棒性。在五个具有挑战性的数据集上的实验证明了 NICE-SLAM 在映射和跟踪质量方面的竞争结果。
  - [GNeRF：基于 GAN 的无姿势相机的神经辐射场, ICCV2021(oral)](https://arxiv.org/abs/2103.15606) | [code]
    > 我们介绍了 GNeRF，这是一个将生成对抗网络 (GAN) 与神经辐射场 (NeRF) 重建相结合的框架，用于具有未知甚至随机初始化相机姿势的复杂场景。最近基于 NeRF 的进展因显着的逼真的新视图合成而受到欢迎。然而，它们中的大多数严重依赖于准确的相机位姿估计，而最近的一些方法只能在相机轨迹相对较短的大致前向场景中优化未知相机位姿，并且需要粗略的相机位姿初始化。不同的是，我们的 GNeRF 仅将随机初始化的姿势用于复杂的由外而内的场景。我们提出了一种新颖的两阶段端到端框架。第一阶段将 GAN 的使用带入新领域，以联合优化粗略的相机姿势和辐射场，而第二阶段通过额外的光度损失对它们进行细化。我们使用混合迭代优化方案克服了局部最小值。对各种合成和自然场景的广泛实验证明了 GNeRF 的有效性。更令人印象深刻的是，我们的方法在那些以前被认为极具挑战性的重复模式甚至低纹理的场景中优于基线。
  - [BARF：捆绑调整神经辐射场, ICCV2021(oral)](https://chenhsuanlin.bitbucket.io/bundle-adjusting-NeRF/) | [***``[code]``***](https://github.com/chenhsuanlin/bundle-adjusting-NeRF)
    > 神经辐射场 (NeRF) 最近在计算机视觉界引起了极大的兴趣，因为它具有合成真实世界场景的逼真的新颖视图的能力。然而，NeRF 的一个限制是它需要准确的相机姿势来学习场景表示。在本文中，我们提出了 Bundle-Adjusting Neural Radiance Fields (BARF)，用于从不完美（甚至未知）的相机姿势训练 NeRF——学习神经 3D 表示和注册相机帧的联合问题。我们建立了与经典图像对齐的理论联系，并表明从粗到细的配准也适用于 NeRF。此外，我们表明，在 NeRF 中天真地应用位置编码会对基于合成的目标的注册产生负面影响。合成数据和真实世界数据的实验表明，BARF 可以有效地优化神经场景表示并同时解决大的相机位姿错位问题。这使得来自未知相机位姿的视频序列的视图合成和定位成为可能，为视觉定位系统（例如 SLAM）和密集 3D 映射和重建的潜在应用开辟了新途径。
  - [自校准神经辐射场, ICCV2021](https://postech-cvlab.github.io/SCNeRF/) | [***``[code]``***](https://github.com/POSTECH-CVLab/SCNeRF)
    > 在这项工作中，我们提出了一种用于具有任意非线性失真的通用相机的相机自校准算法。我们共同学习场景的几何形状和准确的相机参数，无需任何校准对象。我们的相机模型包括针孔模型、径向失真和可以学习任意非线性相机失真的通用噪声模型。虽然传统的自校准算法主要依赖于几何约束，但我们还结合了光度一致性。这需要学习场景的几何形状，我们使用神经辐射场 (NeRF)。我们还提出了一种新的几何损失函数，即投影射线距离损失，以结合复杂非线性相机模型的几何一致性。我们在标准真实图像数据集上验证了我们的方法，并证明我们的模型可以从头开始学习相机的内在和外在（姿势），而无需 COLMAP 初始化。此外，我们表明，以可微分的方式学习准确的相机模型可以让我们在 NeRF 上提高 PSNR。我们通过实验证明我们提出的方法适用于 NeRF 的变体。此外，我们使用一组用鱼眼镜头拍摄的图像来证明学习相机模型与 COLMAP 初始化相比，共同提高了性能。
  - [动态场景的神经场景图, CVPR2021(oral)](https://arxiv.org/abs/2011.10379) | [***``[code]``***](https://github.com/princeton-computational-imaging/neural-scene-graphs)
    > 最近的隐式神经渲染方法表明，可以通过仅由一组 RGB 图像监督的预测其体积密度和颜色来学习复杂场景的准确视图合成。然而，现有方法仅限于学习将所有场景对象编码为单个神经网络的静态场景的有效表示，并且缺乏将动态场景表示和分解为单个场景对象的能力。在这项工作中，我们提出了第一个将动态场景分解为场景图的神经渲染方法。我们提出了一种学习的场景图表示，它对对象变换和辐射进行编码，以有效地渲染场景的新颖排列和视图。为此，我们学习隐式编码的场景，并结合联合学习的潜在表示来描述具有单个隐式函数的对象。我们在合成和真实汽车数据上评估所提出的方法，验证我们的方法学习动态场景 - 仅通过观察该场景的视频 - 并允许渲染具有看不见的对象集的新颖场景组合的新颖照片般逼真的视图看不见的姿势。
